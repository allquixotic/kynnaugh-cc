// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: google/cloud/speech/v1beta1/cloud_speech.proto

#define INTERNAL_SUPPRESS_PROTOBUF_FIELD_DEPRECATION
#include "google/cloud/speech/v1beta1/cloud_speech.pb.h"

#include <algorithm>

#include <google/protobuf/stubs/common.h>
#include <google/protobuf/stubs/port.h>
#include <google/protobuf/stubs/once.h>
#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/wire_format_lite_inl.h>
#include <google/protobuf/descriptor.h>
#include <google/protobuf/generated_message_reflection.h>
#include <google/protobuf/reflection_ops.h>
#include <google/protobuf/wire_format.h>
// @@protoc_insertion_point(includes)

namespace google {
namespace cloud {
namespace speech {
namespace v1beta1 {
class SyncRecognizeRequestDefaultTypeInternal : public ::google::protobuf::internal::ExplicitlyConstructed<SyncRecognizeRequest> {};
SyncRecognizeRequestDefaultTypeInternal _SyncRecognizeRequest_default_instance_;
class AsyncRecognizeRequestDefaultTypeInternal : public ::google::protobuf::internal::ExplicitlyConstructed<AsyncRecognizeRequest> {};
AsyncRecognizeRequestDefaultTypeInternal _AsyncRecognizeRequest_default_instance_;
class StreamingRecognizeRequestDefaultTypeInternal : public ::google::protobuf::internal::ExplicitlyConstructed<StreamingRecognizeRequest> {};
StreamingRecognizeRequestDefaultTypeInternal _StreamingRecognizeRequest_default_instance_;
class StreamingRecognitionConfigDefaultTypeInternal : public ::google::protobuf::internal::ExplicitlyConstructed<StreamingRecognitionConfig> {};
StreamingRecognitionConfigDefaultTypeInternal _StreamingRecognitionConfig_default_instance_;
class RecognitionConfigDefaultTypeInternal : public ::google::protobuf::internal::ExplicitlyConstructed<RecognitionConfig> {};
RecognitionConfigDefaultTypeInternal _RecognitionConfig_default_instance_;
class SpeechContextDefaultTypeInternal : public ::google::protobuf::internal::ExplicitlyConstructed<SpeechContext> {};
SpeechContextDefaultTypeInternal _SpeechContext_default_instance_;
class RecognitionAudioDefaultTypeInternal : public ::google::protobuf::internal::ExplicitlyConstructed<RecognitionAudio> {};
RecognitionAudioDefaultTypeInternal _RecognitionAudio_default_instance_;
class SyncRecognizeResponseDefaultTypeInternal : public ::google::protobuf::internal::ExplicitlyConstructed<SyncRecognizeResponse> {};
SyncRecognizeResponseDefaultTypeInternal _SyncRecognizeResponse_default_instance_;
class AsyncRecognizeResponseDefaultTypeInternal : public ::google::protobuf::internal::ExplicitlyConstructed<AsyncRecognizeResponse> {};
AsyncRecognizeResponseDefaultTypeInternal _AsyncRecognizeResponse_default_instance_;
class AsyncRecognizeMetadataDefaultTypeInternal : public ::google::protobuf::internal::ExplicitlyConstructed<AsyncRecognizeMetadata> {};
AsyncRecognizeMetadataDefaultTypeInternal _AsyncRecognizeMetadata_default_instance_;
class StreamingRecognizeResponseDefaultTypeInternal : public ::google::protobuf::internal::ExplicitlyConstructed<StreamingRecognizeResponse> {};
StreamingRecognizeResponseDefaultTypeInternal _StreamingRecognizeResponse_default_instance_;
class StreamingRecognitionResultDefaultTypeInternal : public ::google::protobuf::internal::ExplicitlyConstructed<StreamingRecognitionResult> {};
StreamingRecognitionResultDefaultTypeInternal _StreamingRecognitionResult_default_instance_;
class SpeechRecognitionResultDefaultTypeInternal : public ::google::protobuf::internal::ExplicitlyConstructed<SpeechRecognitionResult> {};
SpeechRecognitionResultDefaultTypeInternal _SpeechRecognitionResult_default_instance_;
class SpeechRecognitionAlternativeDefaultTypeInternal : public ::google::protobuf::internal::ExplicitlyConstructed<SpeechRecognitionAlternative> {};
SpeechRecognitionAlternativeDefaultTypeInternal _SpeechRecognitionAlternative_default_instance_;

namespace {

::google::protobuf::Metadata file_level_metadata[14];
const ::google::protobuf::EnumDescriptor* file_level_enum_descriptors[2];
struct StreamingRecognizeRequestOneofInstance {
  const ::google::cloud::speech::v1beta1::StreamingRecognitionConfig* streaming_config_;
  ::google::protobuf::internal::ArenaStringPtr audio_content_;
} StreamingRecognizeRequest_default_oneof_instance_;
struct RecognitionAudioOneofInstance {
  ::google::protobuf::internal::ArenaStringPtr content_;
  ::google::protobuf::internal::ArenaStringPtr uri_;
} RecognitionAudio_default_oneof_instance_;

}  // namespace


const ::google::protobuf::uint32* protobuf_Offsets_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto() GOOGLE_ATTRIBUTE_COLD;
const ::google::protobuf::uint32* protobuf_Offsets_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto() {
  static const ::google::protobuf::uint32 offsets[] = {
    ~0u,  // no _has_bits_
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(SyncRecognizeRequest, _internal_metadata_),
    ~0u,  // no _extensions_
    ~0u,  // no _oneof_case_
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(SyncRecognizeRequest, config_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(SyncRecognizeRequest, audio_),
    ~0u,  // no _has_bits_
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(AsyncRecognizeRequest, _internal_metadata_),
    ~0u,  // no _extensions_
    ~0u,  // no _oneof_case_
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(AsyncRecognizeRequest, config_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(AsyncRecognizeRequest, audio_),
    ~0u,  // no _has_bits_
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(StreamingRecognizeRequest, _internal_metadata_),
    ~0u,  // no _extensions_
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(StreamingRecognizeRequest, _oneof_case_[0]),
    PROTO2_GENERATED_DEFAULT_ONEOF_FIELD_OFFSET((&StreamingRecognizeRequest_default_oneof_instance_), streaming_config_),
    PROTO2_GENERATED_DEFAULT_ONEOF_FIELD_OFFSET((&StreamingRecognizeRequest_default_oneof_instance_), audio_content_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(StreamingRecognizeRequest, streaming_request_),
    ~0u,  // no _has_bits_
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(StreamingRecognitionConfig, _internal_metadata_),
    ~0u,  // no _extensions_
    ~0u,  // no _oneof_case_
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(StreamingRecognitionConfig, config_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(StreamingRecognitionConfig, single_utterance_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(StreamingRecognitionConfig, interim_results_),
    ~0u,  // no _has_bits_
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RecognitionConfig, _internal_metadata_),
    ~0u,  // no _extensions_
    ~0u,  // no _oneof_case_
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RecognitionConfig, encoding_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RecognitionConfig, sample_rate_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RecognitionConfig, language_code_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RecognitionConfig, max_alternatives_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RecognitionConfig, profanity_filter_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RecognitionConfig, speech_context_),
    ~0u,  // no _has_bits_
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(SpeechContext, _internal_metadata_),
    ~0u,  // no _extensions_
    ~0u,  // no _oneof_case_
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(SpeechContext, phrases_),
    ~0u,  // no _has_bits_
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RecognitionAudio, _internal_metadata_),
    ~0u,  // no _extensions_
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RecognitionAudio, _oneof_case_[0]),
    PROTO2_GENERATED_DEFAULT_ONEOF_FIELD_OFFSET((&RecognitionAudio_default_oneof_instance_), content_),
    PROTO2_GENERATED_DEFAULT_ONEOF_FIELD_OFFSET((&RecognitionAudio_default_oneof_instance_), uri_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RecognitionAudio, audio_source_),
    ~0u,  // no _has_bits_
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(SyncRecognizeResponse, _internal_metadata_),
    ~0u,  // no _extensions_
    ~0u,  // no _oneof_case_
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(SyncRecognizeResponse, results_),
    ~0u,  // no _has_bits_
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(AsyncRecognizeResponse, _internal_metadata_),
    ~0u,  // no _extensions_
    ~0u,  // no _oneof_case_
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(AsyncRecognizeResponse, results_),
    ~0u,  // no _has_bits_
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(AsyncRecognizeMetadata, _internal_metadata_),
    ~0u,  // no _extensions_
    ~0u,  // no _oneof_case_
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(AsyncRecognizeMetadata, progress_percent_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(AsyncRecognizeMetadata, start_time_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(AsyncRecognizeMetadata, last_update_time_),
    ~0u,  // no _has_bits_
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(StreamingRecognizeResponse, _internal_metadata_),
    ~0u,  // no _extensions_
    ~0u,  // no _oneof_case_
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(StreamingRecognizeResponse, error_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(StreamingRecognizeResponse, results_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(StreamingRecognizeResponse, result_index_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(StreamingRecognizeResponse, endpointer_type_),
    ~0u,  // no _has_bits_
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(StreamingRecognitionResult, _internal_metadata_),
    ~0u,  // no _extensions_
    ~0u,  // no _oneof_case_
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(StreamingRecognitionResult, alternatives_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(StreamingRecognitionResult, is_final_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(StreamingRecognitionResult, stability_),
    ~0u,  // no _has_bits_
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(SpeechRecognitionResult, _internal_metadata_),
    ~0u,  // no _extensions_
    ~0u,  // no _oneof_case_
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(SpeechRecognitionResult, alternatives_),
    ~0u,  // no _has_bits_
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(SpeechRecognitionAlternative, _internal_metadata_),
    ~0u,  // no _extensions_
    ~0u,  // no _oneof_case_
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(SpeechRecognitionAlternative, transcript_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(SpeechRecognitionAlternative, confidence_),
  };
  return offsets;
}

static const ::google::protobuf::internal::MigrationSchema schemas[] = {
  { 0, -1, sizeof(SyncRecognizeRequest)},
  { 6, -1, sizeof(AsyncRecognizeRequest)},
  { 12, -1, sizeof(StreamingRecognizeRequest)},
  { 19, -1, sizeof(StreamingRecognitionConfig)},
  { 26, -1, sizeof(RecognitionConfig)},
  { 36, -1, sizeof(SpeechContext)},
  { 41, -1, sizeof(RecognitionAudio)},
  { 48, -1, sizeof(SyncRecognizeResponse)},
  { 53, -1, sizeof(AsyncRecognizeResponse)},
  { 58, -1, sizeof(AsyncRecognizeMetadata)},
  { 65, -1, sizeof(StreamingRecognizeResponse)},
  { 73, -1, sizeof(StreamingRecognitionResult)},
  { 80, -1, sizeof(SpeechRecognitionResult)},
  { 85, -1, sizeof(SpeechRecognitionAlternative)},
};

static const ::google::protobuf::internal::DefaultInstanceData file_default_instances[] = {
  {reinterpret_cast<const ::google::protobuf::Message*>(&_SyncRecognizeRequest_default_instance_), NULL},
  {reinterpret_cast<const ::google::protobuf::Message*>(&_AsyncRecognizeRequest_default_instance_), NULL},
  {reinterpret_cast<const ::google::protobuf::Message*>(&_StreamingRecognizeRequest_default_instance_), &StreamingRecognizeRequest_default_oneof_instance_},
  {reinterpret_cast<const ::google::protobuf::Message*>(&_StreamingRecognitionConfig_default_instance_), NULL},
  {reinterpret_cast<const ::google::protobuf::Message*>(&_RecognitionConfig_default_instance_), NULL},
  {reinterpret_cast<const ::google::protobuf::Message*>(&_SpeechContext_default_instance_), NULL},
  {reinterpret_cast<const ::google::protobuf::Message*>(&_RecognitionAudio_default_instance_), &RecognitionAudio_default_oneof_instance_},
  {reinterpret_cast<const ::google::protobuf::Message*>(&_SyncRecognizeResponse_default_instance_), NULL},
  {reinterpret_cast<const ::google::protobuf::Message*>(&_AsyncRecognizeResponse_default_instance_), NULL},
  {reinterpret_cast<const ::google::protobuf::Message*>(&_AsyncRecognizeMetadata_default_instance_), NULL},
  {reinterpret_cast<const ::google::protobuf::Message*>(&_StreamingRecognizeResponse_default_instance_), NULL},
  {reinterpret_cast<const ::google::protobuf::Message*>(&_StreamingRecognitionResult_default_instance_), NULL},
  {reinterpret_cast<const ::google::protobuf::Message*>(&_SpeechRecognitionResult_default_instance_), NULL},
  {reinterpret_cast<const ::google::protobuf::Message*>(&_SpeechRecognitionAlternative_default_instance_), NULL},
};

namespace {

void protobuf_AssignDescriptors() {
  protobuf_AddDesc_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto();
  ::google::protobuf::MessageFactory* factory = NULL;
  AssignDescriptors(
      "google/cloud/speech/v1beta1/cloud_speech.proto", schemas, file_default_instances, protobuf_Offsets_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto(), factory,
      file_level_metadata, file_level_enum_descriptors, NULL);
}

void protobuf_AssignDescriptorsOnce() {
  static GOOGLE_PROTOBUF_DECLARE_ONCE(once);
  ::google::protobuf::GoogleOnceInit(&once, &protobuf_AssignDescriptors);
}

void protobuf_RegisterTypes(const ::std::string&) GOOGLE_ATTRIBUTE_COLD;
void protobuf_RegisterTypes(const ::std::string&) {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::internal::RegisterAllTypes(file_level_metadata, 14);
}

}  // namespace

void protobuf_ShutdownFile_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto() {
  _SyncRecognizeRequest_default_instance_.Shutdown();
  delete file_level_metadata[0].reflection;
  _AsyncRecognizeRequest_default_instance_.Shutdown();
  delete file_level_metadata[1].reflection;
  _StreamingRecognizeRequest_default_instance_.Shutdown();
  delete file_level_metadata[2].reflection;
  _StreamingRecognitionConfig_default_instance_.Shutdown();
  delete file_level_metadata[3].reflection;
  _RecognitionConfig_default_instance_.Shutdown();
  delete file_level_metadata[4].reflection;
  _SpeechContext_default_instance_.Shutdown();
  delete file_level_metadata[5].reflection;
  _RecognitionAudio_default_instance_.Shutdown();
  delete file_level_metadata[6].reflection;
  _SyncRecognizeResponse_default_instance_.Shutdown();
  delete file_level_metadata[7].reflection;
  _AsyncRecognizeResponse_default_instance_.Shutdown();
  delete file_level_metadata[8].reflection;
  _AsyncRecognizeMetadata_default_instance_.Shutdown();
  delete file_level_metadata[9].reflection;
  _StreamingRecognizeResponse_default_instance_.Shutdown();
  delete file_level_metadata[10].reflection;
  _StreamingRecognitionResult_default_instance_.Shutdown();
  delete file_level_metadata[11].reflection;
  _SpeechRecognitionResult_default_instance_.Shutdown();
  delete file_level_metadata[12].reflection;
  _SpeechRecognitionAlternative_default_instance_.Shutdown();
  delete file_level_metadata[13].reflection;
}

void protobuf_InitDefaults_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto_impl() {
  GOOGLE_PROTOBUF_VERIFY_VERSION;

  ::google::api::protobuf_InitDefaults_google_2fapi_2fannotations_2eproto();
  ::google::longrunning::protobuf_InitDefaults_google_2flongrunning_2foperations_2eproto();
  ::google::protobuf::protobuf_InitDefaults_google_2fprotobuf_2ftimestamp_2eproto();
  ::google::rpc::protobuf_InitDefaults_google_2frpc_2fstatus_2eproto();
  ::google::protobuf::internal::InitProtobufDefaults();
  _SyncRecognizeRequest_default_instance_.DefaultConstruct();
  _AsyncRecognizeRequest_default_instance_.DefaultConstruct();
  _StreamingRecognizeRequest_default_instance_.DefaultConstruct();
  _StreamingRecognitionConfig_default_instance_.DefaultConstruct();
  _RecognitionConfig_default_instance_.DefaultConstruct();
  _SpeechContext_default_instance_.DefaultConstruct();
  _RecognitionAudio_default_instance_.DefaultConstruct();
  _SyncRecognizeResponse_default_instance_.DefaultConstruct();
  _AsyncRecognizeResponse_default_instance_.DefaultConstruct();
  _AsyncRecognizeMetadata_default_instance_.DefaultConstruct();
  _StreamingRecognizeResponse_default_instance_.DefaultConstruct();
  _StreamingRecognitionResult_default_instance_.DefaultConstruct();
  _SpeechRecognitionResult_default_instance_.DefaultConstruct();
  _SpeechRecognitionAlternative_default_instance_.DefaultConstruct();
  _SyncRecognizeRequest_default_instance_.get_mutable()->config_ = const_cast< ::google::cloud::speech::v1beta1::RecognitionConfig*>(
      ::google::cloud::speech::v1beta1::RecognitionConfig::internal_default_instance());
  _SyncRecognizeRequest_default_instance_.get_mutable()->audio_ = const_cast< ::google::cloud::speech::v1beta1::RecognitionAudio*>(
      ::google::cloud::speech::v1beta1::RecognitionAudio::internal_default_instance());
  _AsyncRecognizeRequest_default_instance_.get_mutable()->config_ = const_cast< ::google::cloud::speech::v1beta1::RecognitionConfig*>(
      ::google::cloud::speech::v1beta1::RecognitionConfig::internal_default_instance());
  _AsyncRecognizeRequest_default_instance_.get_mutable()->audio_ = const_cast< ::google::cloud::speech::v1beta1::RecognitionAudio*>(
      ::google::cloud::speech::v1beta1::RecognitionAudio::internal_default_instance());
  StreamingRecognizeRequest_default_oneof_instance_.streaming_config_ = const_cast< ::google::cloud::speech::v1beta1::StreamingRecognitionConfig*>(
      ::google::cloud::speech::v1beta1::StreamingRecognitionConfig::internal_default_instance());
  StreamingRecognizeRequest_default_oneof_instance_.audio_content_.UnsafeSetDefault(
      &::google::protobuf::internal::GetEmptyStringAlreadyInited());
  _StreamingRecognitionConfig_default_instance_.get_mutable()->config_ = const_cast< ::google::cloud::speech::v1beta1::RecognitionConfig*>(
      ::google::cloud::speech::v1beta1::RecognitionConfig::internal_default_instance());
  _RecognitionConfig_default_instance_.get_mutable()->speech_context_ = const_cast< ::google::cloud::speech::v1beta1::SpeechContext*>(
      ::google::cloud::speech::v1beta1::SpeechContext::internal_default_instance());
  RecognitionAudio_default_oneof_instance_.content_.UnsafeSetDefault(
      &::google::protobuf::internal::GetEmptyStringAlreadyInited());
  RecognitionAudio_default_oneof_instance_.uri_.UnsafeSetDefault(
      &::google::protobuf::internal::GetEmptyStringAlreadyInited());
  _AsyncRecognizeMetadata_default_instance_.get_mutable()->start_time_ = const_cast< ::google::protobuf::Timestamp*>(
      ::google::protobuf::Timestamp::internal_default_instance());
  _AsyncRecognizeMetadata_default_instance_.get_mutable()->last_update_time_ = const_cast< ::google::protobuf::Timestamp*>(
      ::google::protobuf::Timestamp::internal_default_instance());
  _StreamingRecognizeResponse_default_instance_.get_mutable()->error_ = const_cast< ::google::rpc::Status*>(
      ::google::rpc::Status::internal_default_instance());
}

void protobuf_InitDefaults_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto() {
  static GOOGLE_PROTOBUF_DECLARE_ONCE(once);
  ::google::protobuf::GoogleOnceInit(&once, &protobuf_InitDefaults_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto_impl);
}
void protobuf_AddDesc_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto_impl() {
  protobuf_InitDefaults_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto();
  static const char descriptor[] = {
      "\n.google/cloud/speech/v1beta1/cloud_spee"
      "ch.proto\022\033google.cloud.speech.v1beta1\032\034g"
      "oogle/api/annotations.proto\032#google/long"
      "running/operations.proto\032\037google/protobu"
      "f/timestamp.proto\032\027google/rpc/status.pro"
      "to\"\224\001\n\024SyncRecognizeRequest\022>\n\006config\030\001 "
      "\001(\0132..google.cloud.speech.v1beta1.Recogn"
      "itionConfig\022<\n\005audio\030\002 \001(\0132-.google.clou"
      "d.speech.v1beta1.RecognitionAudio\"\225\001\n\025As"
      "yncRecognizeRequest\022>\n\006config\030\001 \001(\0132..go"
      "ogle.cloud.speech.v1beta1.RecognitionCon"
      "fig\022<\n\005audio\030\002 \001(\0132-.google.cloud.speech"
      ".v1beta1.RecognitionAudio\"\236\001\n\031StreamingR"
      "ecognizeRequest\022S\n\020streaming_config\030\001 \001("
      "\01327.google.cloud.speech.v1beta1.Streamin"
      "gRecognitionConfigH\000\022\027\n\raudio_content\030\002 "
      "\001(\014H\000B\023\n\021streaming_request\"\217\001\n\032Streaming"
      "RecognitionConfig\022>\n\006config\030\001 \001(\0132..goog"
      "le.cloud.speech.v1beta1.RecognitionConfi"
      "g\022\030\n\020single_utterance\030\002 \001(\010\022\027\n\017interim_r"
      "esults\030\003 \001(\010\"\352\002\n\021RecognitionConfig\022N\n\010en"
      "coding\030\001 \001(\0162<.google.cloud.speech.v1bet"
      "a1.RecognitionConfig.AudioEncoding\022\023\n\013sa"
      "mple_rate\030\002 \001(\005\022\025\n\rlanguage_code\030\003 \001(\t\022\030"
      "\n\020max_alternatives\030\004 \001(\005\022\030\n\020profanity_fi"
      "lter\030\005 \001(\010\022B\n\016speech_context\030\006 \001(\0132*.goo"
      "gle.cloud.speech.v1beta1.SpeechContext\"a"
      "\n\rAudioEncoding\022\030\n\024ENCODING_UNSPECIFIED\020"
      "\000\022\014\n\010LINEAR16\020\001\022\010\n\004FLAC\020\002\022\t\n\005MULAW\020\003\022\007\n\003"
      "AMR\020\004\022\n\n\006AMR_WB\020\005\" \n\rSpeechContext\022\017\n\007ph"
      "rases\030\001 \003(\t\"D\n\020RecognitionAudio\022\021\n\007conte"
      "nt\030\001 \001(\014H\000\022\r\n\003uri\030\002 \001(\tH\000B\016\n\014audio_sourc"
      "e\"^\n\025SyncRecognizeResponse\022E\n\007results\030\002 "
      "\003(\01324.google.cloud.speech.v1beta1.Speech"
      "RecognitionResult\"_\n\026AsyncRecognizeRespo"
      "nse\022E\n\007results\030\002 \003(\01324.google.cloud.spee"
      "ch.v1beta1.SpeechRecognitionResult\"\230\001\n\026A"
      "syncRecognizeMetadata\022\030\n\020progress_percen"
      "t\030\001 \001(\005\022.\n\nstart_time\030\002 \001(\0132\032.google.pro"
      "tobuf.Timestamp\0224\n\020last_update_time\030\003 \001("
      "\0132\032.google.protobuf.Timestamp\"\205\003\n\032Stream"
      "ingRecognizeResponse\022!\n\005error\030\001 \001(\0132\022.go"
      "ogle.rpc.Status\022H\n\007results\030\002 \003(\01327.googl"
      "e.cloud.speech.v1beta1.StreamingRecognit"
      "ionResult\022\024\n\014result_index\030\003 \001(\005\022_\n\017endpo"
      "inter_type\030\004 \001(\0162F.google.cloud.speech.v"
      "1beta1.StreamingRecognizeResponse.Endpoi"
      "nterType\"\202\001\n\016EndpointerType\022 \n\034ENDPOINTE"
      "R_EVENT_UNSPECIFIED\020\000\022\023\n\017START_OF_SPEECH"
      "\020\001\022\021\n\rEND_OF_SPEECH\020\002\022\020\n\014END_OF_AUDIO\020\003\022"
      "\024\n\020END_OF_UTTERANCE\020\004\"\222\001\n\032StreamingRecog"
      "nitionResult\022O\n\014alternatives\030\001 \003(\01329.goo"
      "gle.cloud.speech.v1beta1.SpeechRecogniti"
      "onAlternative\022\020\n\010is_final\030\002 \001(\010\022\021\n\tstabi"
      "lity\030\003 \001(\002\"j\n\027SpeechRecognitionResult\022O\n"
      "\014alternatives\030\001 \003(\01329.google.cloud.speec"
      "h.v1beta1.SpeechRecognitionAlternative\"F"
      "\n\034SpeechRecognitionAlternative\022\022\n\ntransc"
      "ript\030\001 \001(\t\022\022\n\nconfidence\030\002 \001(\0022\310\003\n\006Speec"
      "h\022\240\001\n\rSyncRecognize\0221.google.cloud.speec"
      "h.v1beta1.SyncRecognizeRequest\0322.google."
      "cloud.speech.v1beta1.SyncRecognizeRespon"
      "se\"(\202\323\344\223\002\"\"\035/v1beta1/speech:syncrecogniz"
      "e:\001*\022\216\001\n\016AsyncRecognize\0222.google.cloud.s"
      "peech.v1beta1.AsyncRecognizeRequest\032\035.go"
      "ogle.longrunning.Operation\")\202\323\344\223\002#\"\036/v1b"
      "eta1/speech:asyncrecognize:\001*\022\211\001\n\022Stream"
      "ingRecognize\0226.google.cloud.speech.v1bet"
      "a1.StreamingRecognizeRequest\0327.google.cl"
      "oud.speech.v1beta1.StreamingRecognizeRes"
      "ponse(\0010\001B0\n\037com.google.cloud.speech.v1b"
      "eta1B\013SpeechProtoP\001b\006proto3"
  };
  ::google::protobuf::DescriptorPool::InternalAddGeneratedFile(
      descriptor, 2867);
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedFile(
    "google/cloud/speech/v1beta1/cloud_speech.proto", &protobuf_RegisterTypes);
  ::google::api::protobuf_AddDesc_google_2fapi_2fannotations_2eproto();
  ::google::longrunning::protobuf_AddDesc_google_2flongrunning_2foperations_2eproto();
  ::google::protobuf::protobuf_AddDesc_google_2fprotobuf_2ftimestamp_2eproto();
  ::google::rpc::protobuf_AddDesc_google_2frpc_2fstatus_2eproto();
  ::google::protobuf::internal::OnShutdown(&protobuf_ShutdownFile_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto);
}

GOOGLE_PROTOBUF_DECLARE_ONCE(protobuf_AddDesc_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto_once_);
void protobuf_AddDesc_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto() {
  ::google::protobuf::GoogleOnceInit(&protobuf_AddDesc_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto_once_,
                 &protobuf_AddDesc_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto_impl);
}
// Force AddDescriptors() to be called at static initialization time.
struct StaticDescriptorInitializer_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto {
  StaticDescriptorInitializer_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto() {
    protobuf_AddDesc_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto();
  }
} static_descriptor_initializer_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto_;
const ::google::protobuf::EnumDescriptor* RecognitionConfig_AudioEncoding_descriptor() {
  protobuf_AssignDescriptorsOnce();
  return file_level_enum_descriptors[0];
}
bool RecognitionConfig_AudioEncoding_IsValid(int value) {
  switch (value) {
    case 0:
    case 1:
    case 2:
    case 3:
    case 4:
    case 5:
      return true;
    default:
      return false;
  }
}

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const RecognitionConfig_AudioEncoding RecognitionConfig::ENCODING_UNSPECIFIED;
const RecognitionConfig_AudioEncoding RecognitionConfig::LINEAR16;
const RecognitionConfig_AudioEncoding RecognitionConfig::FLAC;
const RecognitionConfig_AudioEncoding RecognitionConfig::MULAW;
const RecognitionConfig_AudioEncoding RecognitionConfig::AMR;
const RecognitionConfig_AudioEncoding RecognitionConfig::AMR_WB;
const RecognitionConfig_AudioEncoding RecognitionConfig::AudioEncoding_MIN;
const RecognitionConfig_AudioEncoding RecognitionConfig::AudioEncoding_MAX;
const int RecognitionConfig::AudioEncoding_ARRAYSIZE;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900
const ::google::protobuf::EnumDescriptor* StreamingRecognizeResponse_EndpointerType_descriptor() {
  protobuf_AssignDescriptorsOnce();
  return file_level_enum_descriptors[1];
}
bool StreamingRecognizeResponse_EndpointerType_IsValid(int value) {
  switch (value) {
    case 0:
    case 1:
    case 2:
    case 3:
    case 4:
      return true;
    default:
      return false;
  }
}

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const StreamingRecognizeResponse_EndpointerType StreamingRecognizeResponse::ENDPOINTER_EVENT_UNSPECIFIED;
const StreamingRecognizeResponse_EndpointerType StreamingRecognizeResponse::START_OF_SPEECH;
const StreamingRecognizeResponse_EndpointerType StreamingRecognizeResponse::END_OF_SPEECH;
const StreamingRecognizeResponse_EndpointerType StreamingRecognizeResponse::END_OF_AUDIO;
const StreamingRecognizeResponse_EndpointerType StreamingRecognizeResponse::END_OF_UTTERANCE;
const StreamingRecognizeResponse_EndpointerType StreamingRecognizeResponse::EndpointerType_MIN;
const StreamingRecognizeResponse_EndpointerType StreamingRecognizeResponse::EndpointerType_MAX;
const int StreamingRecognizeResponse::EndpointerType_ARRAYSIZE;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int SyncRecognizeRequest::kConfigFieldNumber;
const int SyncRecognizeRequest::kAudioFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

SyncRecognizeRequest::SyncRecognizeRequest()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  if (GOOGLE_PREDICT_TRUE(this != internal_default_instance())) {
    protobuf_InitDefaults_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto();
  }
  SharedCtor();
  // @@protoc_insertion_point(constructor:google.cloud.speech.v1beta1.SyncRecognizeRequest)
}
SyncRecognizeRequest::SyncRecognizeRequest(const SyncRecognizeRequest& from)
  : ::google::protobuf::Message(),
      _internal_metadata_(NULL),
      _cached_size_(0) {
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  if (from.has_config()) {
    config_ = new ::google::cloud::speech::v1beta1::RecognitionConfig(*from.config_);
  } else {
    config_ = NULL;
  }
  if (from.has_audio()) {
    audio_ = new ::google::cloud::speech::v1beta1::RecognitionAudio(*from.audio_);
  } else {
    audio_ = NULL;
  }
  // @@protoc_insertion_point(copy_constructor:google.cloud.speech.v1beta1.SyncRecognizeRequest)
}

void SyncRecognizeRequest::SharedCtor() {
  ::memset(&config_, 0, reinterpret_cast<char*>(&audio_) -
    reinterpret_cast<char*>(&config_) + sizeof(audio_));
  _cached_size_ = 0;
}

SyncRecognizeRequest::~SyncRecognizeRequest() {
  // @@protoc_insertion_point(destructor:google.cloud.speech.v1beta1.SyncRecognizeRequest)
  SharedDtor();
}

void SyncRecognizeRequest::SharedDtor() {
  if (this != internal_default_instance()) {
    delete config_;
  }
  if (this != internal_default_instance()) {
    delete audio_;
  }
}

void SyncRecognizeRequest::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* SyncRecognizeRequest::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return file_level_metadata[0].descriptor;
}

const SyncRecognizeRequest& SyncRecognizeRequest::default_instance() {
  protobuf_InitDefaults_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto();
  return *internal_default_instance();
}

SyncRecognizeRequest* SyncRecognizeRequest::New(::google::protobuf::Arena* arena) const {
  SyncRecognizeRequest* n = new SyncRecognizeRequest;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void SyncRecognizeRequest::Clear() {
// @@protoc_insertion_point(message_clear_start:google.cloud.speech.v1beta1.SyncRecognizeRequest)
  if (GetArenaNoVirtual() == NULL && config_ != NULL) {
    delete config_;
  }
  config_ = NULL;
  if (GetArenaNoVirtual() == NULL && audio_ != NULL) {
    delete audio_;
  }
  audio_ = NULL;
}

bool SyncRecognizeRequest::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:google.cloud.speech.v1beta1.SyncRecognizeRequest)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoffNoLastTag(127u);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // .google.cloud.speech.v1beta1.RecognitionConfig config = 1;
      case 1: {
        if (tag == 10u) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_config()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // .google.cloud.speech.v1beta1.RecognitionAudio audio = 2;
      case 2: {
        if (tag == 18u) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_audio()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:google.cloud.speech.v1beta1.SyncRecognizeRequest)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:google.cloud.speech.v1beta1.SyncRecognizeRequest)
  return false;
#undef DO_
}

void SyncRecognizeRequest::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:google.cloud.speech.v1beta1.SyncRecognizeRequest)
  // .google.cloud.speech.v1beta1.RecognitionConfig config = 1;
  if (this->has_config()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, *this->config_, output);
  }

  // .google.cloud.speech.v1beta1.RecognitionAudio audio = 2;
  if (this->has_audio()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      2, *this->audio_, output);
  }

  // @@protoc_insertion_point(serialize_end:google.cloud.speech.v1beta1.SyncRecognizeRequest)
}

::google::protobuf::uint8* SyncRecognizeRequest::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  (void)deterministic; // Unused
  // @@protoc_insertion_point(serialize_to_array_start:google.cloud.speech.v1beta1.SyncRecognizeRequest)
  // .google.cloud.speech.v1beta1.RecognitionConfig config = 1;
  if (this->has_config()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        1, *this->config_, false, target);
  }

  // .google.cloud.speech.v1beta1.RecognitionAudio audio = 2;
  if (this->has_audio()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        2, *this->audio_, false, target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:google.cloud.speech.v1beta1.SyncRecognizeRequest)
  return target;
}

size_t SyncRecognizeRequest::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:google.cloud.speech.v1beta1.SyncRecognizeRequest)
  size_t total_size = 0;

  // .google.cloud.speech.v1beta1.RecognitionConfig config = 1;
  if (this->has_config()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->config_);
  }

  // .google.cloud.speech.v1beta1.RecognitionAudio audio = 2;
  if (this->has_audio()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->audio_);
  }

  int cached_size = ::google::protobuf::internal::ToCachedSize(total_size);
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = cached_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void SyncRecognizeRequest::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:google.cloud.speech.v1beta1.SyncRecognizeRequest)
  GOOGLE_DCHECK_NE(&from, this);
  const SyncRecognizeRequest* source =
      ::google::protobuf::internal::DynamicCastToGenerated<const SyncRecognizeRequest>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:google.cloud.speech.v1beta1.SyncRecognizeRequest)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:google.cloud.speech.v1beta1.SyncRecognizeRequest)
    MergeFrom(*source);
  }
}

void SyncRecognizeRequest::MergeFrom(const SyncRecognizeRequest& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:google.cloud.speech.v1beta1.SyncRecognizeRequest)
  GOOGLE_DCHECK_NE(&from, this);
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  if (from.has_config()) {
    mutable_config()->::google::cloud::speech::v1beta1::RecognitionConfig::MergeFrom(from.config());
  }
  if (from.has_audio()) {
    mutable_audio()->::google::cloud::speech::v1beta1::RecognitionAudio::MergeFrom(from.audio());
  }
}

void SyncRecognizeRequest::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:google.cloud.speech.v1beta1.SyncRecognizeRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void SyncRecognizeRequest::CopyFrom(const SyncRecognizeRequest& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:google.cloud.speech.v1beta1.SyncRecognizeRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool SyncRecognizeRequest::IsInitialized() const {
  return true;
}

void SyncRecognizeRequest::Swap(SyncRecognizeRequest* other) {
  if (other == this) return;
  InternalSwap(other);
}
void SyncRecognizeRequest::InternalSwap(SyncRecognizeRequest* other) {
  std::swap(config_, other->config_);
  std::swap(audio_, other->audio_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata SyncRecognizeRequest::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  return file_level_metadata[0];
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// SyncRecognizeRequest

// .google.cloud.speech.v1beta1.RecognitionConfig config = 1;
bool SyncRecognizeRequest::has_config() const {
  return this != internal_default_instance() && config_ != NULL;
}
void SyncRecognizeRequest::clear_config() {
  if (GetArenaNoVirtual() == NULL && config_ != NULL) delete config_;
  config_ = NULL;
}
const ::google::cloud::speech::v1beta1::RecognitionConfig& SyncRecognizeRequest::config() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.SyncRecognizeRequest.config)
  return config_ != NULL ? *config_
                         : *::google::cloud::speech::v1beta1::RecognitionConfig::internal_default_instance();
}
::google::cloud::speech::v1beta1::RecognitionConfig* SyncRecognizeRequest::mutable_config() {
  
  if (config_ == NULL) {
    config_ = new ::google::cloud::speech::v1beta1::RecognitionConfig;
  }
  // @@protoc_insertion_point(field_mutable:google.cloud.speech.v1beta1.SyncRecognizeRequest.config)
  return config_;
}
::google::cloud::speech::v1beta1::RecognitionConfig* SyncRecognizeRequest::release_config() {
  // @@protoc_insertion_point(field_release:google.cloud.speech.v1beta1.SyncRecognizeRequest.config)
  
  ::google::cloud::speech::v1beta1::RecognitionConfig* temp = config_;
  config_ = NULL;
  return temp;
}
void SyncRecognizeRequest::set_allocated_config(::google::cloud::speech::v1beta1::RecognitionConfig* config) {
  delete config_;
  config_ = config;
  if (config) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:google.cloud.speech.v1beta1.SyncRecognizeRequest.config)
}

// .google.cloud.speech.v1beta1.RecognitionAudio audio = 2;
bool SyncRecognizeRequest::has_audio() const {
  return this != internal_default_instance() && audio_ != NULL;
}
void SyncRecognizeRequest::clear_audio() {
  if (GetArenaNoVirtual() == NULL && audio_ != NULL) delete audio_;
  audio_ = NULL;
}
const ::google::cloud::speech::v1beta1::RecognitionAudio& SyncRecognizeRequest::audio() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.SyncRecognizeRequest.audio)
  return audio_ != NULL ? *audio_
                         : *::google::cloud::speech::v1beta1::RecognitionAudio::internal_default_instance();
}
::google::cloud::speech::v1beta1::RecognitionAudio* SyncRecognizeRequest::mutable_audio() {
  
  if (audio_ == NULL) {
    audio_ = new ::google::cloud::speech::v1beta1::RecognitionAudio;
  }
  // @@protoc_insertion_point(field_mutable:google.cloud.speech.v1beta1.SyncRecognizeRequest.audio)
  return audio_;
}
::google::cloud::speech::v1beta1::RecognitionAudio* SyncRecognizeRequest::release_audio() {
  // @@protoc_insertion_point(field_release:google.cloud.speech.v1beta1.SyncRecognizeRequest.audio)
  
  ::google::cloud::speech::v1beta1::RecognitionAudio* temp = audio_;
  audio_ = NULL;
  return temp;
}
void SyncRecognizeRequest::set_allocated_audio(::google::cloud::speech::v1beta1::RecognitionAudio* audio) {
  delete audio_;
  audio_ = audio;
  if (audio) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:google.cloud.speech.v1beta1.SyncRecognizeRequest.audio)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int AsyncRecognizeRequest::kConfigFieldNumber;
const int AsyncRecognizeRequest::kAudioFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

AsyncRecognizeRequest::AsyncRecognizeRequest()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  if (GOOGLE_PREDICT_TRUE(this != internal_default_instance())) {
    protobuf_InitDefaults_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto();
  }
  SharedCtor();
  // @@protoc_insertion_point(constructor:google.cloud.speech.v1beta1.AsyncRecognizeRequest)
}
AsyncRecognizeRequest::AsyncRecognizeRequest(const AsyncRecognizeRequest& from)
  : ::google::protobuf::Message(),
      _internal_metadata_(NULL),
      _cached_size_(0) {
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  if (from.has_config()) {
    config_ = new ::google::cloud::speech::v1beta1::RecognitionConfig(*from.config_);
  } else {
    config_ = NULL;
  }
  if (from.has_audio()) {
    audio_ = new ::google::cloud::speech::v1beta1::RecognitionAudio(*from.audio_);
  } else {
    audio_ = NULL;
  }
  // @@protoc_insertion_point(copy_constructor:google.cloud.speech.v1beta1.AsyncRecognizeRequest)
}

void AsyncRecognizeRequest::SharedCtor() {
  ::memset(&config_, 0, reinterpret_cast<char*>(&audio_) -
    reinterpret_cast<char*>(&config_) + sizeof(audio_));
  _cached_size_ = 0;
}

AsyncRecognizeRequest::~AsyncRecognizeRequest() {
  // @@protoc_insertion_point(destructor:google.cloud.speech.v1beta1.AsyncRecognizeRequest)
  SharedDtor();
}

void AsyncRecognizeRequest::SharedDtor() {
  if (this != internal_default_instance()) {
    delete config_;
  }
  if (this != internal_default_instance()) {
    delete audio_;
  }
}

void AsyncRecognizeRequest::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* AsyncRecognizeRequest::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return file_level_metadata[1].descriptor;
}

const AsyncRecognizeRequest& AsyncRecognizeRequest::default_instance() {
  protobuf_InitDefaults_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto();
  return *internal_default_instance();
}

AsyncRecognizeRequest* AsyncRecognizeRequest::New(::google::protobuf::Arena* arena) const {
  AsyncRecognizeRequest* n = new AsyncRecognizeRequest;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void AsyncRecognizeRequest::Clear() {
// @@protoc_insertion_point(message_clear_start:google.cloud.speech.v1beta1.AsyncRecognizeRequest)
  if (GetArenaNoVirtual() == NULL && config_ != NULL) {
    delete config_;
  }
  config_ = NULL;
  if (GetArenaNoVirtual() == NULL && audio_ != NULL) {
    delete audio_;
  }
  audio_ = NULL;
}

bool AsyncRecognizeRequest::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:google.cloud.speech.v1beta1.AsyncRecognizeRequest)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoffNoLastTag(127u);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // .google.cloud.speech.v1beta1.RecognitionConfig config = 1;
      case 1: {
        if (tag == 10u) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_config()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // .google.cloud.speech.v1beta1.RecognitionAudio audio = 2;
      case 2: {
        if (tag == 18u) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_audio()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:google.cloud.speech.v1beta1.AsyncRecognizeRequest)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:google.cloud.speech.v1beta1.AsyncRecognizeRequest)
  return false;
#undef DO_
}

void AsyncRecognizeRequest::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:google.cloud.speech.v1beta1.AsyncRecognizeRequest)
  // .google.cloud.speech.v1beta1.RecognitionConfig config = 1;
  if (this->has_config()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, *this->config_, output);
  }

  // .google.cloud.speech.v1beta1.RecognitionAudio audio = 2;
  if (this->has_audio()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      2, *this->audio_, output);
  }

  // @@protoc_insertion_point(serialize_end:google.cloud.speech.v1beta1.AsyncRecognizeRequest)
}

::google::protobuf::uint8* AsyncRecognizeRequest::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  (void)deterministic; // Unused
  // @@protoc_insertion_point(serialize_to_array_start:google.cloud.speech.v1beta1.AsyncRecognizeRequest)
  // .google.cloud.speech.v1beta1.RecognitionConfig config = 1;
  if (this->has_config()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        1, *this->config_, false, target);
  }

  // .google.cloud.speech.v1beta1.RecognitionAudio audio = 2;
  if (this->has_audio()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        2, *this->audio_, false, target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:google.cloud.speech.v1beta1.AsyncRecognizeRequest)
  return target;
}

size_t AsyncRecognizeRequest::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:google.cloud.speech.v1beta1.AsyncRecognizeRequest)
  size_t total_size = 0;

  // .google.cloud.speech.v1beta1.RecognitionConfig config = 1;
  if (this->has_config()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->config_);
  }

  // .google.cloud.speech.v1beta1.RecognitionAudio audio = 2;
  if (this->has_audio()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->audio_);
  }

  int cached_size = ::google::protobuf::internal::ToCachedSize(total_size);
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = cached_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void AsyncRecognizeRequest::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:google.cloud.speech.v1beta1.AsyncRecognizeRequest)
  GOOGLE_DCHECK_NE(&from, this);
  const AsyncRecognizeRequest* source =
      ::google::protobuf::internal::DynamicCastToGenerated<const AsyncRecognizeRequest>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:google.cloud.speech.v1beta1.AsyncRecognizeRequest)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:google.cloud.speech.v1beta1.AsyncRecognizeRequest)
    MergeFrom(*source);
  }
}

void AsyncRecognizeRequest::MergeFrom(const AsyncRecognizeRequest& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:google.cloud.speech.v1beta1.AsyncRecognizeRequest)
  GOOGLE_DCHECK_NE(&from, this);
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  if (from.has_config()) {
    mutable_config()->::google::cloud::speech::v1beta1::RecognitionConfig::MergeFrom(from.config());
  }
  if (from.has_audio()) {
    mutable_audio()->::google::cloud::speech::v1beta1::RecognitionAudio::MergeFrom(from.audio());
  }
}

void AsyncRecognizeRequest::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:google.cloud.speech.v1beta1.AsyncRecognizeRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void AsyncRecognizeRequest::CopyFrom(const AsyncRecognizeRequest& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:google.cloud.speech.v1beta1.AsyncRecognizeRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool AsyncRecognizeRequest::IsInitialized() const {
  return true;
}

void AsyncRecognizeRequest::Swap(AsyncRecognizeRequest* other) {
  if (other == this) return;
  InternalSwap(other);
}
void AsyncRecognizeRequest::InternalSwap(AsyncRecognizeRequest* other) {
  std::swap(config_, other->config_);
  std::swap(audio_, other->audio_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata AsyncRecognizeRequest::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  return file_level_metadata[1];
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// AsyncRecognizeRequest

// .google.cloud.speech.v1beta1.RecognitionConfig config = 1;
bool AsyncRecognizeRequest::has_config() const {
  return this != internal_default_instance() && config_ != NULL;
}
void AsyncRecognizeRequest::clear_config() {
  if (GetArenaNoVirtual() == NULL && config_ != NULL) delete config_;
  config_ = NULL;
}
const ::google::cloud::speech::v1beta1::RecognitionConfig& AsyncRecognizeRequest::config() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.AsyncRecognizeRequest.config)
  return config_ != NULL ? *config_
                         : *::google::cloud::speech::v1beta1::RecognitionConfig::internal_default_instance();
}
::google::cloud::speech::v1beta1::RecognitionConfig* AsyncRecognizeRequest::mutable_config() {
  
  if (config_ == NULL) {
    config_ = new ::google::cloud::speech::v1beta1::RecognitionConfig;
  }
  // @@protoc_insertion_point(field_mutable:google.cloud.speech.v1beta1.AsyncRecognizeRequest.config)
  return config_;
}
::google::cloud::speech::v1beta1::RecognitionConfig* AsyncRecognizeRequest::release_config() {
  // @@protoc_insertion_point(field_release:google.cloud.speech.v1beta1.AsyncRecognizeRequest.config)
  
  ::google::cloud::speech::v1beta1::RecognitionConfig* temp = config_;
  config_ = NULL;
  return temp;
}
void AsyncRecognizeRequest::set_allocated_config(::google::cloud::speech::v1beta1::RecognitionConfig* config) {
  delete config_;
  config_ = config;
  if (config) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:google.cloud.speech.v1beta1.AsyncRecognizeRequest.config)
}

// .google.cloud.speech.v1beta1.RecognitionAudio audio = 2;
bool AsyncRecognizeRequest::has_audio() const {
  return this != internal_default_instance() && audio_ != NULL;
}
void AsyncRecognizeRequest::clear_audio() {
  if (GetArenaNoVirtual() == NULL && audio_ != NULL) delete audio_;
  audio_ = NULL;
}
const ::google::cloud::speech::v1beta1::RecognitionAudio& AsyncRecognizeRequest::audio() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.AsyncRecognizeRequest.audio)
  return audio_ != NULL ? *audio_
                         : *::google::cloud::speech::v1beta1::RecognitionAudio::internal_default_instance();
}
::google::cloud::speech::v1beta1::RecognitionAudio* AsyncRecognizeRequest::mutable_audio() {
  
  if (audio_ == NULL) {
    audio_ = new ::google::cloud::speech::v1beta1::RecognitionAudio;
  }
  // @@protoc_insertion_point(field_mutable:google.cloud.speech.v1beta1.AsyncRecognizeRequest.audio)
  return audio_;
}
::google::cloud::speech::v1beta1::RecognitionAudio* AsyncRecognizeRequest::release_audio() {
  // @@protoc_insertion_point(field_release:google.cloud.speech.v1beta1.AsyncRecognizeRequest.audio)
  
  ::google::cloud::speech::v1beta1::RecognitionAudio* temp = audio_;
  audio_ = NULL;
  return temp;
}
void AsyncRecognizeRequest::set_allocated_audio(::google::cloud::speech::v1beta1::RecognitionAudio* audio) {
  delete audio_;
  audio_ = audio;
  if (audio) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:google.cloud.speech.v1beta1.AsyncRecognizeRequest.audio)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int StreamingRecognizeRequest::kStreamingConfigFieldNumber;
const int StreamingRecognizeRequest::kAudioContentFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

StreamingRecognizeRequest::StreamingRecognizeRequest()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  if (GOOGLE_PREDICT_TRUE(this != internal_default_instance())) {
    protobuf_InitDefaults_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto();
  }
  SharedCtor();
  // @@protoc_insertion_point(constructor:google.cloud.speech.v1beta1.StreamingRecognizeRequest)
}
StreamingRecognizeRequest::StreamingRecognizeRequest(const StreamingRecognizeRequest& from)
  : ::google::protobuf::Message(),
      _internal_metadata_(NULL),
      _cached_size_(0) {
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  clear_has_streaming_request();
  switch (from.streaming_request_case()) {
    case kStreamingConfig: {
      mutable_streaming_config()->::google::cloud::speech::v1beta1::StreamingRecognitionConfig::MergeFrom(from.streaming_config());
      break;
    }
    case kAudioContent: {
      set_audio_content(from.audio_content());
      break;
    }
    case STREAMING_REQUEST_NOT_SET: {
      break;
    }
  }
  // @@protoc_insertion_point(copy_constructor:google.cloud.speech.v1beta1.StreamingRecognizeRequest)
}

void StreamingRecognizeRequest::SharedCtor() {
  clear_has_streaming_request();
  _cached_size_ = 0;
}

StreamingRecognizeRequest::~StreamingRecognizeRequest() {
  // @@protoc_insertion_point(destructor:google.cloud.speech.v1beta1.StreamingRecognizeRequest)
  SharedDtor();
}

void StreamingRecognizeRequest::SharedDtor() {
  if (has_streaming_request()) {
    clear_streaming_request();
  }
}

void StreamingRecognizeRequest::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* StreamingRecognizeRequest::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return file_level_metadata[2].descriptor;
}

const StreamingRecognizeRequest& StreamingRecognizeRequest::default_instance() {
  protobuf_InitDefaults_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto();
  return *internal_default_instance();
}

StreamingRecognizeRequest* StreamingRecognizeRequest::New(::google::protobuf::Arena* arena) const {
  StreamingRecognizeRequest* n = new StreamingRecognizeRequest;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void StreamingRecognizeRequest::clear_streaming_request() {
// @@protoc_insertion_point(one_of_clear_start:google.cloud.speech.v1beta1.StreamingRecognizeRequest)
  switch (streaming_request_case()) {
    case kStreamingConfig: {
      delete streaming_request_.streaming_config_;
      break;
    }
    case kAudioContent: {
      streaming_request_.audio_content_.DestroyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
      break;
    }
    case STREAMING_REQUEST_NOT_SET: {
      break;
    }
  }
  _oneof_case_[0] = STREAMING_REQUEST_NOT_SET;
}


void StreamingRecognizeRequest::Clear() {
// @@protoc_insertion_point(message_clear_start:google.cloud.speech.v1beta1.StreamingRecognizeRequest)
  clear_streaming_request();
}

bool StreamingRecognizeRequest::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:google.cloud.speech.v1beta1.StreamingRecognizeRequest)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoffNoLastTag(127u);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // .google.cloud.speech.v1beta1.StreamingRecognitionConfig streaming_config = 1;
      case 1: {
        if (tag == 10u) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_streaming_config()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // bytes audio_content = 2;
      case 2: {
        if (tag == 18u) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadBytes(
                input, this->mutable_audio_content()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:google.cloud.speech.v1beta1.StreamingRecognizeRequest)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:google.cloud.speech.v1beta1.StreamingRecognizeRequest)
  return false;
#undef DO_
}

void StreamingRecognizeRequest::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:google.cloud.speech.v1beta1.StreamingRecognizeRequest)
  // .google.cloud.speech.v1beta1.StreamingRecognitionConfig streaming_config = 1;
  if (has_streaming_config()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, *streaming_request_.streaming_config_, output);
  }

  // bytes audio_content = 2;
  if (has_audio_content()) {
    ::google::protobuf::internal::WireFormatLite::WriteBytesMaybeAliased(
      2, this->audio_content(), output);
  }

  // @@protoc_insertion_point(serialize_end:google.cloud.speech.v1beta1.StreamingRecognizeRequest)
}

::google::protobuf::uint8* StreamingRecognizeRequest::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  (void)deterministic; // Unused
  // @@protoc_insertion_point(serialize_to_array_start:google.cloud.speech.v1beta1.StreamingRecognizeRequest)
  // .google.cloud.speech.v1beta1.StreamingRecognitionConfig streaming_config = 1;
  if (has_streaming_config()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        1, *streaming_request_.streaming_config_, false, target);
  }

  // bytes audio_content = 2;
  if (has_audio_content()) {
    target =
      ::google::protobuf::internal::WireFormatLite::WriteBytesToArray(
        2, this->audio_content(), target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:google.cloud.speech.v1beta1.StreamingRecognizeRequest)
  return target;
}

size_t StreamingRecognizeRequest::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:google.cloud.speech.v1beta1.StreamingRecognizeRequest)
  size_t total_size = 0;

  switch (streaming_request_case()) {
    // .google.cloud.speech.v1beta1.StreamingRecognitionConfig streaming_config = 1;
    case kStreamingConfig: {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
          *streaming_request_.streaming_config_);
      break;
    }
    // bytes audio_content = 2;
    case kAudioContent: {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::BytesSize(
          this->audio_content());
      break;
    }
    case STREAMING_REQUEST_NOT_SET: {
      break;
    }
  }
  int cached_size = ::google::protobuf::internal::ToCachedSize(total_size);
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = cached_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void StreamingRecognizeRequest::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:google.cloud.speech.v1beta1.StreamingRecognizeRequest)
  GOOGLE_DCHECK_NE(&from, this);
  const StreamingRecognizeRequest* source =
      ::google::protobuf::internal::DynamicCastToGenerated<const StreamingRecognizeRequest>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:google.cloud.speech.v1beta1.StreamingRecognizeRequest)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:google.cloud.speech.v1beta1.StreamingRecognizeRequest)
    MergeFrom(*source);
  }
}

void StreamingRecognizeRequest::MergeFrom(const StreamingRecognizeRequest& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:google.cloud.speech.v1beta1.StreamingRecognizeRequest)
  GOOGLE_DCHECK_NE(&from, this);
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  switch (from.streaming_request_case()) {
    case kStreamingConfig: {
      mutable_streaming_config()->::google::cloud::speech::v1beta1::StreamingRecognitionConfig::MergeFrom(from.streaming_config());
      break;
    }
    case kAudioContent: {
      set_audio_content(from.audio_content());
      break;
    }
    case STREAMING_REQUEST_NOT_SET: {
      break;
    }
  }
}

void StreamingRecognizeRequest::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:google.cloud.speech.v1beta1.StreamingRecognizeRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void StreamingRecognizeRequest::CopyFrom(const StreamingRecognizeRequest& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:google.cloud.speech.v1beta1.StreamingRecognizeRequest)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool StreamingRecognizeRequest::IsInitialized() const {
  return true;
}

void StreamingRecognizeRequest::Swap(StreamingRecognizeRequest* other) {
  if (other == this) return;
  InternalSwap(other);
}
void StreamingRecognizeRequest::InternalSwap(StreamingRecognizeRequest* other) {
  std::swap(streaming_request_, other->streaming_request_);
  std::swap(_oneof_case_[0], other->_oneof_case_[0]);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata StreamingRecognizeRequest::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  return file_level_metadata[2];
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// StreamingRecognizeRequest

// .google.cloud.speech.v1beta1.StreamingRecognitionConfig streaming_config = 1;
bool StreamingRecognizeRequest::has_streaming_config() const {
  return streaming_request_case() == kStreamingConfig;
}
void StreamingRecognizeRequest::set_has_streaming_config() {
  _oneof_case_[0] = kStreamingConfig;
}
void StreamingRecognizeRequest::clear_streaming_config() {
  if (has_streaming_config()) {
    delete streaming_request_.streaming_config_;
    clear_has_streaming_request();
  }
}
 const ::google::cloud::speech::v1beta1::StreamingRecognitionConfig& StreamingRecognizeRequest::streaming_config() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.StreamingRecognizeRequest.streaming_config)
  return has_streaming_config()
      ? *streaming_request_.streaming_config_
      : ::google::cloud::speech::v1beta1::StreamingRecognitionConfig::default_instance();
}
::google::cloud::speech::v1beta1::StreamingRecognitionConfig* StreamingRecognizeRequest::mutable_streaming_config() {
  if (!has_streaming_config()) {
    clear_streaming_request();
    set_has_streaming_config();
    streaming_request_.streaming_config_ = new ::google::cloud::speech::v1beta1::StreamingRecognitionConfig;
  }
  // @@protoc_insertion_point(field_mutable:google.cloud.speech.v1beta1.StreamingRecognizeRequest.streaming_config)
  return streaming_request_.streaming_config_;
}
::google::cloud::speech::v1beta1::StreamingRecognitionConfig* StreamingRecognizeRequest::release_streaming_config() {
  // @@protoc_insertion_point(field_release:google.cloud.speech.v1beta1.StreamingRecognizeRequest.streaming_config)
  if (has_streaming_config()) {
    clear_has_streaming_request();
    ::google::cloud::speech::v1beta1::StreamingRecognitionConfig* temp = streaming_request_.streaming_config_;
    streaming_request_.streaming_config_ = NULL;
    return temp;
  } else {
    return NULL;
  }
}
void StreamingRecognizeRequest::set_allocated_streaming_config(::google::cloud::speech::v1beta1::StreamingRecognitionConfig* streaming_config) {
  clear_streaming_request();
  if (streaming_config) {
    set_has_streaming_config();
    streaming_request_.streaming_config_ = streaming_config;
  }
  // @@protoc_insertion_point(field_set_allocated:google.cloud.speech.v1beta1.StreamingRecognizeRequest.streaming_config)
}

// bytes audio_content = 2;
bool StreamingRecognizeRequest::has_audio_content() const {
  return streaming_request_case() == kAudioContent;
}
void StreamingRecognizeRequest::set_has_audio_content() {
  _oneof_case_[0] = kAudioContent;
}
void StreamingRecognizeRequest::clear_audio_content() {
  if (has_audio_content()) {
    streaming_request_.audio_content_.DestroyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
    clear_has_streaming_request();
  }
}
const ::std::string& StreamingRecognizeRequest::audio_content() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.StreamingRecognizeRequest.audio_content)
  if (has_audio_content()) {
    return streaming_request_.audio_content_.GetNoArena();
  }
  return *&::google::protobuf::internal::GetEmptyStringAlreadyInited();
}
void StreamingRecognizeRequest::set_audio_content(const ::std::string& value) {
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.StreamingRecognizeRequest.audio_content)
  if (!has_audio_content()) {
    clear_streaming_request();
    set_has_audio_content();
    streaming_request_.audio_content_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  }
  streaming_request_.audio_content_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.StreamingRecognizeRequest.audio_content)
}
void StreamingRecognizeRequest::set_audio_content(const char* value) {
  if (!has_audio_content()) {
    clear_streaming_request();
    set_has_audio_content();
    streaming_request_.audio_content_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  }
  streaming_request_.audio_content_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(value));
  // @@protoc_insertion_point(field_set_char:google.cloud.speech.v1beta1.StreamingRecognizeRequest.audio_content)
}
void StreamingRecognizeRequest::set_audio_content(const void* value, size_t size) {
  if (!has_audio_content()) {
    clear_streaming_request();
    set_has_audio_content();
    streaming_request_.audio_content_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  }
  streaming_request_.audio_content_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(
      reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:google.cloud.speech.v1beta1.StreamingRecognizeRequest.audio_content)
}
::std::string* StreamingRecognizeRequest::mutable_audio_content() {
  if (!has_audio_content()) {
    clear_streaming_request();
    set_has_audio_content();
    streaming_request_.audio_content_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  }
  // @@protoc_insertion_point(field_mutable:google.cloud.speech.v1beta1.StreamingRecognizeRequest.audio_content)
  return streaming_request_.audio_content_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
::std::string* StreamingRecognizeRequest::release_audio_content() {
  // @@protoc_insertion_point(field_release:google.cloud.speech.v1beta1.StreamingRecognizeRequest.audio_content)
  if (has_audio_content()) {
    clear_has_streaming_request();
    return streaming_request_.audio_content_.ReleaseNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  } else {
    return NULL;
  }
}
void StreamingRecognizeRequest::set_allocated_audio_content(::std::string* audio_content) {
  if (!has_audio_content()) {
    streaming_request_.audio_content_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  }
  clear_streaming_request();
  if (audio_content != NULL) {
    set_has_audio_content();
    streaming_request_.audio_content_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
        audio_content);
  }
  // @@protoc_insertion_point(field_set_allocated:google.cloud.speech.v1beta1.StreamingRecognizeRequest.audio_content)
}

bool StreamingRecognizeRequest::has_streaming_request() const {
  return streaming_request_case() != STREAMING_REQUEST_NOT_SET;
}
void StreamingRecognizeRequest::clear_has_streaming_request() {
  _oneof_case_[0] = STREAMING_REQUEST_NOT_SET;
}
StreamingRecognizeRequest::StreamingRequestCase StreamingRecognizeRequest::streaming_request_case() const {
  return StreamingRecognizeRequest::StreamingRequestCase(_oneof_case_[0]);
}
#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int StreamingRecognitionConfig::kConfigFieldNumber;
const int StreamingRecognitionConfig::kSingleUtteranceFieldNumber;
const int StreamingRecognitionConfig::kInterimResultsFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

StreamingRecognitionConfig::StreamingRecognitionConfig()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  if (GOOGLE_PREDICT_TRUE(this != internal_default_instance())) {
    protobuf_InitDefaults_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto();
  }
  SharedCtor();
  // @@protoc_insertion_point(constructor:google.cloud.speech.v1beta1.StreamingRecognitionConfig)
}
StreamingRecognitionConfig::StreamingRecognitionConfig(const StreamingRecognitionConfig& from)
  : ::google::protobuf::Message(),
      _internal_metadata_(NULL),
      _cached_size_(0) {
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  if (from.has_config()) {
    config_ = new ::google::cloud::speech::v1beta1::RecognitionConfig(*from.config_);
  } else {
    config_ = NULL;
  }
  ::memcpy(&single_utterance_, &from.single_utterance_,
    reinterpret_cast<char*>(&interim_results_) -
    reinterpret_cast<char*>(&single_utterance_) + sizeof(interim_results_));
  // @@protoc_insertion_point(copy_constructor:google.cloud.speech.v1beta1.StreamingRecognitionConfig)
}

void StreamingRecognitionConfig::SharedCtor() {
  ::memset(&config_, 0, reinterpret_cast<char*>(&interim_results_) -
    reinterpret_cast<char*>(&config_) + sizeof(interim_results_));
  _cached_size_ = 0;
}

StreamingRecognitionConfig::~StreamingRecognitionConfig() {
  // @@protoc_insertion_point(destructor:google.cloud.speech.v1beta1.StreamingRecognitionConfig)
  SharedDtor();
}

void StreamingRecognitionConfig::SharedDtor() {
  if (this != internal_default_instance()) {
    delete config_;
  }
}

void StreamingRecognitionConfig::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* StreamingRecognitionConfig::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return file_level_metadata[3].descriptor;
}

const StreamingRecognitionConfig& StreamingRecognitionConfig::default_instance() {
  protobuf_InitDefaults_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto();
  return *internal_default_instance();
}

StreamingRecognitionConfig* StreamingRecognitionConfig::New(::google::protobuf::Arena* arena) const {
  StreamingRecognitionConfig* n = new StreamingRecognitionConfig;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void StreamingRecognitionConfig::Clear() {
// @@protoc_insertion_point(message_clear_start:google.cloud.speech.v1beta1.StreamingRecognitionConfig)
  if (GetArenaNoVirtual() == NULL && config_ != NULL) {
    delete config_;
  }
  config_ = NULL;
  ::memset(&single_utterance_, 0, reinterpret_cast<char*>(&interim_results_) -
    reinterpret_cast<char*>(&single_utterance_) + sizeof(interim_results_));
}

bool StreamingRecognitionConfig::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:google.cloud.speech.v1beta1.StreamingRecognitionConfig)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoffNoLastTag(127u);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // .google.cloud.speech.v1beta1.RecognitionConfig config = 1;
      case 1: {
        if (tag == 10u) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_config()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // bool single_utterance = 2;
      case 2: {
        if (tag == 16u) {

          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   bool, ::google::protobuf::internal::WireFormatLite::TYPE_BOOL>(
                 input, &single_utterance_)));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // bool interim_results = 3;
      case 3: {
        if (tag == 24u) {

          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   bool, ::google::protobuf::internal::WireFormatLite::TYPE_BOOL>(
                 input, &interim_results_)));
        } else {
          goto handle_unusual;
        }
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:google.cloud.speech.v1beta1.StreamingRecognitionConfig)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:google.cloud.speech.v1beta1.StreamingRecognitionConfig)
  return false;
#undef DO_
}

void StreamingRecognitionConfig::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:google.cloud.speech.v1beta1.StreamingRecognitionConfig)
  // .google.cloud.speech.v1beta1.RecognitionConfig config = 1;
  if (this->has_config()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, *this->config_, output);
  }

  // bool single_utterance = 2;
  if (this->single_utterance() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteBool(2, this->single_utterance(), output);
  }

  // bool interim_results = 3;
  if (this->interim_results() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteBool(3, this->interim_results(), output);
  }

  // @@protoc_insertion_point(serialize_end:google.cloud.speech.v1beta1.StreamingRecognitionConfig)
}

::google::protobuf::uint8* StreamingRecognitionConfig::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  (void)deterministic; // Unused
  // @@protoc_insertion_point(serialize_to_array_start:google.cloud.speech.v1beta1.StreamingRecognitionConfig)
  // .google.cloud.speech.v1beta1.RecognitionConfig config = 1;
  if (this->has_config()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        1, *this->config_, false, target);
  }

  // bool single_utterance = 2;
  if (this->single_utterance() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteBoolToArray(2, this->single_utterance(), target);
  }

  // bool interim_results = 3;
  if (this->interim_results() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteBoolToArray(3, this->interim_results(), target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:google.cloud.speech.v1beta1.StreamingRecognitionConfig)
  return target;
}

size_t StreamingRecognitionConfig::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:google.cloud.speech.v1beta1.StreamingRecognitionConfig)
  size_t total_size = 0;

  // .google.cloud.speech.v1beta1.RecognitionConfig config = 1;
  if (this->has_config()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->config_);
  }

  // bool single_utterance = 2;
  if (this->single_utterance() != 0) {
    total_size += 1 + 1;
  }

  // bool interim_results = 3;
  if (this->interim_results() != 0) {
    total_size += 1 + 1;
  }

  int cached_size = ::google::protobuf::internal::ToCachedSize(total_size);
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = cached_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void StreamingRecognitionConfig::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:google.cloud.speech.v1beta1.StreamingRecognitionConfig)
  GOOGLE_DCHECK_NE(&from, this);
  const StreamingRecognitionConfig* source =
      ::google::protobuf::internal::DynamicCastToGenerated<const StreamingRecognitionConfig>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:google.cloud.speech.v1beta1.StreamingRecognitionConfig)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:google.cloud.speech.v1beta1.StreamingRecognitionConfig)
    MergeFrom(*source);
  }
}

void StreamingRecognitionConfig::MergeFrom(const StreamingRecognitionConfig& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:google.cloud.speech.v1beta1.StreamingRecognitionConfig)
  GOOGLE_DCHECK_NE(&from, this);
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  if (from.has_config()) {
    mutable_config()->::google::cloud::speech::v1beta1::RecognitionConfig::MergeFrom(from.config());
  }
  if (from.single_utterance() != 0) {
    set_single_utterance(from.single_utterance());
  }
  if (from.interim_results() != 0) {
    set_interim_results(from.interim_results());
  }
}

void StreamingRecognitionConfig::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:google.cloud.speech.v1beta1.StreamingRecognitionConfig)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void StreamingRecognitionConfig::CopyFrom(const StreamingRecognitionConfig& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:google.cloud.speech.v1beta1.StreamingRecognitionConfig)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool StreamingRecognitionConfig::IsInitialized() const {
  return true;
}

void StreamingRecognitionConfig::Swap(StreamingRecognitionConfig* other) {
  if (other == this) return;
  InternalSwap(other);
}
void StreamingRecognitionConfig::InternalSwap(StreamingRecognitionConfig* other) {
  std::swap(config_, other->config_);
  std::swap(single_utterance_, other->single_utterance_);
  std::swap(interim_results_, other->interim_results_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata StreamingRecognitionConfig::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  return file_level_metadata[3];
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// StreamingRecognitionConfig

// .google.cloud.speech.v1beta1.RecognitionConfig config = 1;
bool StreamingRecognitionConfig::has_config() const {
  return this != internal_default_instance() && config_ != NULL;
}
void StreamingRecognitionConfig::clear_config() {
  if (GetArenaNoVirtual() == NULL && config_ != NULL) delete config_;
  config_ = NULL;
}
const ::google::cloud::speech::v1beta1::RecognitionConfig& StreamingRecognitionConfig::config() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.StreamingRecognitionConfig.config)
  return config_ != NULL ? *config_
                         : *::google::cloud::speech::v1beta1::RecognitionConfig::internal_default_instance();
}
::google::cloud::speech::v1beta1::RecognitionConfig* StreamingRecognitionConfig::mutable_config() {
  
  if (config_ == NULL) {
    config_ = new ::google::cloud::speech::v1beta1::RecognitionConfig;
  }
  // @@protoc_insertion_point(field_mutable:google.cloud.speech.v1beta1.StreamingRecognitionConfig.config)
  return config_;
}
::google::cloud::speech::v1beta1::RecognitionConfig* StreamingRecognitionConfig::release_config() {
  // @@protoc_insertion_point(field_release:google.cloud.speech.v1beta1.StreamingRecognitionConfig.config)
  
  ::google::cloud::speech::v1beta1::RecognitionConfig* temp = config_;
  config_ = NULL;
  return temp;
}
void StreamingRecognitionConfig::set_allocated_config(::google::cloud::speech::v1beta1::RecognitionConfig* config) {
  delete config_;
  config_ = config;
  if (config) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:google.cloud.speech.v1beta1.StreamingRecognitionConfig.config)
}

// bool single_utterance = 2;
void StreamingRecognitionConfig::clear_single_utterance() {
  single_utterance_ = false;
}
bool StreamingRecognitionConfig::single_utterance() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.StreamingRecognitionConfig.single_utterance)
  return single_utterance_;
}
void StreamingRecognitionConfig::set_single_utterance(bool value) {
  
  single_utterance_ = value;
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.StreamingRecognitionConfig.single_utterance)
}

// bool interim_results = 3;
void StreamingRecognitionConfig::clear_interim_results() {
  interim_results_ = false;
}
bool StreamingRecognitionConfig::interim_results() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.StreamingRecognitionConfig.interim_results)
  return interim_results_;
}
void StreamingRecognitionConfig::set_interim_results(bool value) {
  
  interim_results_ = value;
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.StreamingRecognitionConfig.interim_results)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int RecognitionConfig::kEncodingFieldNumber;
const int RecognitionConfig::kSampleRateFieldNumber;
const int RecognitionConfig::kLanguageCodeFieldNumber;
const int RecognitionConfig::kMaxAlternativesFieldNumber;
const int RecognitionConfig::kProfanityFilterFieldNumber;
const int RecognitionConfig::kSpeechContextFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

RecognitionConfig::RecognitionConfig()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  if (GOOGLE_PREDICT_TRUE(this != internal_default_instance())) {
    protobuf_InitDefaults_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto();
  }
  SharedCtor();
  // @@protoc_insertion_point(constructor:google.cloud.speech.v1beta1.RecognitionConfig)
}
RecognitionConfig::RecognitionConfig(const RecognitionConfig& from)
  : ::google::protobuf::Message(),
      _internal_metadata_(NULL),
      _cached_size_(0) {
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  language_code_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  if (from.language_code().size() > 0) {
    language_code_.AssignWithDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), from.language_code_);
  }
  if (from.has_speech_context()) {
    speech_context_ = new ::google::cloud::speech::v1beta1::SpeechContext(*from.speech_context_);
  } else {
    speech_context_ = NULL;
  }
  ::memcpy(&encoding_, &from.encoding_,
    reinterpret_cast<char*>(&profanity_filter_) -
    reinterpret_cast<char*>(&encoding_) + sizeof(profanity_filter_));
  // @@protoc_insertion_point(copy_constructor:google.cloud.speech.v1beta1.RecognitionConfig)
}

void RecognitionConfig::SharedCtor() {
  language_code_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  ::memset(&speech_context_, 0, reinterpret_cast<char*>(&profanity_filter_) -
    reinterpret_cast<char*>(&speech_context_) + sizeof(profanity_filter_));
  _cached_size_ = 0;
}

RecognitionConfig::~RecognitionConfig() {
  // @@protoc_insertion_point(destructor:google.cloud.speech.v1beta1.RecognitionConfig)
  SharedDtor();
}

void RecognitionConfig::SharedDtor() {
  language_code_.DestroyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  if (this != internal_default_instance()) {
    delete speech_context_;
  }
}

void RecognitionConfig::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* RecognitionConfig::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return file_level_metadata[4].descriptor;
}

const RecognitionConfig& RecognitionConfig::default_instance() {
  protobuf_InitDefaults_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto();
  return *internal_default_instance();
}

RecognitionConfig* RecognitionConfig::New(::google::protobuf::Arena* arena) const {
  RecognitionConfig* n = new RecognitionConfig;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void RecognitionConfig::Clear() {
// @@protoc_insertion_point(message_clear_start:google.cloud.speech.v1beta1.RecognitionConfig)
  language_code_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  if (GetArenaNoVirtual() == NULL && speech_context_ != NULL) {
    delete speech_context_;
  }
  speech_context_ = NULL;
  ::memset(&encoding_, 0, reinterpret_cast<char*>(&profanity_filter_) -
    reinterpret_cast<char*>(&encoding_) + sizeof(profanity_filter_));
}

bool RecognitionConfig::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:google.cloud.speech.v1beta1.RecognitionConfig)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoffNoLastTag(127u);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // .google.cloud.speech.v1beta1.RecognitionConfig.AudioEncoding encoding = 1;
      case 1: {
        if (tag == 8u) {
          int value;
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   int, ::google::protobuf::internal::WireFormatLite::TYPE_ENUM>(
                 input, &value)));
          set_encoding(static_cast< ::google::cloud::speech::v1beta1::RecognitionConfig_AudioEncoding >(value));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // int32 sample_rate = 2;
      case 2: {
        if (tag == 16u) {

          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int32, ::google::protobuf::internal::WireFormatLite::TYPE_INT32>(
                 input, &sample_rate_)));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // string language_code = 3;
      case 3: {
        if (tag == 26u) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadString(
                input, this->mutable_language_code()));
          DO_(::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
            this->language_code().data(), this->language_code().length(),
            ::google::protobuf::internal::WireFormatLite::PARSE,
            "google.cloud.speech.v1beta1.RecognitionConfig.language_code"));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // int32 max_alternatives = 4;
      case 4: {
        if (tag == 32u) {

          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int32, ::google::protobuf::internal::WireFormatLite::TYPE_INT32>(
                 input, &max_alternatives_)));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // bool profanity_filter = 5;
      case 5: {
        if (tag == 40u) {

          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   bool, ::google::protobuf::internal::WireFormatLite::TYPE_BOOL>(
                 input, &profanity_filter_)));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // .google.cloud.speech.v1beta1.SpeechContext speech_context = 6;
      case 6: {
        if (tag == 50u) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_speech_context()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:google.cloud.speech.v1beta1.RecognitionConfig)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:google.cloud.speech.v1beta1.RecognitionConfig)
  return false;
#undef DO_
}

void RecognitionConfig::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:google.cloud.speech.v1beta1.RecognitionConfig)
  // .google.cloud.speech.v1beta1.RecognitionConfig.AudioEncoding encoding = 1;
  if (this->encoding() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteEnum(
      1, this->encoding(), output);
  }

  // int32 sample_rate = 2;
  if (this->sample_rate() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteInt32(2, this->sample_rate(), output);
  }

  // string language_code = 3;
  if (this->language_code().size() > 0) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->language_code().data(), this->language_code().length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "google.cloud.speech.v1beta1.RecognitionConfig.language_code");
    ::google::protobuf::internal::WireFormatLite::WriteStringMaybeAliased(
      3, this->language_code(), output);
  }

  // int32 max_alternatives = 4;
  if (this->max_alternatives() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteInt32(4, this->max_alternatives(), output);
  }

  // bool profanity_filter = 5;
  if (this->profanity_filter() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteBool(5, this->profanity_filter(), output);
  }

  // .google.cloud.speech.v1beta1.SpeechContext speech_context = 6;
  if (this->has_speech_context()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      6, *this->speech_context_, output);
  }

  // @@protoc_insertion_point(serialize_end:google.cloud.speech.v1beta1.RecognitionConfig)
}

::google::protobuf::uint8* RecognitionConfig::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  (void)deterministic; // Unused
  // @@protoc_insertion_point(serialize_to_array_start:google.cloud.speech.v1beta1.RecognitionConfig)
  // .google.cloud.speech.v1beta1.RecognitionConfig.AudioEncoding encoding = 1;
  if (this->encoding() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteEnumToArray(
      1, this->encoding(), target);
  }

  // int32 sample_rate = 2;
  if (this->sample_rate() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt32ToArray(2, this->sample_rate(), target);
  }

  // string language_code = 3;
  if (this->language_code().size() > 0) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->language_code().data(), this->language_code().length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "google.cloud.speech.v1beta1.RecognitionConfig.language_code");
    target =
      ::google::protobuf::internal::WireFormatLite::WriteStringToArray(
        3, this->language_code(), target);
  }

  // int32 max_alternatives = 4;
  if (this->max_alternatives() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt32ToArray(4, this->max_alternatives(), target);
  }

  // bool profanity_filter = 5;
  if (this->profanity_filter() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteBoolToArray(5, this->profanity_filter(), target);
  }

  // .google.cloud.speech.v1beta1.SpeechContext speech_context = 6;
  if (this->has_speech_context()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        6, *this->speech_context_, false, target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:google.cloud.speech.v1beta1.RecognitionConfig)
  return target;
}

size_t RecognitionConfig::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:google.cloud.speech.v1beta1.RecognitionConfig)
  size_t total_size = 0;

  // string language_code = 3;
  if (this->language_code().size() > 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::StringSize(
        this->language_code());
  }

  // .google.cloud.speech.v1beta1.SpeechContext speech_context = 6;
  if (this->has_speech_context()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->speech_context_);
  }

  // .google.cloud.speech.v1beta1.RecognitionConfig.AudioEncoding encoding = 1;
  if (this->encoding() != 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::EnumSize(this->encoding());
  }

  // int32 sample_rate = 2;
  if (this->sample_rate() != 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::Int32Size(
        this->sample_rate());
  }

  // int32 max_alternatives = 4;
  if (this->max_alternatives() != 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::Int32Size(
        this->max_alternatives());
  }

  // bool profanity_filter = 5;
  if (this->profanity_filter() != 0) {
    total_size += 1 + 1;
  }

  int cached_size = ::google::protobuf::internal::ToCachedSize(total_size);
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = cached_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void RecognitionConfig::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:google.cloud.speech.v1beta1.RecognitionConfig)
  GOOGLE_DCHECK_NE(&from, this);
  const RecognitionConfig* source =
      ::google::protobuf::internal::DynamicCastToGenerated<const RecognitionConfig>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:google.cloud.speech.v1beta1.RecognitionConfig)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:google.cloud.speech.v1beta1.RecognitionConfig)
    MergeFrom(*source);
  }
}

void RecognitionConfig::MergeFrom(const RecognitionConfig& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:google.cloud.speech.v1beta1.RecognitionConfig)
  GOOGLE_DCHECK_NE(&from, this);
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  if (from.language_code().size() > 0) {

    language_code_.AssignWithDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), from.language_code_);
  }
  if (from.has_speech_context()) {
    mutable_speech_context()->::google::cloud::speech::v1beta1::SpeechContext::MergeFrom(from.speech_context());
  }
  if (from.encoding() != 0) {
    set_encoding(from.encoding());
  }
  if (from.sample_rate() != 0) {
    set_sample_rate(from.sample_rate());
  }
  if (from.max_alternatives() != 0) {
    set_max_alternatives(from.max_alternatives());
  }
  if (from.profanity_filter() != 0) {
    set_profanity_filter(from.profanity_filter());
  }
}

void RecognitionConfig::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:google.cloud.speech.v1beta1.RecognitionConfig)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void RecognitionConfig::CopyFrom(const RecognitionConfig& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:google.cloud.speech.v1beta1.RecognitionConfig)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool RecognitionConfig::IsInitialized() const {
  return true;
}

void RecognitionConfig::Swap(RecognitionConfig* other) {
  if (other == this) return;
  InternalSwap(other);
}
void RecognitionConfig::InternalSwap(RecognitionConfig* other) {
  language_code_.Swap(&other->language_code_);
  std::swap(speech_context_, other->speech_context_);
  std::swap(encoding_, other->encoding_);
  std::swap(sample_rate_, other->sample_rate_);
  std::swap(max_alternatives_, other->max_alternatives_);
  std::swap(profanity_filter_, other->profanity_filter_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata RecognitionConfig::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  return file_level_metadata[4];
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// RecognitionConfig

// .google.cloud.speech.v1beta1.RecognitionConfig.AudioEncoding encoding = 1;
void RecognitionConfig::clear_encoding() {
  encoding_ = 0;
}
::google::cloud::speech::v1beta1::RecognitionConfig_AudioEncoding RecognitionConfig::encoding() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.RecognitionConfig.encoding)
  return static_cast< ::google::cloud::speech::v1beta1::RecognitionConfig_AudioEncoding >(encoding_);
}
void RecognitionConfig::set_encoding(::google::cloud::speech::v1beta1::RecognitionConfig_AudioEncoding value) {
  
  encoding_ = value;
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.RecognitionConfig.encoding)
}

// int32 sample_rate = 2;
void RecognitionConfig::clear_sample_rate() {
  sample_rate_ = 0;
}
::google::protobuf::int32 RecognitionConfig::sample_rate() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.RecognitionConfig.sample_rate)
  return sample_rate_;
}
void RecognitionConfig::set_sample_rate(::google::protobuf::int32 value) {
  
  sample_rate_ = value;
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.RecognitionConfig.sample_rate)
}

// string language_code = 3;
void RecognitionConfig::clear_language_code() {
  language_code_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
const ::std::string& RecognitionConfig::language_code() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.RecognitionConfig.language_code)
  return language_code_.GetNoArena();
}
void RecognitionConfig::set_language_code(const ::std::string& value) {
  
  language_code_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.RecognitionConfig.language_code)
}
void RecognitionConfig::set_language_code(const char* value) {
  
  language_code_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:google.cloud.speech.v1beta1.RecognitionConfig.language_code)
}
void RecognitionConfig::set_language_code(const char* value, size_t size) {
  
  language_code_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:google.cloud.speech.v1beta1.RecognitionConfig.language_code)
}
::std::string* RecognitionConfig::mutable_language_code() {
  
  // @@protoc_insertion_point(field_mutable:google.cloud.speech.v1beta1.RecognitionConfig.language_code)
  return language_code_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
::std::string* RecognitionConfig::release_language_code() {
  // @@protoc_insertion_point(field_release:google.cloud.speech.v1beta1.RecognitionConfig.language_code)
  
  return language_code_.ReleaseNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
void RecognitionConfig::set_allocated_language_code(::std::string* language_code) {
  if (language_code != NULL) {
    
  } else {
    
  }
  language_code_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), language_code);
  // @@protoc_insertion_point(field_set_allocated:google.cloud.speech.v1beta1.RecognitionConfig.language_code)
}

// int32 max_alternatives = 4;
void RecognitionConfig::clear_max_alternatives() {
  max_alternatives_ = 0;
}
::google::protobuf::int32 RecognitionConfig::max_alternatives() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.RecognitionConfig.max_alternatives)
  return max_alternatives_;
}
void RecognitionConfig::set_max_alternatives(::google::protobuf::int32 value) {
  
  max_alternatives_ = value;
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.RecognitionConfig.max_alternatives)
}

// bool profanity_filter = 5;
void RecognitionConfig::clear_profanity_filter() {
  profanity_filter_ = false;
}
bool RecognitionConfig::profanity_filter() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.RecognitionConfig.profanity_filter)
  return profanity_filter_;
}
void RecognitionConfig::set_profanity_filter(bool value) {
  
  profanity_filter_ = value;
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.RecognitionConfig.profanity_filter)
}

// .google.cloud.speech.v1beta1.SpeechContext speech_context = 6;
bool RecognitionConfig::has_speech_context() const {
  return this != internal_default_instance() && speech_context_ != NULL;
}
void RecognitionConfig::clear_speech_context() {
  if (GetArenaNoVirtual() == NULL && speech_context_ != NULL) delete speech_context_;
  speech_context_ = NULL;
}
const ::google::cloud::speech::v1beta1::SpeechContext& RecognitionConfig::speech_context() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.RecognitionConfig.speech_context)
  return speech_context_ != NULL ? *speech_context_
                         : *::google::cloud::speech::v1beta1::SpeechContext::internal_default_instance();
}
::google::cloud::speech::v1beta1::SpeechContext* RecognitionConfig::mutable_speech_context() {
  
  if (speech_context_ == NULL) {
    speech_context_ = new ::google::cloud::speech::v1beta1::SpeechContext;
  }
  // @@protoc_insertion_point(field_mutable:google.cloud.speech.v1beta1.RecognitionConfig.speech_context)
  return speech_context_;
}
::google::cloud::speech::v1beta1::SpeechContext* RecognitionConfig::release_speech_context() {
  // @@protoc_insertion_point(field_release:google.cloud.speech.v1beta1.RecognitionConfig.speech_context)
  
  ::google::cloud::speech::v1beta1::SpeechContext* temp = speech_context_;
  speech_context_ = NULL;
  return temp;
}
void RecognitionConfig::set_allocated_speech_context(::google::cloud::speech::v1beta1::SpeechContext* speech_context) {
  delete speech_context_;
  speech_context_ = speech_context;
  if (speech_context) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:google.cloud.speech.v1beta1.RecognitionConfig.speech_context)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int SpeechContext::kPhrasesFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

SpeechContext::SpeechContext()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  if (GOOGLE_PREDICT_TRUE(this != internal_default_instance())) {
    protobuf_InitDefaults_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto();
  }
  SharedCtor();
  // @@protoc_insertion_point(constructor:google.cloud.speech.v1beta1.SpeechContext)
}
SpeechContext::SpeechContext(const SpeechContext& from)
  : ::google::protobuf::Message(),
      _internal_metadata_(NULL),
      phrases_(from.phrases_),
      _cached_size_(0) {
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  // @@protoc_insertion_point(copy_constructor:google.cloud.speech.v1beta1.SpeechContext)
}

void SpeechContext::SharedCtor() {
  _cached_size_ = 0;
}

SpeechContext::~SpeechContext() {
  // @@protoc_insertion_point(destructor:google.cloud.speech.v1beta1.SpeechContext)
  SharedDtor();
}

void SpeechContext::SharedDtor() {
}

void SpeechContext::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* SpeechContext::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return file_level_metadata[5].descriptor;
}

const SpeechContext& SpeechContext::default_instance() {
  protobuf_InitDefaults_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto();
  return *internal_default_instance();
}

SpeechContext* SpeechContext::New(::google::protobuf::Arena* arena) const {
  SpeechContext* n = new SpeechContext;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void SpeechContext::Clear() {
// @@protoc_insertion_point(message_clear_start:google.cloud.speech.v1beta1.SpeechContext)
  phrases_.Clear();
}

bool SpeechContext::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:google.cloud.speech.v1beta1.SpeechContext)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoffNoLastTag(127u);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // repeated string phrases = 1;
      case 1: {
        if (tag == 10u) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadString(
                input, this->add_phrases()));
          DO_(::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
            this->phrases(this->phrases_size() - 1).data(),
            this->phrases(this->phrases_size() - 1).length(),
            ::google::protobuf::internal::WireFormatLite::PARSE,
            "google.cloud.speech.v1beta1.SpeechContext.phrases"));
        } else {
          goto handle_unusual;
        }
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:google.cloud.speech.v1beta1.SpeechContext)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:google.cloud.speech.v1beta1.SpeechContext)
  return false;
#undef DO_
}

void SpeechContext::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:google.cloud.speech.v1beta1.SpeechContext)
  // repeated string phrases = 1;
  for (int i = 0; i < this->phrases_size(); i++) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->phrases(i).data(), this->phrases(i).length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "google.cloud.speech.v1beta1.SpeechContext.phrases");
    ::google::protobuf::internal::WireFormatLite::WriteString(
      1, this->phrases(i), output);
  }

  // @@protoc_insertion_point(serialize_end:google.cloud.speech.v1beta1.SpeechContext)
}

::google::protobuf::uint8* SpeechContext::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  (void)deterministic; // Unused
  // @@protoc_insertion_point(serialize_to_array_start:google.cloud.speech.v1beta1.SpeechContext)
  // repeated string phrases = 1;
  for (int i = 0; i < this->phrases_size(); i++) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->phrases(i).data(), this->phrases(i).length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "google.cloud.speech.v1beta1.SpeechContext.phrases");
    target = ::google::protobuf::internal::WireFormatLite::
      WriteStringToArray(1, this->phrases(i), target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:google.cloud.speech.v1beta1.SpeechContext)
  return target;
}

size_t SpeechContext::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:google.cloud.speech.v1beta1.SpeechContext)
  size_t total_size = 0;

  // repeated string phrases = 1;
  total_size += 1 *
      ::google::protobuf::internal::FromIntSize(this->phrases_size());
  for (int i = 0; i < this->phrases_size(); i++) {
    total_size += ::google::protobuf::internal::WireFormatLite::StringSize(
      this->phrases(i));
  }

  int cached_size = ::google::protobuf::internal::ToCachedSize(total_size);
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = cached_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void SpeechContext::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:google.cloud.speech.v1beta1.SpeechContext)
  GOOGLE_DCHECK_NE(&from, this);
  const SpeechContext* source =
      ::google::protobuf::internal::DynamicCastToGenerated<const SpeechContext>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:google.cloud.speech.v1beta1.SpeechContext)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:google.cloud.speech.v1beta1.SpeechContext)
    MergeFrom(*source);
  }
}

void SpeechContext::MergeFrom(const SpeechContext& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:google.cloud.speech.v1beta1.SpeechContext)
  GOOGLE_DCHECK_NE(&from, this);
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  phrases_.MergeFrom(from.phrases_);
}

void SpeechContext::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:google.cloud.speech.v1beta1.SpeechContext)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void SpeechContext::CopyFrom(const SpeechContext& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:google.cloud.speech.v1beta1.SpeechContext)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool SpeechContext::IsInitialized() const {
  return true;
}

void SpeechContext::Swap(SpeechContext* other) {
  if (other == this) return;
  InternalSwap(other);
}
void SpeechContext::InternalSwap(SpeechContext* other) {
  phrases_.UnsafeArenaSwap(&other->phrases_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata SpeechContext::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  return file_level_metadata[5];
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// SpeechContext

// repeated string phrases = 1;
int SpeechContext::phrases_size() const {
  return phrases_.size();
}
void SpeechContext::clear_phrases() {
  phrases_.Clear();
}
const ::std::string& SpeechContext::phrases(int index) const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.SpeechContext.phrases)
  return phrases_.Get(index);
}
::std::string* SpeechContext::mutable_phrases(int index) {
  // @@protoc_insertion_point(field_mutable:google.cloud.speech.v1beta1.SpeechContext.phrases)
  return phrases_.Mutable(index);
}
void SpeechContext::set_phrases(int index, const ::std::string& value) {
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.SpeechContext.phrases)
  phrases_.Mutable(index)->assign(value);
}
void SpeechContext::set_phrases(int index, const char* value) {
  phrases_.Mutable(index)->assign(value);
  // @@protoc_insertion_point(field_set_char:google.cloud.speech.v1beta1.SpeechContext.phrases)
}
void SpeechContext::set_phrases(int index, const char* value, size_t size) {
  phrases_.Mutable(index)->assign(
    reinterpret_cast<const char*>(value), size);
  // @@protoc_insertion_point(field_set_pointer:google.cloud.speech.v1beta1.SpeechContext.phrases)
}
::std::string* SpeechContext::add_phrases() {
  // @@protoc_insertion_point(field_add_mutable:google.cloud.speech.v1beta1.SpeechContext.phrases)
  return phrases_.Add();
}
void SpeechContext::add_phrases(const ::std::string& value) {
  phrases_.Add()->assign(value);
  // @@protoc_insertion_point(field_add:google.cloud.speech.v1beta1.SpeechContext.phrases)
}
void SpeechContext::add_phrases(const char* value) {
  phrases_.Add()->assign(value);
  // @@protoc_insertion_point(field_add_char:google.cloud.speech.v1beta1.SpeechContext.phrases)
}
void SpeechContext::add_phrases(const char* value, size_t size) {
  phrases_.Add()->assign(reinterpret_cast<const char*>(value), size);
  // @@protoc_insertion_point(field_add_pointer:google.cloud.speech.v1beta1.SpeechContext.phrases)
}
const ::google::protobuf::RepeatedPtrField< ::std::string>&
SpeechContext::phrases() const {
  // @@protoc_insertion_point(field_list:google.cloud.speech.v1beta1.SpeechContext.phrases)
  return phrases_;
}
::google::protobuf::RepeatedPtrField< ::std::string>*
SpeechContext::mutable_phrases() {
  // @@protoc_insertion_point(field_mutable_list:google.cloud.speech.v1beta1.SpeechContext.phrases)
  return &phrases_;
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int RecognitionAudio::kContentFieldNumber;
const int RecognitionAudio::kUriFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

RecognitionAudio::RecognitionAudio()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  if (GOOGLE_PREDICT_TRUE(this != internal_default_instance())) {
    protobuf_InitDefaults_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto();
  }
  SharedCtor();
  // @@protoc_insertion_point(constructor:google.cloud.speech.v1beta1.RecognitionAudio)
}
RecognitionAudio::RecognitionAudio(const RecognitionAudio& from)
  : ::google::protobuf::Message(),
      _internal_metadata_(NULL),
      _cached_size_(0) {
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  clear_has_audio_source();
  switch (from.audio_source_case()) {
    case kContent: {
      set_content(from.content());
      break;
    }
    case kUri: {
      set_uri(from.uri());
      break;
    }
    case AUDIO_SOURCE_NOT_SET: {
      break;
    }
  }
  // @@protoc_insertion_point(copy_constructor:google.cloud.speech.v1beta1.RecognitionAudio)
}

void RecognitionAudio::SharedCtor() {
  clear_has_audio_source();
  _cached_size_ = 0;
}

RecognitionAudio::~RecognitionAudio() {
  // @@protoc_insertion_point(destructor:google.cloud.speech.v1beta1.RecognitionAudio)
  SharedDtor();
}

void RecognitionAudio::SharedDtor() {
  if (has_audio_source()) {
    clear_audio_source();
  }
}

void RecognitionAudio::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* RecognitionAudio::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return file_level_metadata[6].descriptor;
}

const RecognitionAudio& RecognitionAudio::default_instance() {
  protobuf_InitDefaults_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto();
  return *internal_default_instance();
}

RecognitionAudio* RecognitionAudio::New(::google::protobuf::Arena* arena) const {
  RecognitionAudio* n = new RecognitionAudio;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void RecognitionAudio::clear_audio_source() {
// @@protoc_insertion_point(one_of_clear_start:google.cloud.speech.v1beta1.RecognitionAudio)
  switch (audio_source_case()) {
    case kContent: {
      audio_source_.content_.DestroyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
      break;
    }
    case kUri: {
      audio_source_.uri_.DestroyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
      break;
    }
    case AUDIO_SOURCE_NOT_SET: {
      break;
    }
  }
  _oneof_case_[0] = AUDIO_SOURCE_NOT_SET;
}


void RecognitionAudio::Clear() {
// @@protoc_insertion_point(message_clear_start:google.cloud.speech.v1beta1.RecognitionAudio)
  clear_audio_source();
}

bool RecognitionAudio::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:google.cloud.speech.v1beta1.RecognitionAudio)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoffNoLastTag(127u);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // bytes content = 1;
      case 1: {
        if (tag == 10u) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadBytes(
                input, this->mutable_content()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // string uri = 2;
      case 2: {
        if (tag == 18u) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadString(
                input, this->mutable_uri()));
          DO_(::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
            this->uri().data(), this->uri().length(),
            ::google::protobuf::internal::WireFormatLite::PARSE,
            "google.cloud.speech.v1beta1.RecognitionAudio.uri"));
        } else {
          goto handle_unusual;
        }
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:google.cloud.speech.v1beta1.RecognitionAudio)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:google.cloud.speech.v1beta1.RecognitionAudio)
  return false;
#undef DO_
}

void RecognitionAudio::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:google.cloud.speech.v1beta1.RecognitionAudio)
  // bytes content = 1;
  if (has_content()) {
    ::google::protobuf::internal::WireFormatLite::WriteBytesMaybeAliased(
      1, this->content(), output);
  }

  // string uri = 2;
  if (has_uri()) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->uri().data(), this->uri().length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "google.cloud.speech.v1beta1.RecognitionAudio.uri");
    ::google::protobuf::internal::WireFormatLite::WriteStringMaybeAliased(
      2, this->uri(), output);
  }

  // @@protoc_insertion_point(serialize_end:google.cloud.speech.v1beta1.RecognitionAudio)
}

::google::protobuf::uint8* RecognitionAudio::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  (void)deterministic; // Unused
  // @@protoc_insertion_point(serialize_to_array_start:google.cloud.speech.v1beta1.RecognitionAudio)
  // bytes content = 1;
  if (has_content()) {
    target =
      ::google::protobuf::internal::WireFormatLite::WriteBytesToArray(
        1, this->content(), target);
  }

  // string uri = 2;
  if (has_uri()) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->uri().data(), this->uri().length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "google.cloud.speech.v1beta1.RecognitionAudio.uri");
    target =
      ::google::protobuf::internal::WireFormatLite::WriteStringToArray(
        2, this->uri(), target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:google.cloud.speech.v1beta1.RecognitionAudio)
  return target;
}

size_t RecognitionAudio::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:google.cloud.speech.v1beta1.RecognitionAudio)
  size_t total_size = 0;

  switch (audio_source_case()) {
    // bytes content = 1;
    case kContent: {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::BytesSize(
          this->content());
      break;
    }
    // string uri = 2;
    case kUri: {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::StringSize(
          this->uri());
      break;
    }
    case AUDIO_SOURCE_NOT_SET: {
      break;
    }
  }
  int cached_size = ::google::protobuf::internal::ToCachedSize(total_size);
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = cached_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void RecognitionAudio::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:google.cloud.speech.v1beta1.RecognitionAudio)
  GOOGLE_DCHECK_NE(&from, this);
  const RecognitionAudio* source =
      ::google::protobuf::internal::DynamicCastToGenerated<const RecognitionAudio>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:google.cloud.speech.v1beta1.RecognitionAudio)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:google.cloud.speech.v1beta1.RecognitionAudio)
    MergeFrom(*source);
  }
}

void RecognitionAudio::MergeFrom(const RecognitionAudio& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:google.cloud.speech.v1beta1.RecognitionAudio)
  GOOGLE_DCHECK_NE(&from, this);
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  switch (from.audio_source_case()) {
    case kContent: {
      set_content(from.content());
      break;
    }
    case kUri: {
      set_uri(from.uri());
      break;
    }
    case AUDIO_SOURCE_NOT_SET: {
      break;
    }
  }
}

void RecognitionAudio::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:google.cloud.speech.v1beta1.RecognitionAudio)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void RecognitionAudio::CopyFrom(const RecognitionAudio& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:google.cloud.speech.v1beta1.RecognitionAudio)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool RecognitionAudio::IsInitialized() const {
  return true;
}

void RecognitionAudio::Swap(RecognitionAudio* other) {
  if (other == this) return;
  InternalSwap(other);
}
void RecognitionAudio::InternalSwap(RecognitionAudio* other) {
  std::swap(audio_source_, other->audio_source_);
  std::swap(_oneof_case_[0], other->_oneof_case_[0]);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata RecognitionAudio::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  return file_level_metadata[6];
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// RecognitionAudio

// bytes content = 1;
bool RecognitionAudio::has_content() const {
  return audio_source_case() == kContent;
}
void RecognitionAudio::set_has_content() {
  _oneof_case_[0] = kContent;
}
void RecognitionAudio::clear_content() {
  if (has_content()) {
    audio_source_.content_.DestroyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
    clear_has_audio_source();
  }
}
const ::std::string& RecognitionAudio::content() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.RecognitionAudio.content)
  if (has_content()) {
    return audio_source_.content_.GetNoArena();
  }
  return *&::google::protobuf::internal::GetEmptyStringAlreadyInited();
}
void RecognitionAudio::set_content(const ::std::string& value) {
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.RecognitionAudio.content)
  if (!has_content()) {
    clear_audio_source();
    set_has_content();
    audio_source_.content_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  }
  audio_source_.content_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.RecognitionAudio.content)
}
void RecognitionAudio::set_content(const char* value) {
  if (!has_content()) {
    clear_audio_source();
    set_has_content();
    audio_source_.content_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  }
  audio_source_.content_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(value));
  // @@protoc_insertion_point(field_set_char:google.cloud.speech.v1beta1.RecognitionAudio.content)
}
void RecognitionAudio::set_content(const void* value, size_t size) {
  if (!has_content()) {
    clear_audio_source();
    set_has_content();
    audio_source_.content_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  }
  audio_source_.content_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(
      reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:google.cloud.speech.v1beta1.RecognitionAudio.content)
}
::std::string* RecognitionAudio::mutable_content() {
  if (!has_content()) {
    clear_audio_source();
    set_has_content();
    audio_source_.content_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  }
  // @@protoc_insertion_point(field_mutable:google.cloud.speech.v1beta1.RecognitionAudio.content)
  return audio_source_.content_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
::std::string* RecognitionAudio::release_content() {
  // @@protoc_insertion_point(field_release:google.cloud.speech.v1beta1.RecognitionAudio.content)
  if (has_content()) {
    clear_has_audio_source();
    return audio_source_.content_.ReleaseNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  } else {
    return NULL;
  }
}
void RecognitionAudio::set_allocated_content(::std::string* content) {
  if (!has_content()) {
    audio_source_.content_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  }
  clear_audio_source();
  if (content != NULL) {
    set_has_content();
    audio_source_.content_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
        content);
  }
  // @@protoc_insertion_point(field_set_allocated:google.cloud.speech.v1beta1.RecognitionAudio.content)
}

// string uri = 2;
bool RecognitionAudio::has_uri() const {
  return audio_source_case() == kUri;
}
void RecognitionAudio::set_has_uri() {
  _oneof_case_[0] = kUri;
}
void RecognitionAudio::clear_uri() {
  if (has_uri()) {
    audio_source_.uri_.DestroyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
    clear_has_audio_source();
  }
}
const ::std::string& RecognitionAudio::uri() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.RecognitionAudio.uri)
  if (has_uri()) {
    return audio_source_.uri_.GetNoArena();
  }
  return *&::google::protobuf::internal::GetEmptyStringAlreadyInited();
}
void RecognitionAudio::set_uri(const ::std::string& value) {
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.RecognitionAudio.uri)
  if (!has_uri()) {
    clear_audio_source();
    set_has_uri();
    audio_source_.uri_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  }
  audio_source_.uri_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.RecognitionAudio.uri)
}
void RecognitionAudio::set_uri(const char* value) {
  if (!has_uri()) {
    clear_audio_source();
    set_has_uri();
    audio_source_.uri_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  }
  audio_source_.uri_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(value));
  // @@protoc_insertion_point(field_set_char:google.cloud.speech.v1beta1.RecognitionAudio.uri)
}
void RecognitionAudio::set_uri(const char* value, size_t size) {
  if (!has_uri()) {
    clear_audio_source();
    set_has_uri();
    audio_source_.uri_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  }
  audio_source_.uri_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(
      reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:google.cloud.speech.v1beta1.RecognitionAudio.uri)
}
::std::string* RecognitionAudio::mutable_uri() {
  if (!has_uri()) {
    clear_audio_source();
    set_has_uri();
    audio_source_.uri_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  }
  // @@protoc_insertion_point(field_mutable:google.cloud.speech.v1beta1.RecognitionAudio.uri)
  return audio_source_.uri_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
::std::string* RecognitionAudio::release_uri() {
  // @@protoc_insertion_point(field_release:google.cloud.speech.v1beta1.RecognitionAudio.uri)
  if (has_uri()) {
    clear_has_audio_source();
    return audio_source_.uri_.ReleaseNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  } else {
    return NULL;
  }
}
void RecognitionAudio::set_allocated_uri(::std::string* uri) {
  if (!has_uri()) {
    audio_source_.uri_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  }
  clear_audio_source();
  if (uri != NULL) {
    set_has_uri();
    audio_source_.uri_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
        uri);
  }
  // @@protoc_insertion_point(field_set_allocated:google.cloud.speech.v1beta1.RecognitionAudio.uri)
}

bool RecognitionAudio::has_audio_source() const {
  return audio_source_case() != AUDIO_SOURCE_NOT_SET;
}
void RecognitionAudio::clear_has_audio_source() {
  _oneof_case_[0] = AUDIO_SOURCE_NOT_SET;
}
RecognitionAudio::AudioSourceCase RecognitionAudio::audio_source_case() const {
  return RecognitionAudio::AudioSourceCase(_oneof_case_[0]);
}
#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int SyncRecognizeResponse::kResultsFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

SyncRecognizeResponse::SyncRecognizeResponse()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  if (GOOGLE_PREDICT_TRUE(this != internal_default_instance())) {
    protobuf_InitDefaults_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto();
  }
  SharedCtor();
  // @@protoc_insertion_point(constructor:google.cloud.speech.v1beta1.SyncRecognizeResponse)
}
SyncRecognizeResponse::SyncRecognizeResponse(const SyncRecognizeResponse& from)
  : ::google::protobuf::Message(),
      _internal_metadata_(NULL),
      results_(from.results_),
      _cached_size_(0) {
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  // @@protoc_insertion_point(copy_constructor:google.cloud.speech.v1beta1.SyncRecognizeResponse)
}

void SyncRecognizeResponse::SharedCtor() {
  _cached_size_ = 0;
}

SyncRecognizeResponse::~SyncRecognizeResponse() {
  // @@protoc_insertion_point(destructor:google.cloud.speech.v1beta1.SyncRecognizeResponse)
  SharedDtor();
}

void SyncRecognizeResponse::SharedDtor() {
}

void SyncRecognizeResponse::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* SyncRecognizeResponse::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return file_level_metadata[7].descriptor;
}

const SyncRecognizeResponse& SyncRecognizeResponse::default_instance() {
  protobuf_InitDefaults_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto();
  return *internal_default_instance();
}

SyncRecognizeResponse* SyncRecognizeResponse::New(::google::protobuf::Arena* arena) const {
  SyncRecognizeResponse* n = new SyncRecognizeResponse;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void SyncRecognizeResponse::Clear() {
// @@protoc_insertion_point(message_clear_start:google.cloud.speech.v1beta1.SyncRecognizeResponse)
  results_.Clear();
}

bool SyncRecognizeResponse::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:google.cloud.speech.v1beta1.SyncRecognizeResponse)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoffNoLastTag(127u);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // repeated .google.cloud.speech.v1beta1.SpeechRecognitionResult results = 2;
      case 2: {
        if (tag == 18u) {
          DO_(input->IncrementRecursionDepth());
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtualNoRecursionDepth(
                input, add_results()));
        } else {
          goto handle_unusual;
        }
        input->UnsafeDecrementRecursionDepth();
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:google.cloud.speech.v1beta1.SyncRecognizeResponse)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:google.cloud.speech.v1beta1.SyncRecognizeResponse)
  return false;
#undef DO_
}

void SyncRecognizeResponse::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:google.cloud.speech.v1beta1.SyncRecognizeResponse)
  // repeated .google.cloud.speech.v1beta1.SpeechRecognitionResult results = 2;
  for (unsigned int i = 0, n = this->results_size(); i < n; i++) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      2, this->results(i), output);
  }

  // @@protoc_insertion_point(serialize_end:google.cloud.speech.v1beta1.SyncRecognizeResponse)
}

::google::protobuf::uint8* SyncRecognizeResponse::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  (void)deterministic; // Unused
  // @@protoc_insertion_point(serialize_to_array_start:google.cloud.speech.v1beta1.SyncRecognizeResponse)
  // repeated .google.cloud.speech.v1beta1.SpeechRecognitionResult results = 2;
  for (unsigned int i = 0, n = this->results_size(); i < n; i++) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        2, this->results(i), false, target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:google.cloud.speech.v1beta1.SyncRecognizeResponse)
  return target;
}

size_t SyncRecognizeResponse::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:google.cloud.speech.v1beta1.SyncRecognizeResponse)
  size_t total_size = 0;

  // repeated .google.cloud.speech.v1beta1.SpeechRecognitionResult results = 2;
  {
    unsigned int count = this->results_size();
    total_size += 1UL * count;
    for (unsigned int i = 0; i < count; i++) {
      total_size +=
        ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
          this->results(i));
    }
  }

  int cached_size = ::google::protobuf::internal::ToCachedSize(total_size);
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = cached_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void SyncRecognizeResponse::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:google.cloud.speech.v1beta1.SyncRecognizeResponse)
  GOOGLE_DCHECK_NE(&from, this);
  const SyncRecognizeResponse* source =
      ::google::protobuf::internal::DynamicCastToGenerated<const SyncRecognizeResponse>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:google.cloud.speech.v1beta1.SyncRecognizeResponse)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:google.cloud.speech.v1beta1.SyncRecognizeResponse)
    MergeFrom(*source);
  }
}

void SyncRecognizeResponse::MergeFrom(const SyncRecognizeResponse& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:google.cloud.speech.v1beta1.SyncRecognizeResponse)
  GOOGLE_DCHECK_NE(&from, this);
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  results_.MergeFrom(from.results_);
}

void SyncRecognizeResponse::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:google.cloud.speech.v1beta1.SyncRecognizeResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void SyncRecognizeResponse::CopyFrom(const SyncRecognizeResponse& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:google.cloud.speech.v1beta1.SyncRecognizeResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool SyncRecognizeResponse::IsInitialized() const {
  return true;
}

void SyncRecognizeResponse::Swap(SyncRecognizeResponse* other) {
  if (other == this) return;
  InternalSwap(other);
}
void SyncRecognizeResponse::InternalSwap(SyncRecognizeResponse* other) {
  results_.UnsafeArenaSwap(&other->results_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata SyncRecognizeResponse::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  return file_level_metadata[7];
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// SyncRecognizeResponse

// repeated .google.cloud.speech.v1beta1.SpeechRecognitionResult results = 2;
int SyncRecognizeResponse::results_size() const {
  return results_.size();
}
void SyncRecognizeResponse::clear_results() {
  results_.Clear();
}
const ::google::cloud::speech::v1beta1::SpeechRecognitionResult& SyncRecognizeResponse::results(int index) const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.SyncRecognizeResponse.results)
  return results_.Get(index);
}
::google::cloud::speech::v1beta1::SpeechRecognitionResult* SyncRecognizeResponse::mutable_results(int index) {
  // @@protoc_insertion_point(field_mutable:google.cloud.speech.v1beta1.SyncRecognizeResponse.results)
  return results_.Mutable(index);
}
::google::cloud::speech::v1beta1::SpeechRecognitionResult* SyncRecognizeResponse::add_results() {
  // @@protoc_insertion_point(field_add:google.cloud.speech.v1beta1.SyncRecognizeResponse.results)
  return results_.Add();
}
::google::protobuf::RepeatedPtrField< ::google::cloud::speech::v1beta1::SpeechRecognitionResult >*
SyncRecognizeResponse::mutable_results() {
  // @@protoc_insertion_point(field_mutable_list:google.cloud.speech.v1beta1.SyncRecognizeResponse.results)
  return &results_;
}
const ::google::protobuf::RepeatedPtrField< ::google::cloud::speech::v1beta1::SpeechRecognitionResult >&
SyncRecognizeResponse::results() const {
  // @@protoc_insertion_point(field_list:google.cloud.speech.v1beta1.SyncRecognizeResponse.results)
  return results_;
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int AsyncRecognizeResponse::kResultsFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

AsyncRecognizeResponse::AsyncRecognizeResponse()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  if (GOOGLE_PREDICT_TRUE(this != internal_default_instance())) {
    protobuf_InitDefaults_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto();
  }
  SharedCtor();
  // @@protoc_insertion_point(constructor:google.cloud.speech.v1beta1.AsyncRecognizeResponse)
}
AsyncRecognizeResponse::AsyncRecognizeResponse(const AsyncRecognizeResponse& from)
  : ::google::protobuf::Message(),
      _internal_metadata_(NULL),
      results_(from.results_),
      _cached_size_(0) {
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  // @@protoc_insertion_point(copy_constructor:google.cloud.speech.v1beta1.AsyncRecognizeResponse)
}

void AsyncRecognizeResponse::SharedCtor() {
  _cached_size_ = 0;
}

AsyncRecognizeResponse::~AsyncRecognizeResponse() {
  // @@protoc_insertion_point(destructor:google.cloud.speech.v1beta1.AsyncRecognizeResponse)
  SharedDtor();
}

void AsyncRecognizeResponse::SharedDtor() {
}

void AsyncRecognizeResponse::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* AsyncRecognizeResponse::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return file_level_metadata[8].descriptor;
}

const AsyncRecognizeResponse& AsyncRecognizeResponse::default_instance() {
  protobuf_InitDefaults_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto();
  return *internal_default_instance();
}

AsyncRecognizeResponse* AsyncRecognizeResponse::New(::google::protobuf::Arena* arena) const {
  AsyncRecognizeResponse* n = new AsyncRecognizeResponse;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void AsyncRecognizeResponse::Clear() {
// @@protoc_insertion_point(message_clear_start:google.cloud.speech.v1beta1.AsyncRecognizeResponse)
  results_.Clear();
}

bool AsyncRecognizeResponse::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:google.cloud.speech.v1beta1.AsyncRecognizeResponse)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoffNoLastTag(127u);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // repeated .google.cloud.speech.v1beta1.SpeechRecognitionResult results = 2;
      case 2: {
        if (tag == 18u) {
          DO_(input->IncrementRecursionDepth());
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtualNoRecursionDepth(
                input, add_results()));
        } else {
          goto handle_unusual;
        }
        input->UnsafeDecrementRecursionDepth();
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:google.cloud.speech.v1beta1.AsyncRecognizeResponse)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:google.cloud.speech.v1beta1.AsyncRecognizeResponse)
  return false;
#undef DO_
}

void AsyncRecognizeResponse::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:google.cloud.speech.v1beta1.AsyncRecognizeResponse)
  // repeated .google.cloud.speech.v1beta1.SpeechRecognitionResult results = 2;
  for (unsigned int i = 0, n = this->results_size(); i < n; i++) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      2, this->results(i), output);
  }

  // @@protoc_insertion_point(serialize_end:google.cloud.speech.v1beta1.AsyncRecognizeResponse)
}

::google::protobuf::uint8* AsyncRecognizeResponse::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  (void)deterministic; // Unused
  // @@protoc_insertion_point(serialize_to_array_start:google.cloud.speech.v1beta1.AsyncRecognizeResponse)
  // repeated .google.cloud.speech.v1beta1.SpeechRecognitionResult results = 2;
  for (unsigned int i = 0, n = this->results_size(); i < n; i++) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        2, this->results(i), false, target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:google.cloud.speech.v1beta1.AsyncRecognizeResponse)
  return target;
}

size_t AsyncRecognizeResponse::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:google.cloud.speech.v1beta1.AsyncRecognizeResponse)
  size_t total_size = 0;

  // repeated .google.cloud.speech.v1beta1.SpeechRecognitionResult results = 2;
  {
    unsigned int count = this->results_size();
    total_size += 1UL * count;
    for (unsigned int i = 0; i < count; i++) {
      total_size +=
        ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
          this->results(i));
    }
  }

  int cached_size = ::google::protobuf::internal::ToCachedSize(total_size);
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = cached_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void AsyncRecognizeResponse::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:google.cloud.speech.v1beta1.AsyncRecognizeResponse)
  GOOGLE_DCHECK_NE(&from, this);
  const AsyncRecognizeResponse* source =
      ::google::protobuf::internal::DynamicCastToGenerated<const AsyncRecognizeResponse>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:google.cloud.speech.v1beta1.AsyncRecognizeResponse)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:google.cloud.speech.v1beta1.AsyncRecognizeResponse)
    MergeFrom(*source);
  }
}

void AsyncRecognizeResponse::MergeFrom(const AsyncRecognizeResponse& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:google.cloud.speech.v1beta1.AsyncRecognizeResponse)
  GOOGLE_DCHECK_NE(&from, this);
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  results_.MergeFrom(from.results_);
}

void AsyncRecognizeResponse::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:google.cloud.speech.v1beta1.AsyncRecognizeResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void AsyncRecognizeResponse::CopyFrom(const AsyncRecognizeResponse& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:google.cloud.speech.v1beta1.AsyncRecognizeResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool AsyncRecognizeResponse::IsInitialized() const {
  return true;
}

void AsyncRecognizeResponse::Swap(AsyncRecognizeResponse* other) {
  if (other == this) return;
  InternalSwap(other);
}
void AsyncRecognizeResponse::InternalSwap(AsyncRecognizeResponse* other) {
  results_.UnsafeArenaSwap(&other->results_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata AsyncRecognizeResponse::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  return file_level_metadata[8];
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// AsyncRecognizeResponse

// repeated .google.cloud.speech.v1beta1.SpeechRecognitionResult results = 2;
int AsyncRecognizeResponse::results_size() const {
  return results_.size();
}
void AsyncRecognizeResponse::clear_results() {
  results_.Clear();
}
const ::google::cloud::speech::v1beta1::SpeechRecognitionResult& AsyncRecognizeResponse::results(int index) const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.AsyncRecognizeResponse.results)
  return results_.Get(index);
}
::google::cloud::speech::v1beta1::SpeechRecognitionResult* AsyncRecognizeResponse::mutable_results(int index) {
  // @@protoc_insertion_point(field_mutable:google.cloud.speech.v1beta1.AsyncRecognizeResponse.results)
  return results_.Mutable(index);
}
::google::cloud::speech::v1beta1::SpeechRecognitionResult* AsyncRecognizeResponse::add_results() {
  // @@protoc_insertion_point(field_add:google.cloud.speech.v1beta1.AsyncRecognizeResponse.results)
  return results_.Add();
}
::google::protobuf::RepeatedPtrField< ::google::cloud::speech::v1beta1::SpeechRecognitionResult >*
AsyncRecognizeResponse::mutable_results() {
  // @@protoc_insertion_point(field_mutable_list:google.cloud.speech.v1beta1.AsyncRecognizeResponse.results)
  return &results_;
}
const ::google::protobuf::RepeatedPtrField< ::google::cloud::speech::v1beta1::SpeechRecognitionResult >&
AsyncRecognizeResponse::results() const {
  // @@protoc_insertion_point(field_list:google.cloud.speech.v1beta1.AsyncRecognizeResponse.results)
  return results_;
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int AsyncRecognizeMetadata::kProgressPercentFieldNumber;
const int AsyncRecognizeMetadata::kStartTimeFieldNumber;
const int AsyncRecognizeMetadata::kLastUpdateTimeFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

AsyncRecognizeMetadata::AsyncRecognizeMetadata()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  if (GOOGLE_PREDICT_TRUE(this != internal_default_instance())) {
    protobuf_InitDefaults_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto();
  }
  SharedCtor();
  // @@protoc_insertion_point(constructor:google.cloud.speech.v1beta1.AsyncRecognizeMetadata)
}
AsyncRecognizeMetadata::AsyncRecognizeMetadata(const AsyncRecognizeMetadata& from)
  : ::google::protobuf::Message(),
      _internal_metadata_(NULL),
      _cached_size_(0) {
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  if (from.has_start_time()) {
    start_time_ = new ::google::protobuf::Timestamp(*from.start_time_);
  } else {
    start_time_ = NULL;
  }
  if (from.has_last_update_time()) {
    last_update_time_ = new ::google::protobuf::Timestamp(*from.last_update_time_);
  } else {
    last_update_time_ = NULL;
  }
  progress_percent_ = from.progress_percent_;
  // @@protoc_insertion_point(copy_constructor:google.cloud.speech.v1beta1.AsyncRecognizeMetadata)
}

void AsyncRecognizeMetadata::SharedCtor() {
  ::memset(&start_time_, 0, reinterpret_cast<char*>(&progress_percent_) -
    reinterpret_cast<char*>(&start_time_) + sizeof(progress_percent_));
  _cached_size_ = 0;
}

AsyncRecognizeMetadata::~AsyncRecognizeMetadata() {
  // @@protoc_insertion_point(destructor:google.cloud.speech.v1beta1.AsyncRecognizeMetadata)
  SharedDtor();
}

void AsyncRecognizeMetadata::SharedDtor() {
  if (this != internal_default_instance()) {
    delete start_time_;
  }
  if (this != internal_default_instance()) {
    delete last_update_time_;
  }
}

void AsyncRecognizeMetadata::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* AsyncRecognizeMetadata::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return file_level_metadata[9].descriptor;
}

const AsyncRecognizeMetadata& AsyncRecognizeMetadata::default_instance() {
  protobuf_InitDefaults_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto();
  return *internal_default_instance();
}

AsyncRecognizeMetadata* AsyncRecognizeMetadata::New(::google::protobuf::Arena* arena) const {
  AsyncRecognizeMetadata* n = new AsyncRecognizeMetadata;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void AsyncRecognizeMetadata::Clear() {
// @@protoc_insertion_point(message_clear_start:google.cloud.speech.v1beta1.AsyncRecognizeMetadata)
  if (GetArenaNoVirtual() == NULL && start_time_ != NULL) {
    delete start_time_;
  }
  start_time_ = NULL;
  if (GetArenaNoVirtual() == NULL && last_update_time_ != NULL) {
    delete last_update_time_;
  }
  last_update_time_ = NULL;
  progress_percent_ = 0;
}

bool AsyncRecognizeMetadata::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:google.cloud.speech.v1beta1.AsyncRecognizeMetadata)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoffNoLastTag(127u);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // int32 progress_percent = 1;
      case 1: {
        if (tag == 8u) {

          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int32, ::google::protobuf::internal::WireFormatLite::TYPE_INT32>(
                 input, &progress_percent_)));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // .google.protobuf.Timestamp start_time = 2;
      case 2: {
        if (tag == 18u) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_start_time()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // .google.protobuf.Timestamp last_update_time = 3;
      case 3: {
        if (tag == 26u) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_last_update_time()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:google.cloud.speech.v1beta1.AsyncRecognizeMetadata)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:google.cloud.speech.v1beta1.AsyncRecognizeMetadata)
  return false;
#undef DO_
}

void AsyncRecognizeMetadata::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:google.cloud.speech.v1beta1.AsyncRecognizeMetadata)
  // int32 progress_percent = 1;
  if (this->progress_percent() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteInt32(1, this->progress_percent(), output);
  }

  // .google.protobuf.Timestamp start_time = 2;
  if (this->has_start_time()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      2, *this->start_time_, output);
  }

  // .google.protobuf.Timestamp last_update_time = 3;
  if (this->has_last_update_time()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      3, *this->last_update_time_, output);
  }

  // @@protoc_insertion_point(serialize_end:google.cloud.speech.v1beta1.AsyncRecognizeMetadata)
}

::google::protobuf::uint8* AsyncRecognizeMetadata::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  (void)deterministic; // Unused
  // @@protoc_insertion_point(serialize_to_array_start:google.cloud.speech.v1beta1.AsyncRecognizeMetadata)
  // int32 progress_percent = 1;
  if (this->progress_percent() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt32ToArray(1, this->progress_percent(), target);
  }

  // .google.protobuf.Timestamp start_time = 2;
  if (this->has_start_time()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        2, *this->start_time_, false, target);
  }

  // .google.protobuf.Timestamp last_update_time = 3;
  if (this->has_last_update_time()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        3, *this->last_update_time_, false, target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:google.cloud.speech.v1beta1.AsyncRecognizeMetadata)
  return target;
}

size_t AsyncRecognizeMetadata::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:google.cloud.speech.v1beta1.AsyncRecognizeMetadata)
  size_t total_size = 0;

  // .google.protobuf.Timestamp start_time = 2;
  if (this->has_start_time()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->start_time_);
  }

  // .google.protobuf.Timestamp last_update_time = 3;
  if (this->has_last_update_time()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->last_update_time_);
  }

  // int32 progress_percent = 1;
  if (this->progress_percent() != 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::Int32Size(
        this->progress_percent());
  }

  int cached_size = ::google::protobuf::internal::ToCachedSize(total_size);
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = cached_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void AsyncRecognizeMetadata::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:google.cloud.speech.v1beta1.AsyncRecognizeMetadata)
  GOOGLE_DCHECK_NE(&from, this);
  const AsyncRecognizeMetadata* source =
      ::google::protobuf::internal::DynamicCastToGenerated<const AsyncRecognizeMetadata>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:google.cloud.speech.v1beta1.AsyncRecognizeMetadata)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:google.cloud.speech.v1beta1.AsyncRecognizeMetadata)
    MergeFrom(*source);
  }
}

void AsyncRecognizeMetadata::MergeFrom(const AsyncRecognizeMetadata& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:google.cloud.speech.v1beta1.AsyncRecognizeMetadata)
  GOOGLE_DCHECK_NE(&from, this);
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  if (from.has_start_time()) {
    mutable_start_time()->::google::protobuf::Timestamp::MergeFrom(from.start_time());
  }
  if (from.has_last_update_time()) {
    mutable_last_update_time()->::google::protobuf::Timestamp::MergeFrom(from.last_update_time());
  }
  if (from.progress_percent() != 0) {
    set_progress_percent(from.progress_percent());
  }
}

void AsyncRecognizeMetadata::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:google.cloud.speech.v1beta1.AsyncRecognizeMetadata)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void AsyncRecognizeMetadata::CopyFrom(const AsyncRecognizeMetadata& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:google.cloud.speech.v1beta1.AsyncRecognizeMetadata)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool AsyncRecognizeMetadata::IsInitialized() const {
  return true;
}

void AsyncRecognizeMetadata::Swap(AsyncRecognizeMetadata* other) {
  if (other == this) return;
  InternalSwap(other);
}
void AsyncRecognizeMetadata::InternalSwap(AsyncRecognizeMetadata* other) {
  std::swap(start_time_, other->start_time_);
  std::swap(last_update_time_, other->last_update_time_);
  std::swap(progress_percent_, other->progress_percent_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata AsyncRecognizeMetadata::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  return file_level_metadata[9];
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// AsyncRecognizeMetadata

// int32 progress_percent = 1;
void AsyncRecognizeMetadata::clear_progress_percent() {
  progress_percent_ = 0;
}
::google::protobuf::int32 AsyncRecognizeMetadata::progress_percent() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.AsyncRecognizeMetadata.progress_percent)
  return progress_percent_;
}
void AsyncRecognizeMetadata::set_progress_percent(::google::protobuf::int32 value) {
  
  progress_percent_ = value;
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.AsyncRecognizeMetadata.progress_percent)
}

// .google.protobuf.Timestamp start_time = 2;
bool AsyncRecognizeMetadata::has_start_time() const {
  return this != internal_default_instance() && start_time_ != NULL;
}
void AsyncRecognizeMetadata::clear_start_time() {
  if (GetArenaNoVirtual() == NULL && start_time_ != NULL) delete start_time_;
  start_time_ = NULL;
}
const ::google::protobuf::Timestamp& AsyncRecognizeMetadata::start_time() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.AsyncRecognizeMetadata.start_time)
  return start_time_ != NULL ? *start_time_
                         : *::google::protobuf::Timestamp::internal_default_instance();
}
::google::protobuf::Timestamp* AsyncRecognizeMetadata::mutable_start_time() {
  
  if (start_time_ == NULL) {
    start_time_ = new ::google::protobuf::Timestamp;
  }
  // @@protoc_insertion_point(field_mutable:google.cloud.speech.v1beta1.AsyncRecognizeMetadata.start_time)
  return start_time_;
}
::google::protobuf::Timestamp* AsyncRecognizeMetadata::release_start_time() {
  // @@protoc_insertion_point(field_release:google.cloud.speech.v1beta1.AsyncRecognizeMetadata.start_time)
  
  ::google::protobuf::Timestamp* temp = start_time_;
  start_time_ = NULL;
  return temp;
}
void AsyncRecognizeMetadata::set_allocated_start_time(::google::protobuf::Timestamp* start_time) {
  delete start_time_;
  if (start_time != NULL && start_time->GetArena() != NULL) {
    ::google::protobuf::Timestamp* new_start_time = new ::google::protobuf::Timestamp;
    new_start_time->CopyFrom(*start_time);
    start_time = new_start_time;
  }
  start_time_ = start_time;
  if (start_time) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:google.cloud.speech.v1beta1.AsyncRecognizeMetadata.start_time)
}

// .google.protobuf.Timestamp last_update_time = 3;
bool AsyncRecognizeMetadata::has_last_update_time() const {
  return this != internal_default_instance() && last_update_time_ != NULL;
}
void AsyncRecognizeMetadata::clear_last_update_time() {
  if (GetArenaNoVirtual() == NULL && last_update_time_ != NULL) delete last_update_time_;
  last_update_time_ = NULL;
}
const ::google::protobuf::Timestamp& AsyncRecognizeMetadata::last_update_time() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.AsyncRecognizeMetadata.last_update_time)
  return last_update_time_ != NULL ? *last_update_time_
                         : *::google::protobuf::Timestamp::internal_default_instance();
}
::google::protobuf::Timestamp* AsyncRecognizeMetadata::mutable_last_update_time() {
  
  if (last_update_time_ == NULL) {
    last_update_time_ = new ::google::protobuf::Timestamp;
  }
  // @@protoc_insertion_point(field_mutable:google.cloud.speech.v1beta1.AsyncRecognizeMetadata.last_update_time)
  return last_update_time_;
}
::google::protobuf::Timestamp* AsyncRecognizeMetadata::release_last_update_time() {
  // @@protoc_insertion_point(field_release:google.cloud.speech.v1beta1.AsyncRecognizeMetadata.last_update_time)
  
  ::google::protobuf::Timestamp* temp = last_update_time_;
  last_update_time_ = NULL;
  return temp;
}
void AsyncRecognizeMetadata::set_allocated_last_update_time(::google::protobuf::Timestamp* last_update_time) {
  delete last_update_time_;
  if (last_update_time != NULL && last_update_time->GetArena() != NULL) {
    ::google::protobuf::Timestamp* new_last_update_time = new ::google::protobuf::Timestamp;
    new_last_update_time->CopyFrom(*last_update_time);
    last_update_time = new_last_update_time;
  }
  last_update_time_ = last_update_time;
  if (last_update_time) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:google.cloud.speech.v1beta1.AsyncRecognizeMetadata.last_update_time)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int StreamingRecognizeResponse::kErrorFieldNumber;
const int StreamingRecognizeResponse::kResultsFieldNumber;
const int StreamingRecognizeResponse::kResultIndexFieldNumber;
const int StreamingRecognizeResponse::kEndpointerTypeFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

StreamingRecognizeResponse::StreamingRecognizeResponse()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  if (GOOGLE_PREDICT_TRUE(this != internal_default_instance())) {
    protobuf_InitDefaults_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto();
  }
  SharedCtor();
  // @@protoc_insertion_point(constructor:google.cloud.speech.v1beta1.StreamingRecognizeResponse)
}
StreamingRecognizeResponse::StreamingRecognizeResponse(const StreamingRecognizeResponse& from)
  : ::google::protobuf::Message(),
      _internal_metadata_(NULL),
      results_(from.results_),
      _cached_size_(0) {
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  if (from.has_error()) {
    error_ = new ::google::rpc::Status(*from.error_);
  } else {
    error_ = NULL;
  }
  ::memcpy(&result_index_, &from.result_index_,
    reinterpret_cast<char*>(&endpointer_type_) -
    reinterpret_cast<char*>(&result_index_) + sizeof(endpointer_type_));
  // @@protoc_insertion_point(copy_constructor:google.cloud.speech.v1beta1.StreamingRecognizeResponse)
}

void StreamingRecognizeResponse::SharedCtor() {
  ::memset(&error_, 0, reinterpret_cast<char*>(&endpointer_type_) -
    reinterpret_cast<char*>(&error_) + sizeof(endpointer_type_));
  _cached_size_ = 0;
}

StreamingRecognizeResponse::~StreamingRecognizeResponse() {
  // @@protoc_insertion_point(destructor:google.cloud.speech.v1beta1.StreamingRecognizeResponse)
  SharedDtor();
}

void StreamingRecognizeResponse::SharedDtor() {
  if (this != internal_default_instance()) {
    delete error_;
  }
}

void StreamingRecognizeResponse::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* StreamingRecognizeResponse::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return file_level_metadata[10].descriptor;
}

const StreamingRecognizeResponse& StreamingRecognizeResponse::default_instance() {
  protobuf_InitDefaults_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto();
  return *internal_default_instance();
}

StreamingRecognizeResponse* StreamingRecognizeResponse::New(::google::protobuf::Arena* arena) const {
  StreamingRecognizeResponse* n = new StreamingRecognizeResponse;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void StreamingRecognizeResponse::Clear() {
// @@protoc_insertion_point(message_clear_start:google.cloud.speech.v1beta1.StreamingRecognizeResponse)
  results_.Clear();
  if (GetArenaNoVirtual() == NULL && error_ != NULL) {
    delete error_;
  }
  error_ = NULL;
  ::memset(&result_index_, 0, reinterpret_cast<char*>(&endpointer_type_) -
    reinterpret_cast<char*>(&result_index_) + sizeof(endpointer_type_));
}

bool StreamingRecognizeResponse::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:google.cloud.speech.v1beta1.StreamingRecognizeResponse)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoffNoLastTag(127u);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // .google.rpc.Status error = 1;
      case 1: {
        if (tag == 10u) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_error()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // repeated .google.cloud.speech.v1beta1.StreamingRecognitionResult results = 2;
      case 2: {
        if (tag == 18u) {
          DO_(input->IncrementRecursionDepth());
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtualNoRecursionDepth(
                input, add_results()));
        } else {
          goto handle_unusual;
        }
        input->UnsafeDecrementRecursionDepth();
        break;
      }

      // int32 result_index = 3;
      case 3: {
        if (tag == 24u) {

          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int32, ::google::protobuf::internal::WireFormatLite::TYPE_INT32>(
                 input, &result_index_)));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // .google.cloud.speech.v1beta1.StreamingRecognizeResponse.EndpointerType endpointer_type = 4;
      case 4: {
        if (tag == 32u) {
          int value;
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   int, ::google::protobuf::internal::WireFormatLite::TYPE_ENUM>(
                 input, &value)));
          set_endpointer_type(static_cast< ::google::cloud::speech::v1beta1::StreamingRecognizeResponse_EndpointerType >(value));
        } else {
          goto handle_unusual;
        }
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:google.cloud.speech.v1beta1.StreamingRecognizeResponse)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:google.cloud.speech.v1beta1.StreamingRecognizeResponse)
  return false;
#undef DO_
}

void StreamingRecognizeResponse::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:google.cloud.speech.v1beta1.StreamingRecognizeResponse)
  // .google.rpc.Status error = 1;
  if (this->has_error()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, *this->error_, output);
  }

  // repeated .google.cloud.speech.v1beta1.StreamingRecognitionResult results = 2;
  for (unsigned int i = 0, n = this->results_size(); i < n; i++) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      2, this->results(i), output);
  }

  // int32 result_index = 3;
  if (this->result_index() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteInt32(3, this->result_index(), output);
  }

  // .google.cloud.speech.v1beta1.StreamingRecognizeResponse.EndpointerType endpointer_type = 4;
  if (this->endpointer_type() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteEnum(
      4, this->endpointer_type(), output);
  }

  // @@protoc_insertion_point(serialize_end:google.cloud.speech.v1beta1.StreamingRecognizeResponse)
}

::google::protobuf::uint8* StreamingRecognizeResponse::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  (void)deterministic; // Unused
  // @@protoc_insertion_point(serialize_to_array_start:google.cloud.speech.v1beta1.StreamingRecognizeResponse)
  // .google.rpc.Status error = 1;
  if (this->has_error()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        1, *this->error_, false, target);
  }

  // repeated .google.cloud.speech.v1beta1.StreamingRecognitionResult results = 2;
  for (unsigned int i = 0, n = this->results_size(); i < n; i++) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        2, this->results(i), false, target);
  }

  // int32 result_index = 3;
  if (this->result_index() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt32ToArray(3, this->result_index(), target);
  }

  // .google.cloud.speech.v1beta1.StreamingRecognizeResponse.EndpointerType endpointer_type = 4;
  if (this->endpointer_type() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteEnumToArray(
      4, this->endpointer_type(), target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:google.cloud.speech.v1beta1.StreamingRecognizeResponse)
  return target;
}

size_t StreamingRecognizeResponse::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:google.cloud.speech.v1beta1.StreamingRecognizeResponse)
  size_t total_size = 0;

  // repeated .google.cloud.speech.v1beta1.StreamingRecognitionResult results = 2;
  {
    unsigned int count = this->results_size();
    total_size += 1UL * count;
    for (unsigned int i = 0; i < count; i++) {
      total_size +=
        ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
          this->results(i));
    }
  }

  // .google.rpc.Status error = 1;
  if (this->has_error()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->error_);
  }

  // int32 result_index = 3;
  if (this->result_index() != 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::Int32Size(
        this->result_index());
  }

  // .google.cloud.speech.v1beta1.StreamingRecognizeResponse.EndpointerType endpointer_type = 4;
  if (this->endpointer_type() != 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::EnumSize(this->endpointer_type());
  }

  int cached_size = ::google::protobuf::internal::ToCachedSize(total_size);
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = cached_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void StreamingRecognizeResponse::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:google.cloud.speech.v1beta1.StreamingRecognizeResponse)
  GOOGLE_DCHECK_NE(&from, this);
  const StreamingRecognizeResponse* source =
      ::google::protobuf::internal::DynamicCastToGenerated<const StreamingRecognizeResponse>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:google.cloud.speech.v1beta1.StreamingRecognizeResponse)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:google.cloud.speech.v1beta1.StreamingRecognizeResponse)
    MergeFrom(*source);
  }
}

void StreamingRecognizeResponse::MergeFrom(const StreamingRecognizeResponse& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:google.cloud.speech.v1beta1.StreamingRecognizeResponse)
  GOOGLE_DCHECK_NE(&from, this);
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  results_.MergeFrom(from.results_);
  if (from.has_error()) {
    mutable_error()->::google::rpc::Status::MergeFrom(from.error());
  }
  if (from.result_index() != 0) {
    set_result_index(from.result_index());
  }
  if (from.endpointer_type() != 0) {
    set_endpointer_type(from.endpointer_type());
  }
}

void StreamingRecognizeResponse::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:google.cloud.speech.v1beta1.StreamingRecognizeResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void StreamingRecognizeResponse::CopyFrom(const StreamingRecognizeResponse& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:google.cloud.speech.v1beta1.StreamingRecognizeResponse)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool StreamingRecognizeResponse::IsInitialized() const {
  return true;
}

void StreamingRecognizeResponse::Swap(StreamingRecognizeResponse* other) {
  if (other == this) return;
  InternalSwap(other);
}
void StreamingRecognizeResponse::InternalSwap(StreamingRecognizeResponse* other) {
  results_.UnsafeArenaSwap(&other->results_);
  std::swap(error_, other->error_);
  std::swap(result_index_, other->result_index_);
  std::swap(endpointer_type_, other->endpointer_type_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata StreamingRecognizeResponse::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  return file_level_metadata[10];
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// StreamingRecognizeResponse

// .google.rpc.Status error = 1;
bool StreamingRecognizeResponse::has_error() const {
  return this != internal_default_instance() && error_ != NULL;
}
void StreamingRecognizeResponse::clear_error() {
  if (GetArenaNoVirtual() == NULL && error_ != NULL) delete error_;
  error_ = NULL;
}
const ::google::rpc::Status& StreamingRecognizeResponse::error() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.StreamingRecognizeResponse.error)
  return error_ != NULL ? *error_
                         : *::google::rpc::Status::internal_default_instance();
}
::google::rpc::Status* StreamingRecognizeResponse::mutable_error() {
  
  if (error_ == NULL) {
    error_ = new ::google::rpc::Status;
  }
  // @@protoc_insertion_point(field_mutable:google.cloud.speech.v1beta1.StreamingRecognizeResponse.error)
  return error_;
}
::google::rpc::Status* StreamingRecognizeResponse::release_error() {
  // @@protoc_insertion_point(field_release:google.cloud.speech.v1beta1.StreamingRecognizeResponse.error)
  
  ::google::rpc::Status* temp = error_;
  error_ = NULL;
  return temp;
}
void StreamingRecognizeResponse::set_allocated_error(::google::rpc::Status* error) {
  delete error_;
  error_ = error;
  if (error) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:google.cloud.speech.v1beta1.StreamingRecognizeResponse.error)
}

// repeated .google.cloud.speech.v1beta1.StreamingRecognitionResult results = 2;
int StreamingRecognizeResponse::results_size() const {
  return results_.size();
}
void StreamingRecognizeResponse::clear_results() {
  results_.Clear();
}
const ::google::cloud::speech::v1beta1::StreamingRecognitionResult& StreamingRecognizeResponse::results(int index) const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.StreamingRecognizeResponse.results)
  return results_.Get(index);
}
::google::cloud::speech::v1beta1::StreamingRecognitionResult* StreamingRecognizeResponse::mutable_results(int index) {
  // @@protoc_insertion_point(field_mutable:google.cloud.speech.v1beta1.StreamingRecognizeResponse.results)
  return results_.Mutable(index);
}
::google::cloud::speech::v1beta1::StreamingRecognitionResult* StreamingRecognizeResponse::add_results() {
  // @@protoc_insertion_point(field_add:google.cloud.speech.v1beta1.StreamingRecognizeResponse.results)
  return results_.Add();
}
::google::protobuf::RepeatedPtrField< ::google::cloud::speech::v1beta1::StreamingRecognitionResult >*
StreamingRecognizeResponse::mutable_results() {
  // @@protoc_insertion_point(field_mutable_list:google.cloud.speech.v1beta1.StreamingRecognizeResponse.results)
  return &results_;
}
const ::google::protobuf::RepeatedPtrField< ::google::cloud::speech::v1beta1::StreamingRecognitionResult >&
StreamingRecognizeResponse::results() const {
  // @@protoc_insertion_point(field_list:google.cloud.speech.v1beta1.StreamingRecognizeResponse.results)
  return results_;
}

// int32 result_index = 3;
void StreamingRecognizeResponse::clear_result_index() {
  result_index_ = 0;
}
::google::protobuf::int32 StreamingRecognizeResponse::result_index() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.StreamingRecognizeResponse.result_index)
  return result_index_;
}
void StreamingRecognizeResponse::set_result_index(::google::protobuf::int32 value) {
  
  result_index_ = value;
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.StreamingRecognizeResponse.result_index)
}

// .google.cloud.speech.v1beta1.StreamingRecognizeResponse.EndpointerType endpointer_type = 4;
void StreamingRecognizeResponse::clear_endpointer_type() {
  endpointer_type_ = 0;
}
::google::cloud::speech::v1beta1::StreamingRecognizeResponse_EndpointerType StreamingRecognizeResponse::endpointer_type() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.StreamingRecognizeResponse.endpointer_type)
  return static_cast< ::google::cloud::speech::v1beta1::StreamingRecognizeResponse_EndpointerType >(endpointer_type_);
}
void StreamingRecognizeResponse::set_endpointer_type(::google::cloud::speech::v1beta1::StreamingRecognizeResponse_EndpointerType value) {
  
  endpointer_type_ = value;
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.StreamingRecognizeResponse.endpointer_type)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int StreamingRecognitionResult::kAlternativesFieldNumber;
const int StreamingRecognitionResult::kIsFinalFieldNumber;
const int StreamingRecognitionResult::kStabilityFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

StreamingRecognitionResult::StreamingRecognitionResult()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  if (GOOGLE_PREDICT_TRUE(this != internal_default_instance())) {
    protobuf_InitDefaults_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto();
  }
  SharedCtor();
  // @@protoc_insertion_point(constructor:google.cloud.speech.v1beta1.StreamingRecognitionResult)
}
StreamingRecognitionResult::StreamingRecognitionResult(const StreamingRecognitionResult& from)
  : ::google::protobuf::Message(),
      _internal_metadata_(NULL),
      alternatives_(from.alternatives_),
      _cached_size_(0) {
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  ::memcpy(&is_final_, &from.is_final_,
    reinterpret_cast<char*>(&stability_) -
    reinterpret_cast<char*>(&is_final_) + sizeof(stability_));
  // @@protoc_insertion_point(copy_constructor:google.cloud.speech.v1beta1.StreamingRecognitionResult)
}

void StreamingRecognitionResult::SharedCtor() {
  ::memset(&is_final_, 0, reinterpret_cast<char*>(&stability_) -
    reinterpret_cast<char*>(&is_final_) + sizeof(stability_));
  _cached_size_ = 0;
}

StreamingRecognitionResult::~StreamingRecognitionResult() {
  // @@protoc_insertion_point(destructor:google.cloud.speech.v1beta1.StreamingRecognitionResult)
  SharedDtor();
}

void StreamingRecognitionResult::SharedDtor() {
}

void StreamingRecognitionResult::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* StreamingRecognitionResult::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return file_level_metadata[11].descriptor;
}

const StreamingRecognitionResult& StreamingRecognitionResult::default_instance() {
  protobuf_InitDefaults_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto();
  return *internal_default_instance();
}

StreamingRecognitionResult* StreamingRecognitionResult::New(::google::protobuf::Arena* arena) const {
  StreamingRecognitionResult* n = new StreamingRecognitionResult;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void StreamingRecognitionResult::Clear() {
// @@protoc_insertion_point(message_clear_start:google.cloud.speech.v1beta1.StreamingRecognitionResult)
  alternatives_.Clear();
  ::memset(&is_final_, 0, reinterpret_cast<char*>(&stability_) -
    reinterpret_cast<char*>(&is_final_) + sizeof(stability_));
}

bool StreamingRecognitionResult::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:google.cloud.speech.v1beta1.StreamingRecognitionResult)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoffNoLastTag(127u);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // repeated .google.cloud.speech.v1beta1.SpeechRecognitionAlternative alternatives = 1;
      case 1: {
        if (tag == 10u) {
          DO_(input->IncrementRecursionDepth());
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtualNoRecursionDepth(
                input, add_alternatives()));
        } else {
          goto handle_unusual;
        }
        input->UnsafeDecrementRecursionDepth();
        break;
      }

      // bool is_final = 2;
      case 2: {
        if (tag == 16u) {

          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   bool, ::google::protobuf::internal::WireFormatLite::TYPE_BOOL>(
                 input, &is_final_)));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // float stability = 3;
      case 3: {
        if (tag == 29u) {

          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   float, ::google::protobuf::internal::WireFormatLite::TYPE_FLOAT>(
                 input, &stability_)));
        } else {
          goto handle_unusual;
        }
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:google.cloud.speech.v1beta1.StreamingRecognitionResult)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:google.cloud.speech.v1beta1.StreamingRecognitionResult)
  return false;
#undef DO_
}

void StreamingRecognitionResult::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:google.cloud.speech.v1beta1.StreamingRecognitionResult)
  // repeated .google.cloud.speech.v1beta1.SpeechRecognitionAlternative alternatives = 1;
  for (unsigned int i = 0, n = this->alternatives_size(); i < n; i++) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, this->alternatives(i), output);
  }

  // bool is_final = 2;
  if (this->is_final() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteBool(2, this->is_final(), output);
  }

  // float stability = 3;
  if (this->stability() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteFloat(3, this->stability(), output);
  }

  // @@protoc_insertion_point(serialize_end:google.cloud.speech.v1beta1.StreamingRecognitionResult)
}

::google::protobuf::uint8* StreamingRecognitionResult::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  (void)deterministic; // Unused
  // @@protoc_insertion_point(serialize_to_array_start:google.cloud.speech.v1beta1.StreamingRecognitionResult)
  // repeated .google.cloud.speech.v1beta1.SpeechRecognitionAlternative alternatives = 1;
  for (unsigned int i = 0, n = this->alternatives_size(); i < n; i++) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        1, this->alternatives(i), false, target);
  }

  // bool is_final = 2;
  if (this->is_final() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteBoolToArray(2, this->is_final(), target);
  }

  // float stability = 3;
  if (this->stability() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteFloatToArray(3, this->stability(), target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:google.cloud.speech.v1beta1.StreamingRecognitionResult)
  return target;
}

size_t StreamingRecognitionResult::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:google.cloud.speech.v1beta1.StreamingRecognitionResult)
  size_t total_size = 0;

  // repeated .google.cloud.speech.v1beta1.SpeechRecognitionAlternative alternatives = 1;
  {
    unsigned int count = this->alternatives_size();
    total_size += 1UL * count;
    for (unsigned int i = 0; i < count; i++) {
      total_size +=
        ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
          this->alternatives(i));
    }
  }

  // bool is_final = 2;
  if (this->is_final() != 0) {
    total_size += 1 + 1;
  }

  // float stability = 3;
  if (this->stability() != 0) {
    total_size += 1 + 4;
  }

  int cached_size = ::google::protobuf::internal::ToCachedSize(total_size);
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = cached_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void StreamingRecognitionResult::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:google.cloud.speech.v1beta1.StreamingRecognitionResult)
  GOOGLE_DCHECK_NE(&from, this);
  const StreamingRecognitionResult* source =
      ::google::protobuf::internal::DynamicCastToGenerated<const StreamingRecognitionResult>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:google.cloud.speech.v1beta1.StreamingRecognitionResult)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:google.cloud.speech.v1beta1.StreamingRecognitionResult)
    MergeFrom(*source);
  }
}

void StreamingRecognitionResult::MergeFrom(const StreamingRecognitionResult& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:google.cloud.speech.v1beta1.StreamingRecognitionResult)
  GOOGLE_DCHECK_NE(&from, this);
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  alternatives_.MergeFrom(from.alternatives_);
  if (from.is_final() != 0) {
    set_is_final(from.is_final());
  }
  if (from.stability() != 0) {
    set_stability(from.stability());
  }
}

void StreamingRecognitionResult::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:google.cloud.speech.v1beta1.StreamingRecognitionResult)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void StreamingRecognitionResult::CopyFrom(const StreamingRecognitionResult& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:google.cloud.speech.v1beta1.StreamingRecognitionResult)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool StreamingRecognitionResult::IsInitialized() const {
  return true;
}

void StreamingRecognitionResult::Swap(StreamingRecognitionResult* other) {
  if (other == this) return;
  InternalSwap(other);
}
void StreamingRecognitionResult::InternalSwap(StreamingRecognitionResult* other) {
  alternatives_.UnsafeArenaSwap(&other->alternatives_);
  std::swap(is_final_, other->is_final_);
  std::swap(stability_, other->stability_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata StreamingRecognitionResult::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  return file_level_metadata[11];
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// StreamingRecognitionResult

// repeated .google.cloud.speech.v1beta1.SpeechRecognitionAlternative alternatives = 1;
int StreamingRecognitionResult::alternatives_size() const {
  return alternatives_.size();
}
void StreamingRecognitionResult::clear_alternatives() {
  alternatives_.Clear();
}
const ::google::cloud::speech::v1beta1::SpeechRecognitionAlternative& StreamingRecognitionResult::alternatives(int index) const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.StreamingRecognitionResult.alternatives)
  return alternatives_.Get(index);
}
::google::cloud::speech::v1beta1::SpeechRecognitionAlternative* StreamingRecognitionResult::mutable_alternatives(int index) {
  // @@protoc_insertion_point(field_mutable:google.cloud.speech.v1beta1.StreamingRecognitionResult.alternatives)
  return alternatives_.Mutable(index);
}
::google::cloud::speech::v1beta1::SpeechRecognitionAlternative* StreamingRecognitionResult::add_alternatives() {
  // @@protoc_insertion_point(field_add:google.cloud.speech.v1beta1.StreamingRecognitionResult.alternatives)
  return alternatives_.Add();
}
::google::protobuf::RepeatedPtrField< ::google::cloud::speech::v1beta1::SpeechRecognitionAlternative >*
StreamingRecognitionResult::mutable_alternatives() {
  // @@protoc_insertion_point(field_mutable_list:google.cloud.speech.v1beta1.StreamingRecognitionResult.alternatives)
  return &alternatives_;
}
const ::google::protobuf::RepeatedPtrField< ::google::cloud::speech::v1beta1::SpeechRecognitionAlternative >&
StreamingRecognitionResult::alternatives() const {
  // @@protoc_insertion_point(field_list:google.cloud.speech.v1beta1.StreamingRecognitionResult.alternatives)
  return alternatives_;
}

// bool is_final = 2;
void StreamingRecognitionResult::clear_is_final() {
  is_final_ = false;
}
bool StreamingRecognitionResult::is_final() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.StreamingRecognitionResult.is_final)
  return is_final_;
}
void StreamingRecognitionResult::set_is_final(bool value) {
  
  is_final_ = value;
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.StreamingRecognitionResult.is_final)
}

// float stability = 3;
void StreamingRecognitionResult::clear_stability() {
  stability_ = 0;
}
float StreamingRecognitionResult::stability() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.StreamingRecognitionResult.stability)
  return stability_;
}
void StreamingRecognitionResult::set_stability(float value) {
  
  stability_ = value;
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.StreamingRecognitionResult.stability)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int SpeechRecognitionResult::kAlternativesFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

SpeechRecognitionResult::SpeechRecognitionResult()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  if (GOOGLE_PREDICT_TRUE(this != internal_default_instance())) {
    protobuf_InitDefaults_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto();
  }
  SharedCtor();
  // @@protoc_insertion_point(constructor:google.cloud.speech.v1beta1.SpeechRecognitionResult)
}
SpeechRecognitionResult::SpeechRecognitionResult(const SpeechRecognitionResult& from)
  : ::google::protobuf::Message(),
      _internal_metadata_(NULL),
      alternatives_(from.alternatives_),
      _cached_size_(0) {
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  // @@protoc_insertion_point(copy_constructor:google.cloud.speech.v1beta1.SpeechRecognitionResult)
}

void SpeechRecognitionResult::SharedCtor() {
  _cached_size_ = 0;
}

SpeechRecognitionResult::~SpeechRecognitionResult() {
  // @@protoc_insertion_point(destructor:google.cloud.speech.v1beta1.SpeechRecognitionResult)
  SharedDtor();
}

void SpeechRecognitionResult::SharedDtor() {
}

void SpeechRecognitionResult::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* SpeechRecognitionResult::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return file_level_metadata[12].descriptor;
}

const SpeechRecognitionResult& SpeechRecognitionResult::default_instance() {
  protobuf_InitDefaults_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto();
  return *internal_default_instance();
}

SpeechRecognitionResult* SpeechRecognitionResult::New(::google::protobuf::Arena* arena) const {
  SpeechRecognitionResult* n = new SpeechRecognitionResult;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void SpeechRecognitionResult::Clear() {
// @@protoc_insertion_point(message_clear_start:google.cloud.speech.v1beta1.SpeechRecognitionResult)
  alternatives_.Clear();
}

bool SpeechRecognitionResult::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:google.cloud.speech.v1beta1.SpeechRecognitionResult)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoffNoLastTag(127u);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // repeated .google.cloud.speech.v1beta1.SpeechRecognitionAlternative alternatives = 1;
      case 1: {
        if (tag == 10u) {
          DO_(input->IncrementRecursionDepth());
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtualNoRecursionDepth(
                input, add_alternatives()));
        } else {
          goto handle_unusual;
        }
        input->UnsafeDecrementRecursionDepth();
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:google.cloud.speech.v1beta1.SpeechRecognitionResult)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:google.cloud.speech.v1beta1.SpeechRecognitionResult)
  return false;
#undef DO_
}

void SpeechRecognitionResult::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:google.cloud.speech.v1beta1.SpeechRecognitionResult)
  // repeated .google.cloud.speech.v1beta1.SpeechRecognitionAlternative alternatives = 1;
  for (unsigned int i = 0, n = this->alternatives_size(); i < n; i++) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, this->alternatives(i), output);
  }

  // @@protoc_insertion_point(serialize_end:google.cloud.speech.v1beta1.SpeechRecognitionResult)
}

::google::protobuf::uint8* SpeechRecognitionResult::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  (void)deterministic; // Unused
  // @@protoc_insertion_point(serialize_to_array_start:google.cloud.speech.v1beta1.SpeechRecognitionResult)
  // repeated .google.cloud.speech.v1beta1.SpeechRecognitionAlternative alternatives = 1;
  for (unsigned int i = 0, n = this->alternatives_size(); i < n; i++) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        1, this->alternatives(i), false, target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:google.cloud.speech.v1beta1.SpeechRecognitionResult)
  return target;
}

size_t SpeechRecognitionResult::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:google.cloud.speech.v1beta1.SpeechRecognitionResult)
  size_t total_size = 0;

  // repeated .google.cloud.speech.v1beta1.SpeechRecognitionAlternative alternatives = 1;
  {
    unsigned int count = this->alternatives_size();
    total_size += 1UL * count;
    for (unsigned int i = 0; i < count; i++) {
      total_size +=
        ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
          this->alternatives(i));
    }
  }

  int cached_size = ::google::protobuf::internal::ToCachedSize(total_size);
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = cached_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void SpeechRecognitionResult::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:google.cloud.speech.v1beta1.SpeechRecognitionResult)
  GOOGLE_DCHECK_NE(&from, this);
  const SpeechRecognitionResult* source =
      ::google::protobuf::internal::DynamicCastToGenerated<const SpeechRecognitionResult>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:google.cloud.speech.v1beta1.SpeechRecognitionResult)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:google.cloud.speech.v1beta1.SpeechRecognitionResult)
    MergeFrom(*source);
  }
}

void SpeechRecognitionResult::MergeFrom(const SpeechRecognitionResult& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:google.cloud.speech.v1beta1.SpeechRecognitionResult)
  GOOGLE_DCHECK_NE(&from, this);
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  alternatives_.MergeFrom(from.alternatives_);
}

void SpeechRecognitionResult::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:google.cloud.speech.v1beta1.SpeechRecognitionResult)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void SpeechRecognitionResult::CopyFrom(const SpeechRecognitionResult& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:google.cloud.speech.v1beta1.SpeechRecognitionResult)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool SpeechRecognitionResult::IsInitialized() const {
  return true;
}

void SpeechRecognitionResult::Swap(SpeechRecognitionResult* other) {
  if (other == this) return;
  InternalSwap(other);
}
void SpeechRecognitionResult::InternalSwap(SpeechRecognitionResult* other) {
  alternatives_.UnsafeArenaSwap(&other->alternatives_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata SpeechRecognitionResult::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  return file_level_metadata[12];
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// SpeechRecognitionResult

// repeated .google.cloud.speech.v1beta1.SpeechRecognitionAlternative alternatives = 1;
int SpeechRecognitionResult::alternatives_size() const {
  return alternatives_.size();
}
void SpeechRecognitionResult::clear_alternatives() {
  alternatives_.Clear();
}
const ::google::cloud::speech::v1beta1::SpeechRecognitionAlternative& SpeechRecognitionResult::alternatives(int index) const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.SpeechRecognitionResult.alternatives)
  return alternatives_.Get(index);
}
::google::cloud::speech::v1beta1::SpeechRecognitionAlternative* SpeechRecognitionResult::mutable_alternatives(int index) {
  // @@protoc_insertion_point(field_mutable:google.cloud.speech.v1beta1.SpeechRecognitionResult.alternatives)
  return alternatives_.Mutable(index);
}
::google::cloud::speech::v1beta1::SpeechRecognitionAlternative* SpeechRecognitionResult::add_alternatives() {
  // @@protoc_insertion_point(field_add:google.cloud.speech.v1beta1.SpeechRecognitionResult.alternatives)
  return alternatives_.Add();
}
::google::protobuf::RepeatedPtrField< ::google::cloud::speech::v1beta1::SpeechRecognitionAlternative >*
SpeechRecognitionResult::mutable_alternatives() {
  // @@protoc_insertion_point(field_mutable_list:google.cloud.speech.v1beta1.SpeechRecognitionResult.alternatives)
  return &alternatives_;
}
const ::google::protobuf::RepeatedPtrField< ::google::cloud::speech::v1beta1::SpeechRecognitionAlternative >&
SpeechRecognitionResult::alternatives() const {
  // @@protoc_insertion_point(field_list:google.cloud.speech.v1beta1.SpeechRecognitionResult.alternatives)
  return alternatives_;
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int SpeechRecognitionAlternative::kTranscriptFieldNumber;
const int SpeechRecognitionAlternative::kConfidenceFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

SpeechRecognitionAlternative::SpeechRecognitionAlternative()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  if (GOOGLE_PREDICT_TRUE(this != internal_default_instance())) {
    protobuf_InitDefaults_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto();
  }
  SharedCtor();
  // @@protoc_insertion_point(constructor:google.cloud.speech.v1beta1.SpeechRecognitionAlternative)
}
SpeechRecognitionAlternative::SpeechRecognitionAlternative(const SpeechRecognitionAlternative& from)
  : ::google::protobuf::Message(),
      _internal_metadata_(NULL),
      _cached_size_(0) {
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  transcript_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  if (from.transcript().size() > 0) {
    transcript_.AssignWithDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), from.transcript_);
  }
  confidence_ = from.confidence_;
  // @@protoc_insertion_point(copy_constructor:google.cloud.speech.v1beta1.SpeechRecognitionAlternative)
}

void SpeechRecognitionAlternative::SharedCtor() {
  transcript_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  confidence_ = 0;
  _cached_size_ = 0;
}

SpeechRecognitionAlternative::~SpeechRecognitionAlternative() {
  // @@protoc_insertion_point(destructor:google.cloud.speech.v1beta1.SpeechRecognitionAlternative)
  SharedDtor();
}

void SpeechRecognitionAlternative::SharedDtor() {
  transcript_.DestroyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}

void SpeechRecognitionAlternative::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* SpeechRecognitionAlternative::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return file_level_metadata[13].descriptor;
}

const SpeechRecognitionAlternative& SpeechRecognitionAlternative::default_instance() {
  protobuf_InitDefaults_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto();
  return *internal_default_instance();
}

SpeechRecognitionAlternative* SpeechRecognitionAlternative::New(::google::protobuf::Arena* arena) const {
  SpeechRecognitionAlternative* n = new SpeechRecognitionAlternative;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void SpeechRecognitionAlternative::Clear() {
// @@protoc_insertion_point(message_clear_start:google.cloud.speech.v1beta1.SpeechRecognitionAlternative)
  transcript_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  confidence_ = 0;
}

bool SpeechRecognitionAlternative::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:google.cloud.speech.v1beta1.SpeechRecognitionAlternative)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoffNoLastTag(127u);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // string transcript = 1;
      case 1: {
        if (tag == 10u) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadString(
                input, this->mutable_transcript()));
          DO_(::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
            this->transcript().data(), this->transcript().length(),
            ::google::protobuf::internal::WireFormatLite::PARSE,
            "google.cloud.speech.v1beta1.SpeechRecognitionAlternative.transcript"));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // float confidence = 2;
      case 2: {
        if (tag == 21u) {

          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   float, ::google::protobuf::internal::WireFormatLite::TYPE_FLOAT>(
                 input, &confidence_)));
        } else {
          goto handle_unusual;
        }
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:google.cloud.speech.v1beta1.SpeechRecognitionAlternative)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:google.cloud.speech.v1beta1.SpeechRecognitionAlternative)
  return false;
#undef DO_
}

void SpeechRecognitionAlternative::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:google.cloud.speech.v1beta1.SpeechRecognitionAlternative)
  // string transcript = 1;
  if (this->transcript().size() > 0) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->transcript().data(), this->transcript().length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "google.cloud.speech.v1beta1.SpeechRecognitionAlternative.transcript");
    ::google::protobuf::internal::WireFormatLite::WriteStringMaybeAliased(
      1, this->transcript(), output);
  }

  // float confidence = 2;
  if (this->confidence() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteFloat(2, this->confidence(), output);
  }

  // @@protoc_insertion_point(serialize_end:google.cloud.speech.v1beta1.SpeechRecognitionAlternative)
}

::google::protobuf::uint8* SpeechRecognitionAlternative::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  (void)deterministic; // Unused
  // @@protoc_insertion_point(serialize_to_array_start:google.cloud.speech.v1beta1.SpeechRecognitionAlternative)
  // string transcript = 1;
  if (this->transcript().size() > 0) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->transcript().data(), this->transcript().length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "google.cloud.speech.v1beta1.SpeechRecognitionAlternative.transcript");
    target =
      ::google::protobuf::internal::WireFormatLite::WriteStringToArray(
        1, this->transcript(), target);
  }

  // float confidence = 2;
  if (this->confidence() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteFloatToArray(2, this->confidence(), target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:google.cloud.speech.v1beta1.SpeechRecognitionAlternative)
  return target;
}

size_t SpeechRecognitionAlternative::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:google.cloud.speech.v1beta1.SpeechRecognitionAlternative)
  size_t total_size = 0;

  // string transcript = 1;
  if (this->transcript().size() > 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::StringSize(
        this->transcript());
  }

  // float confidence = 2;
  if (this->confidence() != 0) {
    total_size += 1 + 4;
  }

  int cached_size = ::google::protobuf::internal::ToCachedSize(total_size);
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = cached_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void SpeechRecognitionAlternative::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:google.cloud.speech.v1beta1.SpeechRecognitionAlternative)
  GOOGLE_DCHECK_NE(&from, this);
  const SpeechRecognitionAlternative* source =
      ::google::protobuf::internal::DynamicCastToGenerated<const SpeechRecognitionAlternative>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:google.cloud.speech.v1beta1.SpeechRecognitionAlternative)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:google.cloud.speech.v1beta1.SpeechRecognitionAlternative)
    MergeFrom(*source);
  }
}

void SpeechRecognitionAlternative::MergeFrom(const SpeechRecognitionAlternative& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:google.cloud.speech.v1beta1.SpeechRecognitionAlternative)
  GOOGLE_DCHECK_NE(&from, this);
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  if (from.transcript().size() > 0) {

    transcript_.AssignWithDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), from.transcript_);
  }
  if (from.confidence() != 0) {
    set_confidence(from.confidence());
  }
}

void SpeechRecognitionAlternative::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:google.cloud.speech.v1beta1.SpeechRecognitionAlternative)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void SpeechRecognitionAlternative::CopyFrom(const SpeechRecognitionAlternative& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:google.cloud.speech.v1beta1.SpeechRecognitionAlternative)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool SpeechRecognitionAlternative::IsInitialized() const {
  return true;
}

void SpeechRecognitionAlternative::Swap(SpeechRecognitionAlternative* other) {
  if (other == this) return;
  InternalSwap(other);
}
void SpeechRecognitionAlternative::InternalSwap(SpeechRecognitionAlternative* other) {
  transcript_.Swap(&other->transcript_);
  std::swap(confidence_, other->confidence_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata SpeechRecognitionAlternative::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  return file_level_metadata[13];
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// SpeechRecognitionAlternative

// string transcript = 1;
void SpeechRecognitionAlternative::clear_transcript() {
  transcript_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
const ::std::string& SpeechRecognitionAlternative::transcript() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.SpeechRecognitionAlternative.transcript)
  return transcript_.GetNoArena();
}
void SpeechRecognitionAlternative::set_transcript(const ::std::string& value) {
  
  transcript_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.SpeechRecognitionAlternative.transcript)
}
void SpeechRecognitionAlternative::set_transcript(const char* value) {
  
  transcript_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:google.cloud.speech.v1beta1.SpeechRecognitionAlternative.transcript)
}
void SpeechRecognitionAlternative::set_transcript(const char* value, size_t size) {
  
  transcript_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:google.cloud.speech.v1beta1.SpeechRecognitionAlternative.transcript)
}
::std::string* SpeechRecognitionAlternative::mutable_transcript() {
  
  // @@protoc_insertion_point(field_mutable:google.cloud.speech.v1beta1.SpeechRecognitionAlternative.transcript)
  return transcript_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
::std::string* SpeechRecognitionAlternative::release_transcript() {
  // @@protoc_insertion_point(field_release:google.cloud.speech.v1beta1.SpeechRecognitionAlternative.transcript)
  
  return transcript_.ReleaseNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
void SpeechRecognitionAlternative::set_allocated_transcript(::std::string* transcript) {
  if (transcript != NULL) {
    
  } else {
    
  }
  transcript_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), transcript);
  // @@protoc_insertion_point(field_set_allocated:google.cloud.speech.v1beta1.SpeechRecognitionAlternative.transcript)
}

// float confidence = 2;
void SpeechRecognitionAlternative::clear_confidence() {
  confidence_ = 0;
}
float SpeechRecognitionAlternative::confidence() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.SpeechRecognitionAlternative.confidence)
  return confidence_;
}
void SpeechRecognitionAlternative::set_confidence(float value) {
  
  confidence_ = value;
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.SpeechRecognitionAlternative.confidence)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// @@protoc_insertion_point(namespace_scope)

}  // namespace v1beta1
}  // namespace speech
}  // namespace cloud
}  // namespace google

// @@protoc_insertion_point(global_scope)
