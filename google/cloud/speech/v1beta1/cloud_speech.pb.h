// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: google/cloud/speech/v1beta1/cloud_speech.proto

#ifndef PROTOBUF_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto__INCLUDED
#define PROTOBUF_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto__INCLUDED

#include <string>

#include <google/protobuf/stubs/common.h>

#if GOOGLE_PROTOBUF_VERSION < 3001000
#error This file was generated by a newer version of protoc which is
#error incompatible with your Protocol Buffer headers.  Please update
#error your headers.
#endif
#if 3001000 < GOOGLE_PROTOBUF_MIN_PROTOC_VERSION
#error This file was generated by an older version of protoc which is
#error incompatible with your Protocol Buffer headers.  Please
#error regenerate this file with a newer version of protoc.
#endif

#include <google/protobuf/arena.h>
#include <google/protobuf/arenastring.h>
#include <google/protobuf/generated_message_util.h>
#include <google/protobuf/metadata.h>
#include <google/protobuf/message.h>
#include <google/protobuf/repeated_field.h>
#include <google/protobuf/extension_set.h>
#include <google/protobuf/generated_enum_reflection.h>
#include <google/protobuf/unknown_field_set.h>
#include "google/api/annotations.pb.h"
#include "google/longrunning/operations.pb.h"
#include <google/protobuf/timestamp.pb.h>
#include "google/rpc/status.pb.h"
// @@protoc_insertion_point(includes)

namespace google {
namespace cloud {
namespace speech {
namespace v1beta1 {

// Internal implementation detail -- do not call these.
void protobuf_AddDesc_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto();
void protobuf_InitDefaults_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto();
void protobuf_AssignDesc_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto();
void protobuf_ShutdownFile_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto();

class AsyncRecognizeMetadata;
class AsyncRecognizeRequest;
class AsyncRecognizeResponse;
class RecognitionAudio;
class RecognitionConfig;
class SpeechContext;
class SpeechRecognitionAlternative;
class SpeechRecognitionResult;
class StreamingRecognitionConfig;
class StreamingRecognitionResult;
class StreamingRecognizeRequest;
class StreamingRecognizeResponse;
class SyncRecognizeRequest;
class SyncRecognizeResponse;

enum RecognitionConfig_AudioEncoding {
  RecognitionConfig_AudioEncoding_ENCODING_UNSPECIFIED = 0,
  RecognitionConfig_AudioEncoding_LINEAR16 = 1,
  RecognitionConfig_AudioEncoding_FLAC = 2,
  RecognitionConfig_AudioEncoding_MULAW = 3,
  RecognitionConfig_AudioEncoding_AMR = 4,
  RecognitionConfig_AudioEncoding_AMR_WB = 5,
  RecognitionConfig_AudioEncoding_RecognitionConfig_AudioEncoding_INT_MIN_SENTINEL_DO_NOT_USE_ = ::google::protobuf::kint32min,
  RecognitionConfig_AudioEncoding_RecognitionConfig_AudioEncoding_INT_MAX_SENTINEL_DO_NOT_USE_ = ::google::protobuf::kint32max
};
bool RecognitionConfig_AudioEncoding_IsValid(int value);
const RecognitionConfig_AudioEncoding RecognitionConfig_AudioEncoding_AudioEncoding_MIN = RecognitionConfig_AudioEncoding_ENCODING_UNSPECIFIED;
const RecognitionConfig_AudioEncoding RecognitionConfig_AudioEncoding_AudioEncoding_MAX = RecognitionConfig_AudioEncoding_AMR_WB;
const int RecognitionConfig_AudioEncoding_AudioEncoding_ARRAYSIZE = RecognitionConfig_AudioEncoding_AudioEncoding_MAX + 1;

const ::google::protobuf::EnumDescriptor* RecognitionConfig_AudioEncoding_descriptor();
inline const ::std::string& RecognitionConfig_AudioEncoding_Name(RecognitionConfig_AudioEncoding value) {
  return ::google::protobuf::internal::NameOfEnum(
    RecognitionConfig_AudioEncoding_descriptor(), value);
}
inline bool RecognitionConfig_AudioEncoding_Parse(
    const ::std::string& name, RecognitionConfig_AudioEncoding* value) {
  return ::google::protobuf::internal::ParseNamedEnum<RecognitionConfig_AudioEncoding>(
    RecognitionConfig_AudioEncoding_descriptor(), name, value);
}
enum StreamingRecognizeResponse_EndpointerType {
  StreamingRecognizeResponse_EndpointerType_ENDPOINTER_EVENT_UNSPECIFIED = 0,
  StreamingRecognizeResponse_EndpointerType_START_OF_SPEECH = 1,
  StreamingRecognizeResponse_EndpointerType_END_OF_SPEECH = 2,
  StreamingRecognizeResponse_EndpointerType_END_OF_AUDIO = 3,
  StreamingRecognizeResponse_EndpointerType_END_OF_UTTERANCE = 4,
  StreamingRecognizeResponse_EndpointerType_StreamingRecognizeResponse_EndpointerType_INT_MIN_SENTINEL_DO_NOT_USE_ = ::google::protobuf::kint32min,
  StreamingRecognizeResponse_EndpointerType_StreamingRecognizeResponse_EndpointerType_INT_MAX_SENTINEL_DO_NOT_USE_ = ::google::protobuf::kint32max
};
bool StreamingRecognizeResponse_EndpointerType_IsValid(int value);
const StreamingRecognizeResponse_EndpointerType StreamingRecognizeResponse_EndpointerType_EndpointerType_MIN = StreamingRecognizeResponse_EndpointerType_ENDPOINTER_EVENT_UNSPECIFIED;
const StreamingRecognizeResponse_EndpointerType StreamingRecognizeResponse_EndpointerType_EndpointerType_MAX = StreamingRecognizeResponse_EndpointerType_END_OF_UTTERANCE;
const int StreamingRecognizeResponse_EndpointerType_EndpointerType_ARRAYSIZE = StreamingRecognizeResponse_EndpointerType_EndpointerType_MAX + 1;

const ::google::protobuf::EnumDescriptor* StreamingRecognizeResponse_EndpointerType_descriptor();
inline const ::std::string& StreamingRecognizeResponse_EndpointerType_Name(StreamingRecognizeResponse_EndpointerType value) {
  return ::google::protobuf::internal::NameOfEnum(
    StreamingRecognizeResponse_EndpointerType_descriptor(), value);
}
inline bool StreamingRecognizeResponse_EndpointerType_Parse(
    const ::std::string& name, StreamingRecognizeResponse_EndpointerType* value) {
  return ::google::protobuf::internal::ParseNamedEnum<StreamingRecognizeResponse_EndpointerType>(
    StreamingRecognizeResponse_EndpointerType_descriptor(), name, value);
}
// ===================================================================

class SyncRecognizeRequest : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:google.cloud.speech.v1beta1.SyncRecognizeRequest) */ {
 public:
  SyncRecognizeRequest();
  virtual ~SyncRecognizeRequest();

  SyncRecognizeRequest(const SyncRecognizeRequest& from);

  inline SyncRecognizeRequest& operator=(const SyncRecognizeRequest& from) {
    CopyFrom(from);
    return *this;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const SyncRecognizeRequest& default_instance();

  static const SyncRecognizeRequest* internal_default_instance();

  void Swap(SyncRecognizeRequest* other);

  // implements Message ----------------------------------------------

  inline SyncRecognizeRequest* New() const { return New(NULL); }

  SyncRecognizeRequest* New(::google::protobuf::Arena* arena) const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const SyncRecognizeRequest& from);
  void MergeFrom(const SyncRecognizeRequest& from);
  void Clear();
  bool IsInitialized() const;

  size_t ByteSizeLong() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const {
    return InternalSerializeWithCachedSizesToArray(false, output);
  }
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  void InternalSwap(SyncRecognizeRequest* other);
  void UnsafeMergeFrom(const SyncRecognizeRequest& from);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return _internal_metadata_.arena();
  }
  inline void* MaybeArenaPtr() const {
    return _internal_metadata_.raw_arena_ptr();
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional .google.cloud.speech.v1beta1.RecognitionConfig config = 1;
  bool has_config() const;
  void clear_config();
  static const int kConfigFieldNumber = 1;
  const ::google::cloud::speech::v1beta1::RecognitionConfig& config() const;
  ::google::cloud::speech::v1beta1::RecognitionConfig* mutable_config();
  ::google::cloud::speech::v1beta1::RecognitionConfig* release_config();
  void set_allocated_config(::google::cloud::speech::v1beta1::RecognitionConfig* config);

  // optional .google.cloud.speech.v1beta1.RecognitionAudio audio = 2;
  bool has_audio() const;
  void clear_audio();
  static const int kAudioFieldNumber = 2;
  const ::google::cloud::speech::v1beta1::RecognitionAudio& audio() const;
  ::google::cloud::speech::v1beta1::RecognitionAudio* mutable_audio();
  ::google::cloud::speech::v1beta1::RecognitionAudio* release_audio();
  void set_allocated_audio(::google::cloud::speech::v1beta1::RecognitionAudio* audio);

  // @@protoc_insertion_point(class_scope:google.cloud.speech.v1beta1.SyncRecognizeRequest)
 private:

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::cloud::speech::v1beta1::RecognitionConfig* config_;
  ::google::cloud::speech::v1beta1::RecognitionAudio* audio_;
  mutable int _cached_size_;
  friend void  protobuf_InitDefaults_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto_impl();
  friend void  protobuf_AddDesc_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto_impl();
  friend void protobuf_AssignDesc_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto();
  friend void protobuf_ShutdownFile_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto();

  void InitAsDefaultInstance();
};
extern ::google::protobuf::internal::ExplicitlyConstructed<SyncRecognizeRequest> SyncRecognizeRequest_default_instance_;

// -------------------------------------------------------------------

class AsyncRecognizeRequest : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:google.cloud.speech.v1beta1.AsyncRecognizeRequest) */ {
 public:
  AsyncRecognizeRequest();
  virtual ~AsyncRecognizeRequest();

  AsyncRecognizeRequest(const AsyncRecognizeRequest& from);

  inline AsyncRecognizeRequest& operator=(const AsyncRecognizeRequest& from) {
    CopyFrom(from);
    return *this;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const AsyncRecognizeRequest& default_instance();

  static const AsyncRecognizeRequest* internal_default_instance();

  void Swap(AsyncRecognizeRequest* other);

  // implements Message ----------------------------------------------

  inline AsyncRecognizeRequest* New() const { return New(NULL); }

  AsyncRecognizeRequest* New(::google::protobuf::Arena* arena) const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const AsyncRecognizeRequest& from);
  void MergeFrom(const AsyncRecognizeRequest& from);
  void Clear();
  bool IsInitialized() const;

  size_t ByteSizeLong() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const {
    return InternalSerializeWithCachedSizesToArray(false, output);
  }
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  void InternalSwap(AsyncRecognizeRequest* other);
  void UnsafeMergeFrom(const AsyncRecognizeRequest& from);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return _internal_metadata_.arena();
  }
  inline void* MaybeArenaPtr() const {
    return _internal_metadata_.raw_arena_ptr();
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional .google.cloud.speech.v1beta1.RecognitionConfig config = 1;
  bool has_config() const;
  void clear_config();
  static const int kConfigFieldNumber = 1;
  const ::google::cloud::speech::v1beta1::RecognitionConfig& config() const;
  ::google::cloud::speech::v1beta1::RecognitionConfig* mutable_config();
  ::google::cloud::speech::v1beta1::RecognitionConfig* release_config();
  void set_allocated_config(::google::cloud::speech::v1beta1::RecognitionConfig* config);

  // optional .google.cloud.speech.v1beta1.RecognitionAudio audio = 2;
  bool has_audio() const;
  void clear_audio();
  static const int kAudioFieldNumber = 2;
  const ::google::cloud::speech::v1beta1::RecognitionAudio& audio() const;
  ::google::cloud::speech::v1beta1::RecognitionAudio* mutable_audio();
  ::google::cloud::speech::v1beta1::RecognitionAudio* release_audio();
  void set_allocated_audio(::google::cloud::speech::v1beta1::RecognitionAudio* audio);

  // @@protoc_insertion_point(class_scope:google.cloud.speech.v1beta1.AsyncRecognizeRequest)
 private:

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::cloud::speech::v1beta1::RecognitionConfig* config_;
  ::google::cloud::speech::v1beta1::RecognitionAudio* audio_;
  mutable int _cached_size_;
  friend void  protobuf_InitDefaults_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto_impl();
  friend void  protobuf_AddDesc_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto_impl();
  friend void protobuf_AssignDesc_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto();
  friend void protobuf_ShutdownFile_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto();

  void InitAsDefaultInstance();
};
extern ::google::protobuf::internal::ExplicitlyConstructed<AsyncRecognizeRequest> AsyncRecognizeRequest_default_instance_;

// -------------------------------------------------------------------

class StreamingRecognizeRequest : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:google.cloud.speech.v1beta1.StreamingRecognizeRequest) */ {
 public:
  StreamingRecognizeRequest();
  virtual ~StreamingRecognizeRequest();

  StreamingRecognizeRequest(const StreamingRecognizeRequest& from);

  inline StreamingRecognizeRequest& operator=(const StreamingRecognizeRequest& from) {
    CopyFrom(from);
    return *this;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const StreamingRecognizeRequest& default_instance();

  enum StreamingRequestCase {
    kStreamingConfig = 1,
    kAudioContent = 2,
    STREAMING_REQUEST_NOT_SET = 0,
  };

  static const StreamingRecognizeRequest* internal_default_instance();

  void Swap(StreamingRecognizeRequest* other);

  // implements Message ----------------------------------------------

  inline StreamingRecognizeRequest* New() const { return New(NULL); }

  StreamingRecognizeRequest* New(::google::protobuf::Arena* arena) const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const StreamingRecognizeRequest& from);
  void MergeFrom(const StreamingRecognizeRequest& from);
  void Clear();
  bool IsInitialized() const;

  size_t ByteSizeLong() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const {
    return InternalSerializeWithCachedSizesToArray(false, output);
  }
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  void InternalSwap(StreamingRecognizeRequest* other);
  void UnsafeMergeFrom(const StreamingRecognizeRequest& from);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return _internal_metadata_.arena();
  }
  inline void* MaybeArenaPtr() const {
    return _internal_metadata_.raw_arena_ptr();
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional .google.cloud.speech.v1beta1.StreamingRecognitionConfig streaming_config = 1;
  bool has_streaming_config() const;
  void clear_streaming_config();
  static const int kStreamingConfigFieldNumber = 1;
  const ::google::cloud::speech::v1beta1::StreamingRecognitionConfig& streaming_config() const;
  ::google::cloud::speech::v1beta1::StreamingRecognitionConfig* mutable_streaming_config();
  ::google::cloud::speech::v1beta1::StreamingRecognitionConfig* release_streaming_config();
  void set_allocated_streaming_config(::google::cloud::speech::v1beta1::StreamingRecognitionConfig* streaming_config);

  // optional bytes audio_content = 2;
  private:
  bool has_audio_content() const;
  public:
  void clear_audio_content();
  static const int kAudioContentFieldNumber = 2;
  const ::std::string& audio_content() const;
  void set_audio_content(const ::std::string& value);
  void set_audio_content(const char* value);
  void set_audio_content(const void* value, size_t size);
  ::std::string* mutable_audio_content();
  ::std::string* release_audio_content();
  void set_allocated_audio_content(::std::string* audio_content);

  StreamingRequestCase streaming_request_case() const;
  // @@protoc_insertion_point(class_scope:google.cloud.speech.v1beta1.StreamingRecognizeRequest)
 private:
  inline void set_has_streaming_config();
  inline void set_has_audio_content();

  inline bool has_streaming_request() const;
  void clear_streaming_request();
  inline void clear_has_streaming_request();

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  union StreamingRequestUnion {
    StreamingRequestUnion() {}
    ::google::cloud::speech::v1beta1::StreamingRecognitionConfig* streaming_config_;
    ::google::protobuf::internal::ArenaStringPtr audio_content_;
  } streaming_request_;
  mutable int _cached_size_;
  ::google::protobuf::uint32 _oneof_case_[1];

  friend void  protobuf_InitDefaults_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto_impl();
  friend void  protobuf_AddDesc_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto_impl();
  friend void protobuf_AssignDesc_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto();
  friend void protobuf_ShutdownFile_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto();

  void InitAsDefaultInstance();
};
extern ::google::protobuf::internal::ExplicitlyConstructed<StreamingRecognizeRequest> StreamingRecognizeRequest_default_instance_;

// -------------------------------------------------------------------

class StreamingRecognitionConfig : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:google.cloud.speech.v1beta1.StreamingRecognitionConfig) */ {
 public:
  StreamingRecognitionConfig();
  virtual ~StreamingRecognitionConfig();

  StreamingRecognitionConfig(const StreamingRecognitionConfig& from);

  inline StreamingRecognitionConfig& operator=(const StreamingRecognitionConfig& from) {
    CopyFrom(from);
    return *this;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const StreamingRecognitionConfig& default_instance();

  static const StreamingRecognitionConfig* internal_default_instance();

  void Swap(StreamingRecognitionConfig* other);

  // implements Message ----------------------------------------------

  inline StreamingRecognitionConfig* New() const { return New(NULL); }

  StreamingRecognitionConfig* New(::google::protobuf::Arena* arena) const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const StreamingRecognitionConfig& from);
  void MergeFrom(const StreamingRecognitionConfig& from);
  void Clear();
  bool IsInitialized() const;

  size_t ByteSizeLong() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const {
    return InternalSerializeWithCachedSizesToArray(false, output);
  }
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  void InternalSwap(StreamingRecognitionConfig* other);
  void UnsafeMergeFrom(const StreamingRecognitionConfig& from);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return _internal_metadata_.arena();
  }
  inline void* MaybeArenaPtr() const {
    return _internal_metadata_.raw_arena_ptr();
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional .google.cloud.speech.v1beta1.RecognitionConfig config = 1;
  bool has_config() const;
  void clear_config();
  static const int kConfigFieldNumber = 1;
  const ::google::cloud::speech::v1beta1::RecognitionConfig& config() const;
  ::google::cloud::speech::v1beta1::RecognitionConfig* mutable_config();
  ::google::cloud::speech::v1beta1::RecognitionConfig* release_config();
  void set_allocated_config(::google::cloud::speech::v1beta1::RecognitionConfig* config);

  // optional bool single_utterance = 2;
  void clear_single_utterance();
  static const int kSingleUtteranceFieldNumber = 2;
  bool single_utterance() const;
  void set_single_utterance(bool value);

  // optional bool interim_results = 3;
  void clear_interim_results();
  static const int kInterimResultsFieldNumber = 3;
  bool interim_results() const;
  void set_interim_results(bool value);

  // @@protoc_insertion_point(class_scope:google.cloud.speech.v1beta1.StreamingRecognitionConfig)
 private:

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::cloud::speech::v1beta1::RecognitionConfig* config_;
  bool single_utterance_;
  bool interim_results_;
  mutable int _cached_size_;
  friend void  protobuf_InitDefaults_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto_impl();
  friend void  protobuf_AddDesc_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto_impl();
  friend void protobuf_AssignDesc_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto();
  friend void protobuf_ShutdownFile_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto();

  void InitAsDefaultInstance();
};
extern ::google::protobuf::internal::ExplicitlyConstructed<StreamingRecognitionConfig> StreamingRecognitionConfig_default_instance_;

// -------------------------------------------------------------------

class RecognitionConfig : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:google.cloud.speech.v1beta1.RecognitionConfig) */ {
 public:
  RecognitionConfig();
  virtual ~RecognitionConfig();

  RecognitionConfig(const RecognitionConfig& from);

  inline RecognitionConfig& operator=(const RecognitionConfig& from) {
    CopyFrom(from);
    return *this;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const RecognitionConfig& default_instance();

  static const RecognitionConfig* internal_default_instance();

  void Swap(RecognitionConfig* other);

  // implements Message ----------------------------------------------

  inline RecognitionConfig* New() const { return New(NULL); }

  RecognitionConfig* New(::google::protobuf::Arena* arena) const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const RecognitionConfig& from);
  void MergeFrom(const RecognitionConfig& from);
  void Clear();
  bool IsInitialized() const;

  size_t ByteSizeLong() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const {
    return InternalSerializeWithCachedSizesToArray(false, output);
  }
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  void InternalSwap(RecognitionConfig* other);
  void UnsafeMergeFrom(const RecognitionConfig& from);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return _internal_metadata_.arena();
  }
  inline void* MaybeArenaPtr() const {
    return _internal_metadata_.raw_arena_ptr();
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  typedef RecognitionConfig_AudioEncoding AudioEncoding;
  static const AudioEncoding ENCODING_UNSPECIFIED =
    RecognitionConfig_AudioEncoding_ENCODING_UNSPECIFIED;
  static const AudioEncoding LINEAR16 =
    RecognitionConfig_AudioEncoding_LINEAR16;
  static const AudioEncoding FLAC =
    RecognitionConfig_AudioEncoding_FLAC;
  static const AudioEncoding MULAW =
    RecognitionConfig_AudioEncoding_MULAW;
  static const AudioEncoding AMR =
    RecognitionConfig_AudioEncoding_AMR;
  static const AudioEncoding AMR_WB =
    RecognitionConfig_AudioEncoding_AMR_WB;
  static inline bool AudioEncoding_IsValid(int value) {
    return RecognitionConfig_AudioEncoding_IsValid(value);
  }
  static const AudioEncoding AudioEncoding_MIN =
    RecognitionConfig_AudioEncoding_AudioEncoding_MIN;
  static const AudioEncoding AudioEncoding_MAX =
    RecognitionConfig_AudioEncoding_AudioEncoding_MAX;
  static const int AudioEncoding_ARRAYSIZE =
    RecognitionConfig_AudioEncoding_AudioEncoding_ARRAYSIZE;
  static inline const ::google::protobuf::EnumDescriptor*
  AudioEncoding_descriptor() {
    return RecognitionConfig_AudioEncoding_descriptor();
  }
  static inline const ::std::string& AudioEncoding_Name(AudioEncoding value) {
    return RecognitionConfig_AudioEncoding_Name(value);
  }
  static inline bool AudioEncoding_Parse(const ::std::string& name,
      AudioEncoding* value) {
    return RecognitionConfig_AudioEncoding_Parse(name, value);
  }

  // accessors -------------------------------------------------------

  // optional .google.cloud.speech.v1beta1.RecognitionConfig.AudioEncoding encoding = 1;
  void clear_encoding();
  static const int kEncodingFieldNumber = 1;
  ::google::cloud::speech::v1beta1::RecognitionConfig_AudioEncoding encoding() const;
  void set_encoding(::google::cloud::speech::v1beta1::RecognitionConfig_AudioEncoding value);

  // optional int32 sample_rate = 2;
  void clear_sample_rate();
  static const int kSampleRateFieldNumber = 2;
  ::google::protobuf::int32 sample_rate() const;
  void set_sample_rate(::google::protobuf::int32 value);

  // optional string language_code = 3;
  void clear_language_code();
  static const int kLanguageCodeFieldNumber = 3;
  const ::std::string& language_code() const;
  void set_language_code(const ::std::string& value);
  void set_language_code(const char* value);
  void set_language_code(const char* value, size_t size);
  ::std::string* mutable_language_code();
  ::std::string* release_language_code();
  void set_allocated_language_code(::std::string* language_code);

  // optional int32 max_alternatives = 4;
  void clear_max_alternatives();
  static const int kMaxAlternativesFieldNumber = 4;
  ::google::protobuf::int32 max_alternatives() const;
  void set_max_alternatives(::google::protobuf::int32 value);

  // optional bool profanity_filter = 5;
  void clear_profanity_filter();
  static const int kProfanityFilterFieldNumber = 5;
  bool profanity_filter() const;
  void set_profanity_filter(bool value);

  // optional .google.cloud.speech.v1beta1.SpeechContext speech_context = 6;
  bool has_speech_context() const;
  void clear_speech_context();
  static const int kSpeechContextFieldNumber = 6;
  const ::google::cloud::speech::v1beta1::SpeechContext& speech_context() const;
  ::google::cloud::speech::v1beta1::SpeechContext* mutable_speech_context();
  ::google::cloud::speech::v1beta1::SpeechContext* release_speech_context();
  void set_allocated_speech_context(::google::cloud::speech::v1beta1::SpeechContext* speech_context);

  // @@protoc_insertion_point(class_scope:google.cloud.speech.v1beta1.RecognitionConfig)
 private:

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::ArenaStringPtr language_code_;
  ::google::cloud::speech::v1beta1::SpeechContext* speech_context_;
  int encoding_;
  ::google::protobuf::int32 sample_rate_;
  ::google::protobuf::int32 max_alternatives_;
  bool profanity_filter_;
  mutable int _cached_size_;
  friend void  protobuf_InitDefaults_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto_impl();
  friend void  protobuf_AddDesc_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto_impl();
  friend void protobuf_AssignDesc_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto();
  friend void protobuf_ShutdownFile_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto();

  void InitAsDefaultInstance();
};
extern ::google::protobuf::internal::ExplicitlyConstructed<RecognitionConfig> RecognitionConfig_default_instance_;

// -------------------------------------------------------------------

class SpeechContext : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:google.cloud.speech.v1beta1.SpeechContext) */ {
 public:
  SpeechContext();
  virtual ~SpeechContext();

  SpeechContext(const SpeechContext& from);

  inline SpeechContext& operator=(const SpeechContext& from) {
    CopyFrom(from);
    return *this;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const SpeechContext& default_instance();

  static const SpeechContext* internal_default_instance();

  void Swap(SpeechContext* other);

  // implements Message ----------------------------------------------

  inline SpeechContext* New() const { return New(NULL); }

  SpeechContext* New(::google::protobuf::Arena* arena) const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const SpeechContext& from);
  void MergeFrom(const SpeechContext& from);
  void Clear();
  bool IsInitialized() const;

  size_t ByteSizeLong() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const {
    return InternalSerializeWithCachedSizesToArray(false, output);
  }
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  void InternalSwap(SpeechContext* other);
  void UnsafeMergeFrom(const SpeechContext& from);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return _internal_metadata_.arena();
  }
  inline void* MaybeArenaPtr() const {
    return _internal_metadata_.raw_arena_ptr();
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // repeated string phrases = 1;
  int phrases_size() const;
  void clear_phrases();
  static const int kPhrasesFieldNumber = 1;
  const ::std::string& phrases(int index) const;
  ::std::string* mutable_phrases(int index);
  void set_phrases(int index, const ::std::string& value);
  void set_phrases(int index, const char* value);
  void set_phrases(int index, const char* value, size_t size);
  ::std::string* add_phrases();
  void add_phrases(const ::std::string& value);
  void add_phrases(const char* value);
  void add_phrases(const char* value, size_t size);
  const ::google::protobuf::RepeatedPtrField< ::std::string>& phrases() const;
  ::google::protobuf::RepeatedPtrField< ::std::string>* mutable_phrases();

  // @@protoc_insertion_point(class_scope:google.cloud.speech.v1beta1.SpeechContext)
 private:

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::RepeatedPtrField< ::std::string> phrases_;
  mutable int _cached_size_;
  friend void  protobuf_InitDefaults_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto_impl();
  friend void  protobuf_AddDesc_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto_impl();
  friend void protobuf_AssignDesc_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto();
  friend void protobuf_ShutdownFile_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto();

  void InitAsDefaultInstance();
};
extern ::google::protobuf::internal::ExplicitlyConstructed<SpeechContext> SpeechContext_default_instance_;

// -------------------------------------------------------------------

class RecognitionAudio : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:google.cloud.speech.v1beta1.RecognitionAudio) */ {
 public:
  RecognitionAudio();
  virtual ~RecognitionAudio();

  RecognitionAudio(const RecognitionAudio& from);

  inline RecognitionAudio& operator=(const RecognitionAudio& from) {
    CopyFrom(from);
    return *this;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const RecognitionAudio& default_instance();

  enum AudioSourceCase {
    kContent = 1,
    kUri = 2,
    AUDIO_SOURCE_NOT_SET = 0,
  };

  static const RecognitionAudio* internal_default_instance();

  void Swap(RecognitionAudio* other);

  // implements Message ----------------------------------------------

  inline RecognitionAudio* New() const { return New(NULL); }

  RecognitionAudio* New(::google::protobuf::Arena* arena) const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const RecognitionAudio& from);
  void MergeFrom(const RecognitionAudio& from);
  void Clear();
  bool IsInitialized() const;

  size_t ByteSizeLong() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const {
    return InternalSerializeWithCachedSizesToArray(false, output);
  }
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  void InternalSwap(RecognitionAudio* other);
  void UnsafeMergeFrom(const RecognitionAudio& from);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return _internal_metadata_.arena();
  }
  inline void* MaybeArenaPtr() const {
    return _internal_metadata_.raw_arena_ptr();
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional bytes content = 1;
  private:
  bool has_content() const;
  public:
  void clear_content();
  static const int kContentFieldNumber = 1;
  const ::std::string& content() const;
  void set_content(const ::std::string& value);
  void set_content(const char* value);
  void set_content(const void* value, size_t size);
  ::std::string* mutable_content();
  ::std::string* release_content();
  void set_allocated_content(::std::string* content);

  // optional string uri = 2;
  private:
  bool has_uri() const;
  public:
  void clear_uri();
  static const int kUriFieldNumber = 2;
  const ::std::string& uri() const;
  void set_uri(const ::std::string& value);
  void set_uri(const char* value);
  void set_uri(const char* value, size_t size);
  ::std::string* mutable_uri();
  ::std::string* release_uri();
  void set_allocated_uri(::std::string* uri);

  AudioSourceCase audio_source_case() const;
  // @@protoc_insertion_point(class_scope:google.cloud.speech.v1beta1.RecognitionAudio)
 private:
  inline void set_has_content();
  inline void set_has_uri();

  inline bool has_audio_source() const;
  void clear_audio_source();
  inline void clear_has_audio_source();

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  union AudioSourceUnion {
    AudioSourceUnion() {}
    ::google::protobuf::internal::ArenaStringPtr content_;
    ::google::protobuf::internal::ArenaStringPtr uri_;
  } audio_source_;
  mutable int _cached_size_;
  ::google::protobuf::uint32 _oneof_case_[1];

  friend void  protobuf_InitDefaults_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto_impl();
  friend void  protobuf_AddDesc_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto_impl();
  friend void protobuf_AssignDesc_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto();
  friend void protobuf_ShutdownFile_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto();

  void InitAsDefaultInstance();
};
extern ::google::protobuf::internal::ExplicitlyConstructed<RecognitionAudio> RecognitionAudio_default_instance_;

// -------------------------------------------------------------------

class SyncRecognizeResponse : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:google.cloud.speech.v1beta1.SyncRecognizeResponse) */ {
 public:
  SyncRecognizeResponse();
  virtual ~SyncRecognizeResponse();

  SyncRecognizeResponse(const SyncRecognizeResponse& from);

  inline SyncRecognizeResponse& operator=(const SyncRecognizeResponse& from) {
    CopyFrom(from);
    return *this;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const SyncRecognizeResponse& default_instance();

  static const SyncRecognizeResponse* internal_default_instance();

  void Swap(SyncRecognizeResponse* other);

  // implements Message ----------------------------------------------

  inline SyncRecognizeResponse* New() const { return New(NULL); }

  SyncRecognizeResponse* New(::google::protobuf::Arena* arena) const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const SyncRecognizeResponse& from);
  void MergeFrom(const SyncRecognizeResponse& from);
  void Clear();
  bool IsInitialized() const;

  size_t ByteSizeLong() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const {
    return InternalSerializeWithCachedSizesToArray(false, output);
  }
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  void InternalSwap(SyncRecognizeResponse* other);
  void UnsafeMergeFrom(const SyncRecognizeResponse& from);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return _internal_metadata_.arena();
  }
  inline void* MaybeArenaPtr() const {
    return _internal_metadata_.raw_arena_ptr();
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // repeated .google.cloud.speech.v1beta1.SpeechRecognitionResult results = 2;
  int results_size() const;
  void clear_results();
  static const int kResultsFieldNumber = 2;
  const ::google::cloud::speech::v1beta1::SpeechRecognitionResult& results(int index) const;
  ::google::cloud::speech::v1beta1::SpeechRecognitionResult* mutable_results(int index);
  ::google::cloud::speech::v1beta1::SpeechRecognitionResult* add_results();
  ::google::protobuf::RepeatedPtrField< ::google::cloud::speech::v1beta1::SpeechRecognitionResult >*
      mutable_results();
  const ::google::protobuf::RepeatedPtrField< ::google::cloud::speech::v1beta1::SpeechRecognitionResult >&
      results() const;

  // @@protoc_insertion_point(class_scope:google.cloud.speech.v1beta1.SyncRecognizeResponse)
 private:

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::RepeatedPtrField< ::google::cloud::speech::v1beta1::SpeechRecognitionResult > results_;
  mutable int _cached_size_;
  friend void  protobuf_InitDefaults_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto_impl();
  friend void  protobuf_AddDesc_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto_impl();
  friend void protobuf_AssignDesc_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto();
  friend void protobuf_ShutdownFile_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto();

  void InitAsDefaultInstance();
};
extern ::google::protobuf::internal::ExplicitlyConstructed<SyncRecognizeResponse> SyncRecognizeResponse_default_instance_;

// -------------------------------------------------------------------

class AsyncRecognizeResponse : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:google.cloud.speech.v1beta1.AsyncRecognizeResponse) */ {
 public:
  AsyncRecognizeResponse();
  virtual ~AsyncRecognizeResponse();

  AsyncRecognizeResponse(const AsyncRecognizeResponse& from);

  inline AsyncRecognizeResponse& operator=(const AsyncRecognizeResponse& from) {
    CopyFrom(from);
    return *this;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const AsyncRecognizeResponse& default_instance();

  static const AsyncRecognizeResponse* internal_default_instance();

  void Swap(AsyncRecognizeResponse* other);

  // implements Message ----------------------------------------------

  inline AsyncRecognizeResponse* New() const { return New(NULL); }

  AsyncRecognizeResponse* New(::google::protobuf::Arena* arena) const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const AsyncRecognizeResponse& from);
  void MergeFrom(const AsyncRecognizeResponse& from);
  void Clear();
  bool IsInitialized() const;

  size_t ByteSizeLong() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const {
    return InternalSerializeWithCachedSizesToArray(false, output);
  }
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  void InternalSwap(AsyncRecognizeResponse* other);
  void UnsafeMergeFrom(const AsyncRecognizeResponse& from);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return _internal_metadata_.arena();
  }
  inline void* MaybeArenaPtr() const {
    return _internal_metadata_.raw_arena_ptr();
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // repeated .google.cloud.speech.v1beta1.SpeechRecognitionResult results = 2;
  int results_size() const;
  void clear_results();
  static const int kResultsFieldNumber = 2;
  const ::google::cloud::speech::v1beta1::SpeechRecognitionResult& results(int index) const;
  ::google::cloud::speech::v1beta1::SpeechRecognitionResult* mutable_results(int index);
  ::google::cloud::speech::v1beta1::SpeechRecognitionResult* add_results();
  ::google::protobuf::RepeatedPtrField< ::google::cloud::speech::v1beta1::SpeechRecognitionResult >*
      mutable_results();
  const ::google::protobuf::RepeatedPtrField< ::google::cloud::speech::v1beta1::SpeechRecognitionResult >&
      results() const;

  // @@protoc_insertion_point(class_scope:google.cloud.speech.v1beta1.AsyncRecognizeResponse)
 private:

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::RepeatedPtrField< ::google::cloud::speech::v1beta1::SpeechRecognitionResult > results_;
  mutable int _cached_size_;
  friend void  protobuf_InitDefaults_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto_impl();
  friend void  protobuf_AddDesc_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto_impl();
  friend void protobuf_AssignDesc_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto();
  friend void protobuf_ShutdownFile_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto();

  void InitAsDefaultInstance();
};
extern ::google::protobuf::internal::ExplicitlyConstructed<AsyncRecognizeResponse> AsyncRecognizeResponse_default_instance_;

// -------------------------------------------------------------------

class AsyncRecognizeMetadata : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:google.cloud.speech.v1beta1.AsyncRecognizeMetadata) */ {
 public:
  AsyncRecognizeMetadata();
  virtual ~AsyncRecognizeMetadata();

  AsyncRecognizeMetadata(const AsyncRecognizeMetadata& from);

  inline AsyncRecognizeMetadata& operator=(const AsyncRecognizeMetadata& from) {
    CopyFrom(from);
    return *this;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const AsyncRecognizeMetadata& default_instance();

  static const AsyncRecognizeMetadata* internal_default_instance();

  void Swap(AsyncRecognizeMetadata* other);

  // implements Message ----------------------------------------------

  inline AsyncRecognizeMetadata* New() const { return New(NULL); }

  AsyncRecognizeMetadata* New(::google::protobuf::Arena* arena) const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const AsyncRecognizeMetadata& from);
  void MergeFrom(const AsyncRecognizeMetadata& from);
  void Clear();
  bool IsInitialized() const;

  size_t ByteSizeLong() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const {
    return InternalSerializeWithCachedSizesToArray(false, output);
  }
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  void InternalSwap(AsyncRecognizeMetadata* other);
  void UnsafeMergeFrom(const AsyncRecognizeMetadata& from);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return _internal_metadata_.arena();
  }
  inline void* MaybeArenaPtr() const {
    return _internal_metadata_.raw_arena_ptr();
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional int32 progress_percent = 1;
  void clear_progress_percent();
  static const int kProgressPercentFieldNumber = 1;
  ::google::protobuf::int32 progress_percent() const;
  void set_progress_percent(::google::protobuf::int32 value);

  // optional .google.protobuf.Timestamp start_time = 2;
  bool has_start_time() const;
  void clear_start_time();
  static const int kStartTimeFieldNumber = 2;
  const ::google::protobuf::Timestamp& start_time() const;
  ::google::protobuf::Timestamp* mutable_start_time();
  ::google::protobuf::Timestamp* release_start_time();
  void set_allocated_start_time(::google::protobuf::Timestamp* start_time);

  // optional .google.protobuf.Timestamp last_update_time = 3;
  bool has_last_update_time() const;
  void clear_last_update_time();
  static const int kLastUpdateTimeFieldNumber = 3;
  const ::google::protobuf::Timestamp& last_update_time() const;
  ::google::protobuf::Timestamp* mutable_last_update_time();
  ::google::protobuf::Timestamp* release_last_update_time();
  void set_allocated_last_update_time(::google::protobuf::Timestamp* last_update_time);

  // @@protoc_insertion_point(class_scope:google.cloud.speech.v1beta1.AsyncRecognizeMetadata)
 private:

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::Timestamp* start_time_;
  ::google::protobuf::Timestamp* last_update_time_;
  ::google::protobuf::int32 progress_percent_;
  mutable int _cached_size_;
  friend void  protobuf_InitDefaults_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto_impl();
  friend void  protobuf_AddDesc_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto_impl();
  friend void protobuf_AssignDesc_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto();
  friend void protobuf_ShutdownFile_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto();

  void InitAsDefaultInstance();
};
extern ::google::protobuf::internal::ExplicitlyConstructed<AsyncRecognizeMetadata> AsyncRecognizeMetadata_default_instance_;

// -------------------------------------------------------------------

class StreamingRecognizeResponse : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:google.cloud.speech.v1beta1.StreamingRecognizeResponse) */ {
 public:
  StreamingRecognizeResponse();
  virtual ~StreamingRecognizeResponse();

  StreamingRecognizeResponse(const StreamingRecognizeResponse& from);

  inline StreamingRecognizeResponse& operator=(const StreamingRecognizeResponse& from) {
    CopyFrom(from);
    return *this;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const StreamingRecognizeResponse& default_instance();

  static const StreamingRecognizeResponse* internal_default_instance();

  void Swap(StreamingRecognizeResponse* other);

  // implements Message ----------------------------------------------

  inline StreamingRecognizeResponse* New() const { return New(NULL); }

  StreamingRecognizeResponse* New(::google::protobuf::Arena* arena) const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const StreamingRecognizeResponse& from);
  void MergeFrom(const StreamingRecognizeResponse& from);
  void Clear();
  bool IsInitialized() const;

  size_t ByteSizeLong() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const {
    return InternalSerializeWithCachedSizesToArray(false, output);
  }
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  void InternalSwap(StreamingRecognizeResponse* other);
  void UnsafeMergeFrom(const StreamingRecognizeResponse& from);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return _internal_metadata_.arena();
  }
  inline void* MaybeArenaPtr() const {
    return _internal_metadata_.raw_arena_ptr();
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  typedef StreamingRecognizeResponse_EndpointerType EndpointerType;
  static const EndpointerType ENDPOINTER_EVENT_UNSPECIFIED =
    StreamingRecognizeResponse_EndpointerType_ENDPOINTER_EVENT_UNSPECIFIED;
  static const EndpointerType START_OF_SPEECH =
    StreamingRecognizeResponse_EndpointerType_START_OF_SPEECH;
  static const EndpointerType END_OF_SPEECH =
    StreamingRecognizeResponse_EndpointerType_END_OF_SPEECH;
  static const EndpointerType END_OF_AUDIO =
    StreamingRecognizeResponse_EndpointerType_END_OF_AUDIO;
  static const EndpointerType END_OF_UTTERANCE =
    StreamingRecognizeResponse_EndpointerType_END_OF_UTTERANCE;
  static inline bool EndpointerType_IsValid(int value) {
    return StreamingRecognizeResponse_EndpointerType_IsValid(value);
  }
  static const EndpointerType EndpointerType_MIN =
    StreamingRecognizeResponse_EndpointerType_EndpointerType_MIN;
  static const EndpointerType EndpointerType_MAX =
    StreamingRecognizeResponse_EndpointerType_EndpointerType_MAX;
  static const int EndpointerType_ARRAYSIZE =
    StreamingRecognizeResponse_EndpointerType_EndpointerType_ARRAYSIZE;
  static inline const ::google::protobuf::EnumDescriptor*
  EndpointerType_descriptor() {
    return StreamingRecognizeResponse_EndpointerType_descriptor();
  }
  static inline const ::std::string& EndpointerType_Name(EndpointerType value) {
    return StreamingRecognizeResponse_EndpointerType_Name(value);
  }
  static inline bool EndpointerType_Parse(const ::std::string& name,
      EndpointerType* value) {
    return StreamingRecognizeResponse_EndpointerType_Parse(name, value);
  }

  // accessors -------------------------------------------------------

  // optional .google.rpc.Status error = 1;
  bool has_error() const;
  void clear_error();
  static const int kErrorFieldNumber = 1;
  const ::google::rpc::Status& error() const;
  ::google::rpc::Status* mutable_error();
  ::google::rpc::Status* release_error();
  void set_allocated_error(::google::rpc::Status* error);

  // repeated .google.cloud.speech.v1beta1.StreamingRecognitionResult results = 2;
  int results_size() const;
  void clear_results();
  static const int kResultsFieldNumber = 2;
  const ::google::cloud::speech::v1beta1::StreamingRecognitionResult& results(int index) const;
  ::google::cloud::speech::v1beta1::StreamingRecognitionResult* mutable_results(int index);
  ::google::cloud::speech::v1beta1::StreamingRecognitionResult* add_results();
  ::google::protobuf::RepeatedPtrField< ::google::cloud::speech::v1beta1::StreamingRecognitionResult >*
      mutable_results();
  const ::google::protobuf::RepeatedPtrField< ::google::cloud::speech::v1beta1::StreamingRecognitionResult >&
      results() const;

  // optional int32 result_index = 3;
  void clear_result_index();
  static const int kResultIndexFieldNumber = 3;
  ::google::protobuf::int32 result_index() const;
  void set_result_index(::google::protobuf::int32 value);

  // optional .google.cloud.speech.v1beta1.StreamingRecognizeResponse.EndpointerType endpointer_type = 4;
  void clear_endpointer_type();
  static const int kEndpointerTypeFieldNumber = 4;
  ::google::cloud::speech::v1beta1::StreamingRecognizeResponse_EndpointerType endpointer_type() const;
  void set_endpointer_type(::google::cloud::speech::v1beta1::StreamingRecognizeResponse_EndpointerType value);

  // @@protoc_insertion_point(class_scope:google.cloud.speech.v1beta1.StreamingRecognizeResponse)
 private:

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::RepeatedPtrField< ::google::cloud::speech::v1beta1::StreamingRecognitionResult > results_;
  ::google::rpc::Status* error_;
  ::google::protobuf::int32 result_index_;
  int endpointer_type_;
  mutable int _cached_size_;
  friend void  protobuf_InitDefaults_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto_impl();
  friend void  protobuf_AddDesc_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto_impl();
  friend void protobuf_AssignDesc_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto();
  friend void protobuf_ShutdownFile_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto();

  void InitAsDefaultInstance();
};
extern ::google::protobuf::internal::ExplicitlyConstructed<StreamingRecognizeResponse> StreamingRecognizeResponse_default_instance_;

// -------------------------------------------------------------------

class StreamingRecognitionResult : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:google.cloud.speech.v1beta1.StreamingRecognitionResult) */ {
 public:
  StreamingRecognitionResult();
  virtual ~StreamingRecognitionResult();

  StreamingRecognitionResult(const StreamingRecognitionResult& from);

  inline StreamingRecognitionResult& operator=(const StreamingRecognitionResult& from) {
    CopyFrom(from);
    return *this;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const StreamingRecognitionResult& default_instance();

  static const StreamingRecognitionResult* internal_default_instance();

  void Swap(StreamingRecognitionResult* other);

  // implements Message ----------------------------------------------

  inline StreamingRecognitionResult* New() const { return New(NULL); }

  StreamingRecognitionResult* New(::google::protobuf::Arena* arena) const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const StreamingRecognitionResult& from);
  void MergeFrom(const StreamingRecognitionResult& from);
  void Clear();
  bool IsInitialized() const;

  size_t ByteSizeLong() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const {
    return InternalSerializeWithCachedSizesToArray(false, output);
  }
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  void InternalSwap(StreamingRecognitionResult* other);
  void UnsafeMergeFrom(const StreamingRecognitionResult& from);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return _internal_metadata_.arena();
  }
  inline void* MaybeArenaPtr() const {
    return _internal_metadata_.raw_arena_ptr();
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // repeated .google.cloud.speech.v1beta1.SpeechRecognitionAlternative alternatives = 1;
  int alternatives_size() const;
  void clear_alternatives();
  static const int kAlternativesFieldNumber = 1;
  const ::google::cloud::speech::v1beta1::SpeechRecognitionAlternative& alternatives(int index) const;
  ::google::cloud::speech::v1beta1::SpeechRecognitionAlternative* mutable_alternatives(int index);
  ::google::cloud::speech::v1beta1::SpeechRecognitionAlternative* add_alternatives();
  ::google::protobuf::RepeatedPtrField< ::google::cloud::speech::v1beta1::SpeechRecognitionAlternative >*
      mutable_alternatives();
  const ::google::protobuf::RepeatedPtrField< ::google::cloud::speech::v1beta1::SpeechRecognitionAlternative >&
      alternatives() const;

  // optional bool is_final = 2;
  void clear_is_final();
  static const int kIsFinalFieldNumber = 2;
  bool is_final() const;
  void set_is_final(bool value);

  // optional float stability = 3;
  void clear_stability();
  static const int kStabilityFieldNumber = 3;
  float stability() const;
  void set_stability(float value);

  // @@protoc_insertion_point(class_scope:google.cloud.speech.v1beta1.StreamingRecognitionResult)
 private:

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::RepeatedPtrField< ::google::cloud::speech::v1beta1::SpeechRecognitionAlternative > alternatives_;
  bool is_final_;
  float stability_;
  mutable int _cached_size_;
  friend void  protobuf_InitDefaults_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto_impl();
  friend void  protobuf_AddDesc_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto_impl();
  friend void protobuf_AssignDesc_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto();
  friend void protobuf_ShutdownFile_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto();

  void InitAsDefaultInstance();
};
extern ::google::protobuf::internal::ExplicitlyConstructed<StreamingRecognitionResult> StreamingRecognitionResult_default_instance_;

// -------------------------------------------------------------------

class SpeechRecognitionResult : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:google.cloud.speech.v1beta1.SpeechRecognitionResult) */ {
 public:
  SpeechRecognitionResult();
  virtual ~SpeechRecognitionResult();

  SpeechRecognitionResult(const SpeechRecognitionResult& from);

  inline SpeechRecognitionResult& operator=(const SpeechRecognitionResult& from) {
    CopyFrom(from);
    return *this;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const SpeechRecognitionResult& default_instance();

  static const SpeechRecognitionResult* internal_default_instance();

  void Swap(SpeechRecognitionResult* other);

  // implements Message ----------------------------------------------

  inline SpeechRecognitionResult* New() const { return New(NULL); }

  SpeechRecognitionResult* New(::google::protobuf::Arena* arena) const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const SpeechRecognitionResult& from);
  void MergeFrom(const SpeechRecognitionResult& from);
  void Clear();
  bool IsInitialized() const;

  size_t ByteSizeLong() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const {
    return InternalSerializeWithCachedSizesToArray(false, output);
  }
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  void InternalSwap(SpeechRecognitionResult* other);
  void UnsafeMergeFrom(const SpeechRecognitionResult& from);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return _internal_metadata_.arena();
  }
  inline void* MaybeArenaPtr() const {
    return _internal_metadata_.raw_arena_ptr();
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // repeated .google.cloud.speech.v1beta1.SpeechRecognitionAlternative alternatives = 1;
  int alternatives_size() const;
  void clear_alternatives();
  static const int kAlternativesFieldNumber = 1;
  const ::google::cloud::speech::v1beta1::SpeechRecognitionAlternative& alternatives(int index) const;
  ::google::cloud::speech::v1beta1::SpeechRecognitionAlternative* mutable_alternatives(int index);
  ::google::cloud::speech::v1beta1::SpeechRecognitionAlternative* add_alternatives();
  ::google::protobuf::RepeatedPtrField< ::google::cloud::speech::v1beta1::SpeechRecognitionAlternative >*
      mutable_alternatives();
  const ::google::protobuf::RepeatedPtrField< ::google::cloud::speech::v1beta1::SpeechRecognitionAlternative >&
      alternatives() const;

  // @@protoc_insertion_point(class_scope:google.cloud.speech.v1beta1.SpeechRecognitionResult)
 private:

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::RepeatedPtrField< ::google::cloud::speech::v1beta1::SpeechRecognitionAlternative > alternatives_;
  mutable int _cached_size_;
  friend void  protobuf_InitDefaults_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto_impl();
  friend void  protobuf_AddDesc_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto_impl();
  friend void protobuf_AssignDesc_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto();
  friend void protobuf_ShutdownFile_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto();

  void InitAsDefaultInstance();
};
extern ::google::protobuf::internal::ExplicitlyConstructed<SpeechRecognitionResult> SpeechRecognitionResult_default_instance_;

// -------------------------------------------------------------------

class SpeechRecognitionAlternative : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:google.cloud.speech.v1beta1.SpeechRecognitionAlternative) */ {
 public:
  SpeechRecognitionAlternative();
  virtual ~SpeechRecognitionAlternative();

  SpeechRecognitionAlternative(const SpeechRecognitionAlternative& from);

  inline SpeechRecognitionAlternative& operator=(const SpeechRecognitionAlternative& from) {
    CopyFrom(from);
    return *this;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const SpeechRecognitionAlternative& default_instance();

  static const SpeechRecognitionAlternative* internal_default_instance();

  void Swap(SpeechRecognitionAlternative* other);

  // implements Message ----------------------------------------------

  inline SpeechRecognitionAlternative* New() const { return New(NULL); }

  SpeechRecognitionAlternative* New(::google::protobuf::Arena* arena) const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const SpeechRecognitionAlternative& from);
  void MergeFrom(const SpeechRecognitionAlternative& from);
  void Clear();
  bool IsInitialized() const;

  size_t ByteSizeLong() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const {
    return InternalSerializeWithCachedSizesToArray(false, output);
  }
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  void InternalSwap(SpeechRecognitionAlternative* other);
  void UnsafeMergeFrom(const SpeechRecognitionAlternative& from);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return _internal_metadata_.arena();
  }
  inline void* MaybeArenaPtr() const {
    return _internal_metadata_.raw_arena_ptr();
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional string transcript = 1;
  void clear_transcript();
  static const int kTranscriptFieldNumber = 1;
  const ::std::string& transcript() const;
  void set_transcript(const ::std::string& value);
  void set_transcript(const char* value);
  void set_transcript(const char* value, size_t size);
  ::std::string* mutable_transcript();
  ::std::string* release_transcript();
  void set_allocated_transcript(::std::string* transcript);

  // optional float confidence = 2;
  void clear_confidence();
  static const int kConfidenceFieldNumber = 2;
  float confidence() const;
  void set_confidence(float value);

  // @@protoc_insertion_point(class_scope:google.cloud.speech.v1beta1.SpeechRecognitionAlternative)
 private:

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::ArenaStringPtr transcript_;
  float confidence_;
  mutable int _cached_size_;
  friend void  protobuf_InitDefaults_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto_impl();
  friend void  protobuf_AddDesc_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto_impl();
  friend void protobuf_AssignDesc_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto();
  friend void protobuf_ShutdownFile_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto();

  void InitAsDefaultInstance();
};
extern ::google::protobuf::internal::ExplicitlyConstructed<SpeechRecognitionAlternative> SpeechRecognitionAlternative_default_instance_;

// ===================================================================


// ===================================================================

#if !PROTOBUF_INLINE_NOT_IN_HEADERS
// SyncRecognizeRequest

// optional .google.cloud.speech.v1beta1.RecognitionConfig config = 1;
inline bool SyncRecognizeRequest::has_config() const {
  return this != internal_default_instance() && config_ != NULL;
}
inline void SyncRecognizeRequest::clear_config() {
  if (GetArenaNoVirtual() == NULL && config_ != NULL) delete config_;
  config_ = NULL;
}
inline const ::google::cloud::speech::v1beta1::RecognitionConfig& SyncRecognizeRequest::config() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.SyncRecognizeRequest.config)
  return config_ != NULL ? *config_
                         : *::google::cloud::speech::v1beta1::RecognitionConfig::internal_default_instance();
}
inline ::google::cloud::speech::v1beta1::RecognitionConfig* SyncRecognizeRequest::mutable_config() {
  
  if (config_ == NULL) {
    config_ = new ::google::cloud::speech::v1beta1::RecognitionConfig;
  }
  // @@protoc_insertion_point(field_mutable:google.cloud.speech.v1beta1.SyncRecognizeRequest.config)
  return config_;
}
inline ::google::cloud::speech::v1beta1::RecognitionConfig* SyncRecognizeRequest::release_config() {
  // @@protoc_insertion_point(field_release:google.cloud.speech.v1beta1.SyncRecognizeRequest.config)
  
  ::google::cloud::speech::v1beta1::RecognitionConfig* temp = config_;
  config_ = NULL;
  return temp;
}
inline void SyncRecognizeRequest::set_allocated_config(::google::cloud::speech::v1beta1::RecognitionConfig* config) {
  delete config_;
  config_ = config;
  if (config) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:google.cloud.speech.v1beta1.SyncRecognizeRequest.config)
}

// optional .google.cloud.speech.v1beta1.RecognitionAudio audio = 2;
inline bool SyncRecognizeRequest::has_audio() const {
  return this != internal_default_instance() && audio_ != NULL;
}
inline void SyncRecognizeRequest::clear_audio() {
  if (GetArenaNoVirtual() == NULL && audio_ != NULL) delete audio_;
  audio_ = NULL;
}
inline const ::google::cloud::speech::v1beta1::RecognitionAudio& SyncRecognizeRequest::audio() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.SyncRecognizeRequest.audio)
  return audio_ != NULL ? *audio_
                         : *::google::cloud::speech::v1beta1::RecognitionAudio::internal_default_instance();
}
inline ::google::cloud::speech::v1beta1::RecognitionAudio* SyncRecognizeRequest::mutable_audio() {
  
  if (audio_ == NULL) {
    audio_ = new ::google::cloud::speech::v1beta1::RecognitionAudio;
  }
  // @@protoc_insertion_point(field_mutable:google.cloud.speech.v1beta1.SyncRecognizeRequest.audio)
  return audio_;
}
inline ::google::cloud::speech::v1beta1::RecognitionAudio* SyncRecognizeRequest::release_audio() {
  // @@protoc_insertion_point(field_release:google.cloud.speech.v1beta1.SyncRecognizeRequest.audio)
  
  ::google::cloud::speech::v1beta1::RecognitionAudio* temp = audio_;
  audio_ = NULL;
  return temp;
}
inline void SyncRecognizeRequest::set_allocated_audio(::google::cloud::speech::v1beta1::RecognitionAudio* audio) {
  delete audio_;
  audio_ = audio;
  if (audio) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:google.cloud.speech.v1beta1.SyncRecognizeRequest.audio)
}

inline const SyncRecognizeRequest* SyncRecognizeRequest::internal_default_instance() {
  return &SyncRecognizeRequest_default_instance_.get();
}
// -------------------------------------------------------------------

// AsyncRecognizeRequest

// optional .google.cloud.speech.v1beta1.RecognitionConfig config = 1;
inline bool AsyncRecognizeRequest::has_config() const {
  return this != internal_default_instance() && config_ != NULL;
}
inline void AsyncRecognizeRequest::clear_config() {
  if (GetArenaNoVirtual() == NULL && config_ != NULL) delete config_;
  config_ = NULL;
}
inline const ::google::cloud::speech::v1beta1::RecognitionConfig& AsyncRecognizeRequest::config() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.AsyncRecognizeRequest.config)
  return config_ != NULL ? *config_
                         : *::google::cloud::speech::v1beta1::RecognitionConfig::internal_default_instance();
}
inline ::google::cloud::speech::v1beta1::RecognitionConfig* AsyncRecognizeRequest::mutable_config() {
  
  if (config_ == NULL) {
    config_ = new ::google::cloud::speech::v1beta1::RecognitionConfig;
  }
  // @@protoc_insertion_point(field_mutable:google.cloud.speech.v1beta1.AsyncRecognizeRequest.config)
  return config_;
}
inline ::google::cloud::speech::v1beta1::RecognitionConfig* AsyncRecognizeRequest::release_config() {
  // @@protoc_insertion_point(field_release:google.cloud.speech.v1beta1.AsyncRecognizeRequest.config)
  
  ::google::cloud::speech::v1beta1::RecognitionConfig* temp = config_;
  config_ = NULL;
  return temp;
}
inline void AsyncRecognizeRequest::set_allocated_config(::google::cloud::speech::v1beta1::RecognitionConfig* config) {
  delete config_;
  config_ = config;
  if (config) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:google.cloud.speech.v1beta1.AsyncRecognizeRequest.config)
}

// optional .google.cloud.speech.v1beta1.RecognitionAudio audio = 2;
inline bool AsyncRecognizeRequest::has_audio() const {
  return this != internal_default_instance() && audio_ != NULL;
}
inline void AsyncRecognizeRequest::clear_audio() {
  if (GetArenaNoVirtual() == NULL && audio_ != NULL) delete audio_;
  audio_ = NULL;
}
inline const ::google::cloud::speech::v1beta1::RecognitionAudio& AsyncRecognizeRequest::audio() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.AsyncRecognizeRequest.audio)
  return audio_ != NULL ? *audio_
                         : *::google::cloud::speech::v1beta1::RecognitionAudio::internal_default_instance();
}
inline ::google::cloud::speech::v1beta1::RecognitionAudio* AsyncRecognizeRequest::mutable_audio() {
  
  if (audio_ == NULL) {
    audio_ = new ::google::cloud::speech::v1beta1::RecognitionAudio;
  }
  // @@protoc_insertion_point(field_mutable:google.cloud.speech.v1beta1.AsyncRecognizeRequest.audio)
  return audio_;
}
inline ::google::cloud::speech::v1beta1::RecognitionAudio* AsyncRecognizeRequest::release_audio() {
  // @@protoc_insertion_point(field_release:google.cloud.speech.v1beta1.AsyncRecognizeRequest.audio)
  
  ::google::cloud::speech::v1beta1::RecognitionAudio* temp = audio_;
  audio_ = NULL;
  return temp;
}
inline void AsyncRecognizeRequest::set_allocated_audio(::google::cloud::speech::v1beta1::RecognitionAudio* audio) {
  delete audio_;
  audio_ = audio;
  if (audio) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:google.cloud.speech.v1beta1.AsyncRecognizeRequest.audio)
}

inline const AsyncRecognizeRequest* AsyncRecognizeRequest::internal_default_instance() {
  return &AsyncRecognizeRequest_default_instance_.get();
}
// -------------------------------------------------------------------

// StreamingRecognizeRequest

// optional .google.cloud.speech.v1beta1.StreamingRecognitionConfig streaming_config = 1;
inline bool StreamingRecognizeRequest::has_streaming_config() const {
  return streaming_request_case() == kStreamingConfig;
}
inline void StreamingRecognizeRequest::set_has_streaming_config() {
  _oneof_case_[0] = kStreamingConfig;
}
inline void StreamingRecognizeRequest::clear_streaming_config() {
  if (has_streaming_config()) {
    delete streaming_request_.streaming_config_;
    clear_has_streaming_request();
  }
}
inline  const ::google::cloud::speech::v1beta1::StreamingRecognitionConfig& StreamingRecognizeRequest::streaming_config() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.StreamingRecognizeRequest.streaming_config)
  return has_streaming_config()
      ? *streaming_request_.streaming_config_
      : ::google::cloud::speech::v1beta1::StreamingRecognitionConfig::default_instance();
}
inline ::google::cloud::speech::v1beta1::StreamingRecognitionConfig* StreamingRecognizeRequest::mutable_streaming_config() {
  if (!has_streaming_config()) {
    clear_streaming_request();
    set_has_streaming_config();
    streaming_request_.streaming_config_ = new ::google::cloud::speech::v1beta1::StreamingRecognitionConfig;
  }
  // @@protoc_insertion_point(field_mutable:google.cloud.speech.v1beta1.StreamingRecognizeRequest.streaming_config)
  return streaming_request_.streaming_config_;
}
inline ::google::cloud::speech::v1beta1::StreamingRecognitionConfig* StreamingRecognizeRequest::release_streaming_config() {
  // @@protoc_insertion_point(field_release:google.cloud.speech.v1beta1.StreamingRecognizeRequest.streaming_config)
  if (has_streaming_config()) {
    clear_has_streaming_request();
    ::google::cloud::speech::v1beta1::StreamingRecognitionConfig* temp = streaming_request_.streaming_config_;
    streaming_request_.streaming_config_ = NULL;
    return temp;
  } else {
    return NULL;
  }
}
inline void StreamingRecognizeRequest::set_allocated_streaming_config(::google::cloud::speech::v1beta1::StreamingRecognitionConfig* streaming_config) {
  clear_streaming_request();
  if (streaming_config) {
    set_has_streaming_config();
    streaming_request_.streaming_config_ = streaming_config;
  }
  // @@protoc_insertion_point(field_set_allocated:google.cloud.speech.v1beta1.StreamingRecognizeRequest.streaming_config)
}

// optional bytes audio_content = 2;
inline bool StreamingRecognizeRequest::has_audio_content() const {
  return streaming_request_case() == kAudioContent;
}
inline void StreamingRecognizeRequest::set_has_audio_content() {
  _oneof_case_[0] = kAudioContent;
}
inline void StreamingRecognizeRequest::clear_audio_content() {
  if (has_audio_content()) {
    streaming_request_.audio_content_.DestroyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
    clear_has_streaming_request();
  }
}
inline const ::std::string& StreamingRecognizeRequest::audio_content() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.StreamingRecognizeRequest.audio_content)
  if (has_audio_content()) {
    return streaming_request_.audio_content_.GetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  }
  return *&::google::protobuf::internal::GetEmptyStringAlreadyInited();
}
inline void StreamingRecognizeRequest::set_audio_content(const ::std::string& value) {
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.StreamingRecognizeRequest.audio_content)
  if (!has_audio_content()) {
    clear_streaming_request();
    set_has_audio_content();
    streaming_request_.audio_content_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  }
  streaming_request_.audio_content_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.StreamingRecognizeRequest.audio_content)
}
inline void StreamingRecognizeRequest::set_audio_content(const char* value) {
  if (!has_audio_content()) {
    clear_streaming_request();
    set_has_audio_content();
    streaming_request_.audio_content_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  }
  streaming_request_.audio_content_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(value));
  // @@protoc_insertion_point(field_set_char:google.cloud.speech.v1beta1.StreamingRecognizeRequest.audio_content)
}
inline void StreamingRecognizeRequest::set_audio_content(const void* value, size_t size) {
  if (!has_audio_content()) {
    clear_streaming_request();
    set_has_audio_content();
    streaming_request_.audio_content_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  }
  streaming_request_.audio_content_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(
      reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:google.cloud.speech.v1beta1.StreamingRecognizeRequest.audio_content)
}
inline ::std::string* StreamingRecognizeRequest::mutable_audio_content() {
  if (!has_audio_content()) {
    clear_streaming_request();
    set_has_audio_content();
    streaming_request_.audio_content_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  }
  // @@protoc_insertion_point(field_mutable:google.cloud.speech.v1beta1.StreamingRecognizeRequest.audio_content)
  return streaming_request_.audio_content_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* StreamingRecognizeRequest::release_audio_content() {
  // @@protoc_insertion_point(field_release:google.cloud.speech.v1beta1.StreamingRecognizeRequest.audio_content)
  if (has_audio_content()) {
    clear_has_streaming_request();
    return streaming_request_.audio_content_.ReleaseNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  } else {
    return NULL;
  }
}
inline void StreamingRecognizeRequest::set_allocated_audio_content(::std::string* audio_content) {
  if (!has_audio_content()) {
    streaming_request_.audio_content_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  }
  clear_streaming_request();
  if (audio_content != NULL) {
    set_has_audio_content();
    streaming_request_.audio_content_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
        audio_content);
  }
  // @@protoc_insertion_point(field_set_allocated:google.cloud.speech.v1beta1.StreamingRecognizeRequest.audio_content)
}

inline bool StreamingRecognizeRequest::has_streaming_request() const {
  return streaming_request_case() != STREAMING_REQUEST_NOT_SET;
}
inline void StreamingRecognizeRequest::clear_has_streaming_request() {
  _oneof_case_[0] = STREAMING_REQUEST_NOT_SET;
}
inline StreamingRecognizeRequest::StreamingRequestCase StreamingRecognizeRequest::streaming_request_case() const {
  return StreamingRecognizeRequest::StreamingRequestCase(_oneof_case_[0]);
}
inline const StreamingRecognizeRequest* StreamingRecognizeRequest::internal_default_instance() {
  return &StreamingRecognizeRequest_default_instance_.get();
}
// -------------------------------------------------------------------

// StreamingRecognitionConfig

// optional .google.cloud.speech.v1beta1.RecognitionConfig config = 1;
inline bool StreamingRecognitionConfig::has_config() const {
  return this != internal_default_instance() && config_ != NULL;
}
inline void StreamingRecognitionConfig::clear_config() {
  if (GetArenaNoVirtual() == NULL && config_ != NULL) delete config_;
  config_ = NULL;
}
inline const ::google::cloud::speech::v1beta1::RecognitionConfig& StreamingRecognitionConfig::config() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.StreamingRecognitionConfig.config)
  return config_ != NULL ? *config_
                         : *::google::cloud::speech::v1beta1::RecognitionConfig::internal_default_instance();
}
inline ::google::cloud::speech::v1beta1::RecognitionConfig* StreamingRecognitionConfig::mutable_config() {
  
  if (config_ == NULL) {
    config_ = new ::google::cloud::speech::v1beta1::RecognitionConfig;
  }
  // @@protoc_insertion_point(field_mutable:google.cloud.speech.v1beta1.StreamingRecognitionConfig.config)
  return config_;
}
inline ::google::cloud::speech::v1beta1::RecognitionConfig* StreamingRecognitionConfig::release_config() {
  // @@protoc_insertion_point(field_release:google.cloud.speech.v1beta1.StreamingRecognitionConfig.config)
  
  ::google::cloud::speech::v1beta1::RecognitionConfig* temp = config_;
  config_ = NULL;
  return temp;
}
inline void StreamingRecognitionConfig::set_allocated_config(::google::cloud::speech::v1beta1::RecognitionConfig* config) {
  delete config_;
  config_ = config;
  if (config) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:google.cloud.speech.v1beta1.StreamingRecognitionConfig.config)
}

// optional bool single_utterance = 2;
inline void StreamingRecognitionConfig::clear_single_utterance() {
  single_utterance_ = false;
}
inline bool StreamingRecognitionConfig::single_utterance() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.StreamingRecognitionConfig.single_utterance)
  return single_utterance_;
}
inline void StreamingRecognitionConfig::set_single_utterance(bool value) {
  
  single_utterance_ = value;
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.StreamingRecognitionConfig.single_utterance)
}

// optional bool interim_results = 3;
inline void StreamingRecognitionConfig::clear_interim_results() {
  interim_results_ = false;
}
inline bool StreamingRecognitionConfig::interim_results() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.StreamingRecognitionConfig.interim_results)
  return interim_results_;
}
inline void StreamingRecognitionConfig::set_interim_results(bool value) {
  
  interim_results_ = value;
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.StreamingRecognitionConfig.interim_results)
}

inline const StreamingRecognitionConfig* StreamingRecognitionConfig::internal_default_instance() {
  return &StreamingRecognitionConfig_default_instance_.get();
}
// -------------------------------------------------------------------

// RecognitionConfig

// optional .google.cloud.speech.v1beta1.RecognitionConfig.AudioEncoding encoding = 1;
inline void RecognitionConfig::clear_encoding() {
  encoding_ = 0;
}
inline ::google::cloud::speech::v1beta1::RecognitionConfig_AudioEncoding RecognitionConfig::encoding() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.RecognitionConfig.encoding)
  return static_cast< ::google::cloud::speech::v1beta1::RecognitionConfig_AudioEncoding >(encoding_);
}
inline void RecognitionConfig::set_encoding(::google::cloud::speech::v1beta1::RecognitionConfig_AudioEncoding value) {
  
  encoding_ = value;
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.RecognitionConfig.encoding)
}

// optional int32 sample_rate = 2;
inline void RecognitionConfig::clear_sample_rate() {
  sample_rate_ = 0;
}
inline ::google::protobuf::int32 RecognitionConfig::sample_rate() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.RecognitionConfig.sample_rate)
  return sample_rate_;
}
inline void RecognitionConfig::set_sample_rate(::google::protobuf::int32 value) {
  
  sample_rate_ = value;
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.RecognitionConfig.sample_rate)
}

// optional string language_code = 3;
inline void RecognitionConfig::clear_language_code() {
  language_code_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline const ::std::string& RecognitionConfig::language_code() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.RecognitionConfig.language_code)
  return language_code_.GetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void RecognitionConfig::set_language_code(const ::std::string& value) {
  
  language_code_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.RecognitionConfig.language_code)
}
inline void RecognitionConfig::set_language_code(const char* value) {
  
  language_code_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:google.cloud.speech.v1beta1.RecognitionConfig.language_code)
}
inline void RecognitionConfig::set_language_code(const char* value, size_t size) {
  
  language_code_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:google.cloud.speech.v1beta1.RecognitionConfig.language_code)
}
inline ::std::string* RecognitionConfig::mutable_language_code() {
  
  // @@protoc_insertion_point(field_mutable:google.cloud.speech.v1beta1.RecognitionConfig.language_code)
  return language_code_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* RecognitionConfig::release_language_code() {
  // @@protoc_insertion_point(field_release:google.cloud.speech.v1beta1.RecognitionConfig.language_code)
  
  return language_code_.ReleaseNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void RecognitionConfig::set_allocated_language_code(::std::string* language_code) {
  if (language_code != NULL) {
    
  } else {
    
  }
  language_code_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), language_code);
  // @@protoc_insertion_point(field_set_allocated:google.cloud.speech.v1beta1.RecognitionConfig.language_code)
}

// optional int32 max_alternatives = 4;
inline void RecognitionConfig::clear_max_alternatives() {
  max_alternatives_ = 0;
}
inline ::google::protobuf::int32 RecognitionConfig::max_alternatives() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.RecognitionConfig.max_alternatives)
  return max_alternatives_;
}
inline void RecognitionConfig::set_max_alternatives(::google::protobuf::int32 value) {
  
  max_alternatives_ = value;
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.RecognitionConfig.max_alternatives)
}

// optional bool profanity_filter = 5;
inline void RecognitionConfig::clear_profanity_filter() {
  profanity_filter_ = false;
}
inline bool RecognitionConfig::profanity_filter() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.RecognitionConfig.profanity_filter)
  return profanity_filter_;
}
inline void RecognitionConfig::set_profanity_filter(bool value) {
  
  profanity_filter_ = value;
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.RecognitionConfig.profanity_filter)
}

// optional .google.cloud.speech.v1beta1.SpeechContext speech_context = 6;
inline bool RecognitionConfig::has_speech_context() const {
  return this != internal_default_instance() && speech_context_ != NULL;
}
inline void RecognitionConfig::clear_speech_context() {
  if (GetArenaNoVirtual() == NULL && speech_context_ != NULL) delete speech_context_;
  speech_context_ = NULL;
}
inline const ::google::cloud::speech::v1beta1::SpeechContext& RecognitionConfig::speech_context() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.RecognitionConfig.speech_context)
  return speech_context_ != NULL ? *speech_context_
                         : *::google::cloud::speech::v1beta1::SpeechContext::internal_default_instance();
}
inline ::google::cloud::speech::v1beta1::SpeechContext* RecognitionConfig::mutable_speech_context() {
  
  if (speech_context_ == NULL) {
    speech_context_ = new ::google::cloud::speech::v1beta1::SpeechContext;
  }
  // @@protoc_insertion_point(field_mutable:google.cloud.speech.v1beta1.RecognitionConfig.speech_context)
  return speech_context_;
}
inline ::google::cloud::speech::v1beta1::SpeechContext* RecognitionConfig::release_speech_context() {
  // @@protoc_insertion_point(field_release:google.cloud.speech.v1beta1.RecognitionConfig.speech_context)
  
  ::google::cloud::speech::v1beta1::SpeechContext* temp = speech_context_;
  speech_context_ = NULL;
  return temp;
}
inline void RecognitionConfig::set_allocated_speech_context(::google::cloud::speech::v1beta1::SpeechContext* speech_context) {
  delete speech_context_;
  speech_context_ = speech_context;
  if (speech_context) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:google.cloud.speech.v1beta1.RecognitionConfig.speech_context)
}

inline const RecognitionConfig* RecognitionConfig::internal_default_instance() {
  return &RecognitionConfig_default_instance_.get();
}
// -------------------------------------------------------------------

// SpeechContext

// repeated string phrases = 1;
inline int SpeechContext::phrases_size() const {
  return phrases_.size();
}
inline void SpeechContext::clear_phrases() {
  phrases_.Clear();
}
inline const ::std::string& SpeechContext::phrases(int index) const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.SpeechContext.phrases)
  return phrases_.Get(index);
}
inline ::std::string* SpeechContext::mutable_phrases(int index) {
  // @@protoc_insertion_point(field_mutable:google.cloud.speech.v1beta1.SpeechContext.phrases)
  return phrases_.Mutable(index);
}
inline void SpeechContext::set_phrases(int index, const ::std::string& value) {
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.SpeechContext.phrases)
  phrases_.Mutable(index)->assign(value);
}
inline void SpeechContext::set_phrases(int index, const char* value) {
  phrases_.Mutable(index)->assign(value);
  // @@protoc_insertion_point(field_set_char:google.cloud.speech.v1beta1.SpeechContext.phrases)
}
inline void SpeechContext::set_phrases(int index, const char* value, size_t size) {
  phrases_.Mutable(index)->assign(
    reinterpret_cast<const char*>(value), size);
  // @@protoc_insertion_point(field_set_pointer:google.cloud.speech.v1beta1.SpeechContext.phrases)
}
inline ::std::string* SpeechContext::add_phrases() {
  // @@protoc_insertion_point(field_add_mutable:google.cloud.speech.v1beta1.SpeechContext.phrases)
  return phrases_.Add();
}
inline void SpeechContext::add_phrases(const ::std::string& value) {
  phrases_.Add()->assign(value);
  // @@protoc_insertion_point(field_add:google.cloud.speech.v1beta1.SpeechContext.phrases)
}
inline void SpeechContext::add_phrases(const char* value) {
  phrases_.Add()->assign(value);
  // @@protoc_insertion_point(field_add_char:google.cloud.speech.v1beta1.SpeechContext.phrases)
}
inline void SpeechContext::add_phrases(const char* value, size_t size) {
  phrases_.Add()->assign(reinterpret_cast<const char*>(value), size);
  // @@protoc_insertion_point(field_add_pointer:google.cloud.speech.v1beta1.SpeechContext.phrases)
}
inline const ::google::protobuf::RepeatedPtrField< ::std::string>&
SpeechContext::phrases() const {
  // @@protoc_insertion_point(field_list:google.cloud.speech.v1beta1.SpeechContext.phrases)
  return phrases_;
}
inline ::google::protobuf::RepeatedPtrField< ::std::string>*
SpeechContext::mutable_phrases() {
  // @@protoc_insertion_point(field_mutable_list:google.cloud.speech.v1beta1.SpeechContext.phrases)
  return &phrases_;
}

inline const SpeechContext* SpeechContext::internal_default_instance() {
  return &SpeechContext_default_instance_.get();
}
// -------------------------------------------------------------------

// RecognitionAudio

// optional bytes content = 1;
inline bool RecognitionAudio::has_content() const {
  return audio_source_case() == kContent;
}
inline void RecognitionAudio::set_has_content() {
  _oneof_case_[0] = kContent;
}
inline void RecognitionAudio::clear_content() {
  if (has_content()) {
    audio_source_.content_.DestroyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
    clear_has_audio_source();
  }
}
inline const ::std::string& RecognitionAudio::content() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.RecognitionAudio.content)
  if (has_content()) {
    return audio_source_.content_.GetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  }
  return *&::google::protobuf::internal::GetEmptyStringAlreadyInited();
}
inline void RecognitionAudio::set_content(const ::std::string& value) {
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.RecognitionAudio.content)
  if (!has_content()) {
    clear_audio_source();
    set_has_content();
    audio_source_.content_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  }
  audio_source_.content_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.RecognitionAudio.content)
}
inline void RecognitionAudio::set_content(const char* value) {
  if (!has_content()) {
    clear_audio_source();
    set_has_content();
    audio_source_.content_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  }
  audio_source_.content_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(value));
  // @@protoc_insertion_point(field_set_char:google.cloud.speech.v1beta1.RecognitionAudio.content)
}
inline void RecognitionAudio::set_content(const void* value, size_t size) {
  if (!has_content()) {
    clear_audio_source();
    set_has_content();
    audio_source_.content_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  }
  audio_source_.content_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(
      reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:google.cloud.speech.v1beta1.RecognitionAudio.content)
}
inline ::std::string* RecognitionAudio::mutable_content() {
  if (!has_content()) {
    clear_audio_source();
    set_has_content();
    audio_source_.content_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  }
  // @@protoc_insertion_point(field_mutable:google.cloud.speech.v1beta1.RecognitionAudio.content)
  return audio_source_.content_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* RecognitionAudio::release_content() {
  // @@protoc_insertion_point(field_release:google.cloud.speech.v1beta1.RecognitionAudio.content)
  if (has_content()) {
    clear_has_audio_source();
    return audio_source_.content_.ReleaseNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  } else {
    return NULL;
  }
}
inline void RecognitionAudio::set_allocated_content(::std::string* content) {
  if (!has_content()) {
    audio_source_.content_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  }
  clear_audio_source();
  if (content != NULL) {
    set_has_content();
    audio_source_.content_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
        content);
  }
  // @@protoc_insertion_point(field_set_allocated:google.cloud.speech.v1beta1.RecognitionAudio.content)
}

// optional string uri = 2;
inline bool RecognitionAudio::has_uri() const {
  return audio_source_case() == kUri;
}
inline void RecognitionAudio::set_has_uri() {
  _oneof_case_[0] = kUri;
}
inline void RecognitionAudio::clear_uri() {
  if (has_uri()) {
    audio_source_.uri_.DestroyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
    clear_has_audio_source();
  }
}
inline const ::std::string& RecognitionAudio::uri() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.RecognitionAudio.uri)
  if (has_uri()) {
    return audio_source_.uri_.GetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  }
  return *&::google::protobuf::internal::GetEmptyStringAlreadyInited();
}
inline void RecognitionAudio::set_uri(const ::std::string& value) {
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.RecognitionAudio.uri)
  if (!has_uri()) {
    clear_audio_source();
    set_has_uri();
    audio_source_.uri_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  }
  audio_source_.uri_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.RecognitionAudio.uri)
}
inline void RecognitionAudio::set_uri(const char* value) {
  if (!has_uri()) {
    clear_audio_source();
    set_has_uri();
    audio_source_.uri_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  }
  audio_source_.uri_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(value));
  // @@protoc_insertion_point(field_set_char:google.cloud.speech.v1beta1.RecognitionAudio.uri)
}
inline void RecognitionAudio::set_uri(const char* value, size_t size) {
  if (!has_uri()) {
    clear_audio_source();
    set_has_uri();
    audio_source_.uri_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  }
  audio_source_.uri_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(
      reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:google.cloud.speech.v1beta1.RecognitionAudio.uri)
}
inline ::std::string* RecognitionAudio::mutable_uri() {
  if (!has_uri()) {
    clear_audio_source();
    set_has_uri();
    audio_source_.uri_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  }
  // @@protoc_insertion_point(field_mutable:google.cloud.speech.v1beta1.RecognitionAudio.uri)
  return audio_source_.uri_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* RecognitionAudio::release_uri() {
  // @@protoc_insertion_point(field_release:google.cloud.speech.v1beta1.RecognitionAudio.uri)
  if (has_uri()) {
    clear_has_audio_source();
    return audio_source_.uri_.ReleaseNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  } else {
    return NULL;
  }
}
inline void RecognitionAudio::set_allocated_uri(::std::string* uri) {
  if (!has_uri()) {
    audio_source_.uri_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  }
  clear_audio_source();
  if (uri != NULL) {
    set_has_uri();
    audio_source_.uri_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
        uri);
  }
  // @@protoc_insertion_point(field_set_allocated:google.cloud.speech.v1beta1.RecognitionAudio.uri)
}

inline bool RecognitionAudio::has_audio_source() const {
  return audio_source_case() != AUDIO_SOURCE_NOT_SET;
}
inline void RecognitionAudio::clear_has_audio_source() {
  _oneof_case_[0] = AUDIO_SOURCE_NOT_SET;
}
inline RecognitionAudio::AudioSourceCase RecognitionAudio::audio_source_case() const {
  return RecognitionAudio::AudioSourceCase(_oneof_case_[0]);
}
inline const RecognitionAudio* RecognitionAudio::internal_default_instance() {
  return &RecognitionAudio_default_instance_.get();
}
// -------------------------------------------------------------------

// SyncRecognizeResponse

// repeated .google.cloud.speech.v1beta1.SpeechRecognitionResult results = 2;
inline int SyncRecognizeResponse::results_size() const {
  return results_.size();
}
inline void SyncRecognizeResponse::clear_results() {
  results_.Clear();
}
inline const ::google::cloud::speech::v1beta1::SpeechRecognitionResult& SyncRecognizeResponse::results(int index) const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.SyncRecognizeResponse.results)
  return results_.Get(index);
}
inline ::google::cloud::speech::v1beta1::SpeechRecognitionResult* SyncRecognizeResponse::mutable_results(int index) {
  // @@protoc_insertion_point(field_mutable:google.cloud.speech.v1beta1.SyncRecognizeResponse.results)
  return results_.Mutable(index);
}
inline ::google::cloud::speech::v1beta1::SpeechRecognitionResult* SyncRecognizeResponse::add_results() {
  // @@protoc_insertion_point(field_add:google.cloud.speech.v1beta1.SyncRecognizeResponse.results)
  return results_.Add();
}
inline ::google::protobuf::RepeatedPtrField< ::google::cloud::speech::v1beta1::SpeechRecognitionResult >*
SyncRecognizeResponse::mutable_results() {
  // @@protoc_insertion_point(field_mutable_list:google.cloud.speech.v1beta1.SyncRecognizeResponse.results)
  return &results_;
}
inline const ::google::protobuf::RepeatedPtrField< ::google::cloud::speech::v1beta1::SpeechRecognitionResult >&
SyncRecognizeResponse::results() const {
  // @@protoc_insertion_point(field_list:google.cloud.speech.v1beta1.SyncRecognizeResponse.results)
  return results_;
}

inline const SyncRecognizeResponse* SyncRecognizeResponse::internal_default_instance() {
  return &SyncRecognizeResponse_default_instance_.get();
}
// -------------------------------------------------------------------

// AsyncRecognizeResponse

// repeated .google.cloud.speech.v1beta1.SpeechRecognitionResult results = 2;
inline int AsyncRecognizeResponse::results_size() const {
  return results_.size();
}
inline void AsyncRecognizeResponse::clear_results() {
  results_.Clear();
}
inline const ::google::cloud::speech::v1beta1::SpeechRecognitionResult& AsyncRecognizeResponse::results(int index) const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.AsyncRecognizeResponse.results)
  return results_.Get(index);
}
inline ::google::cloud::speech::v1beta1::SpeechRecognitionResult* AsyncRecognizeResponse::mutable_results(int index) {
  // @@protoc_insertion_point(field_mutable:google.cloud.speech.v1beta1.AsyncRecognizeResponse.results)
  return results_.Mutable(index);
}
inline ::google::cloud::speech::v1beta1::SpeechRecognitionResult* AsyncRecognizeResponse::add_results() {
  // @@protoc_insertion_point(field_add:google.cloud.speech.v1beta1.AsyncRecognizeResponse.results)
  return results_.Add();
}
inline ::google::protobuf::RepeatedPtrField< ::google::cloud::speech::v1beta1::SpeechRecognitionResult >*
AsyncRecognizeResponse::mutable_results() {
  // @@protoc_insertion_point(field_mutable_list:google.cloud.speech.v1beta1.AsyncRecognizeResponse.results)
  return &results_;
}
inline const ::google::protobuf::RepeatedPtrField< ::google::cloud::speech::v1beta1::SpeechRecognitionResult >&
AsyncRecognizeResponse::results() const {
  // @@protoc_insertion_point(field_list:google.cloud.speech.v1beta1.AsyncRecognizeResponse.results)
  return results_;
}

inline const AsyncRecognizeResponse* AsyncRecognizeResponse::internal_default_instance() {
  return &AsyncRecognizeResponse_default_instance_.get();
}
// -------------------------------------------------------------------

// AsyncRecognizeMetadata

// optional int32 progress_percent = 1;
inline void AsyncRecognizeMetadata::clear_progress_percent() {
  progress_percent_ = 0;
}
inline ::google::protobuf::int32 AsyncRecognizeMetadata::progress_percent() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.AsyncRecognizeMetadata.progress_percent)
  return progress_percent_;
}
inline void AsyncRecognizeMetadata::set_progress_percent(::google::protobuf::int32 value) {
  
  progress_percent_ = value;
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.AsyncRecognizeMetadata.progress_percent)
}

// optional .google.protobuf.Timestamp start_time = 2;
inline bool AsyncRecognizeMetadata::has_start_time() const {
  return this != internal_default_instance() && start_time_ != NULL;
}
inline void AsyncRecognizeMetadata::clear_start_time() {
  if (GetArenaNoVirtual() == NULL && start_time_ != NULL) delete start_time_;
  start_time_ = NULL;
}
inline const ::google::protobuf::Timestamp& AsyncRecognizeMetadata::start_time() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.AsyncRecognizeMetadata.start_time)
  return start_time_ != NULL ? *start_time_
                         : *::google::protobuf::Timestamp::internal_default_instance();
}
inline ::google::protobuf::Timestamp* AsyncRecognizeMetadata::mutable_start_time() {
  
  if (start_time_ == NULL) {
    start_time_ = new ::google::protobuf::Timestamp;
  }
  // @@protoc_insertion_point(field_mutable:google.cloud.speech.v1beta1.AsyncRecognizeMetadata.start_time)
  return start_time_;
}
inline ::google::protobuf::Timestamp* AsyncRecognizeMetadata::release_start_time() {
  // @@protoc_insertion_point(field_release:google.cloud.speech.v1beta1.AsyncRecognizeMetadata.start_time)
  
  ::google::protobuf::Timestamp* temp = start_time_;
  start_time_ = NULL;
  return temp;
}
inline void AsyncRecognizeMetadata::set_allocated_start_time(::google::protobuf::Timestamp* start_time) {
  delete start_time_;
  if (start_time != NULL && start_time->GetArena() != NULL) {
    ::google::protobuf::Timestamp* new_start_time = new ::google::protobuf::Timestamp;
    new_start_time->CopyFrom(*start_time);
    start_time = new_start_time;
  }
  start_time_ = start_time;
  if (start_time) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:google.cloud.speech.v1beta1.AsyncRecognizeMetadata.start_time)
}

// optional .google.protobuf.Timestamp last_update_time = 3;
inline bool AsyncRecognizeMetadata::has_last_update_time() const {
  return this != internal_default_instance() && last_update_time_ != NULL;
}
inline void AsyncRecognizeMetadata::clear_last_update_time() {
  if (GetArenaNoVirtual() == NULL && last_update_time_ != NULL) delete last_update_time_;
  last_update_time_ = NULL;
}
inline const ::google::protobuf::Timestamp& AsyncRecognizeMetadata::last_update_time() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.AsyncRecognizeMetadata.last_update_time)
  return last_update_time_ != NULL ? *last_update_time_
                         : *::google::protobuf::Timestamp::internal_default_instance();
}
inline ::google::protobuf::Timestamp* AsyncRecognizeMetadata::mutable_last_update_time() {
  
  if (last_update_time_ == NULL) {
    last_update_time_ = new ::google::protobuf::Timestamp;
  }
  // @@protoc_insertion_point(field_mutable:google.cloud.speech.v1beta1.AsyncRecognizeMetadata.last_update_time)
  return last_update_time_;
}
inline ::google::protobuf::Timestamp* AsyncRecognizeMetadata::release_last_update_time() {
  // @@protoc_insertion_point(field_release:google.cloud.speech.v1beta1.AsyncRecognizeMetadata.last_update_time)
  
  ::google::protobuf::Timestamp* temp = last_update_time_;
  last_update_time_ = NULL;
  return temp;
}
inline void AsyncRecognizeMetadata::set_allocated_last_update_time(::google::protobuf::Timestamp* last_update_time) {
  delete last_update_time_;
  if (last_update_time != NULL && last_update_time->GetArena() != NULL) {
    ::google::protobuf::Timestamp* new_last_update_time = new ::google::protobuf::Timestamp;
    new_last_update_time->CopyFrom(*last_update_time);
    last_update_time = new_last_update_time;
  }
  last_update_time_ = last_update_time;
  if (last_update_time) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:google.cloud.speech.v1beta1.AsyncRecognizeMetadata.last_update_time)
}

inline const AsyncRecognizeMetadata* AsyncRecognizeMetadata::internal_default_instance() {
  return &AsyncRecognizeMetadata_default_instance_.get();
}
// -------------------------------------------------------------------

// StreamingRecognizeResponse

// optional .google.rpc.Status error = 1;
inline bool StreamingRecognizeResponse::has_error() const {
  return this != internal_default_instance() && error_ != NULL;
}
inline void StreamingRecognizeResponse::clear_error() {
  if (GetArenaNoVirtual() == NULL && error_ != NULL) delete error_;
  error_ = NULL;
}
inline const ::google::rpc::Status& StreamingRecognizeResponse::error() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.StreamingRecognizeResponse.error)
  return error_ != NULL ? *error_
                         : *::google::rpc::Status::internal_default_instance();
}
inline ::google::rpc::Status* StreamingRecognizeResponse::mutable_error() {
  
  if (error_ == NULL) {
    error_ = new ::google::rpc::Status;
  }
  // @@protoc_insertion_point(field_mutable:google.cloud.speech.v1beta1.StreamingRecognizeResponse.error)
  return error_;
}
inline ::google::rpc::Status* StreamingRecognizeResponse::release_error() {
  // @@protoc_insertion_point(field_release:google.cloud.speech.v1beta1.StreamingRecognizeResponse.error)
  
  ::google::rpc::Status* temp = error_;
  error_ = NULL;
  return temp;
}
inline void StreamingRecognizeResponse::set_allocated_error(::google::rpc::Status* error) {
  delete error_;
  error_ = error;
  if (error) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:google.cloud.speech.v1beta1.StreamingRecognizeResponse.error)
}

// repeated .google.cloud.speech.v1beta1.StreamingRecognitionResult results = 2;
inline int StreamingRecognizeResponse::results_size() const {
  return results_.size();
}
inline void StreamingRecognizeResponse::clear_results() {
  results_.Clear();
}
inline const ::google::cloud::speech::v1beta1::StreamingRecognitionResult& StreamingRecognizeResponse::results(int index) const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.StreamingRecognizeResponse.results)
  return results_.Get(index);
}
inline ::google::cloud::speech::v1beta1::StreamingRecognitionResult* StreamingRecognizeResponse::mutable_results(int index) {
  // @@protoc_insertion_point(field_mutable:google.cloud.speech.v1beta1.StreamingRecognizeResponse.results)
  return results_.Mutable(index);
}
inline ::google::cloud::speech::v1beta1::StreamingRecognitionResult* StreamingRecognizeResponse::add_results() {
  // @@protoc_insertion_point(field_add:google.cloud.speech.v1beta1.StreamingRecognizeResponse.results)
  return results_.Add();
}
inline ::google::protobuf::RepeatedPtrField< ::google::cloud::speech::v1beta1::StreamingRecognitionResult >*
StreamingRecognizeResponse::mutable_results() {
  // @@protoc_insertion_point(field_mutable_list:google.cloud.speech.v1beta1.StreamingRecognizeResponse.results)
  return &results_;
}
inline const ::google::protobuf::RepeatedPtrField< ::google::cloud::speech::v1beta1::StreamingRecognitionResult >&
StreamingRecognizeResponse::results() const {
  // @@protoc_insertion_point(field_list:google.cloud.speech.v1beta1.StreamingRecognizeResponse.results)
  return results_;
}

// optional int32 result_index = 3;
inline void StreamingRecognizeResponse::clear_result_index() {
  result_index_ = 0;
}
inline ::google::protobuf::int32 StreamingRecognizeResponse::result_index() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.StreamingRecognizeResponse.result_index)
  return result_index_;
}
inline void StreamingRecognizeResponse::set_result_index(::google::protobuf::int32 value) {
  
  result_index_ = value;
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.StreamingRecognizeResponse.result_index)
}

// optional .google.cloud.speech.v1beta1.StreamingRecognizeResponse.EndpointerType endpointer_type = 4;
inline void StreamingRecognizeResponse::clear_endpointer_type() {
  endpointer_type_ = 0;
}
inline ::google::cloud::speech::v1beta1::StreamingRecognizeResponse_EndpointerType StreamingRecognizeResponse::endpointer_type() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.StreamingRecognizeResponse.endpointer_type)
  return static_cast< ::google::cloud::speech::v1beta1::StreamingRecognizeResponse_EndpointerType >(endpointer_type_);
}
inline void StreamingRecognizeResponse::set_endpointer_type(::google::cloud::speech::v1beta1::StreamingRecognizeResponse_EndpointerType value) {
  
  endpointer_type_ = value;
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.StreamingRecognizeResponse.endpointer_type)
}

inline const StreamingRecognizeResponse* StreamingRecognizeResponse::internal_default_instance() {
  return &StreamingRecognizeResponse_default_instance_.get();
}
// -------------------------------------------------------------------

// StreamingRecognitionResult

// repeated .google.cloud.speech.v1beta1.SpeechRecognitionAlternative alternatives = 1;
inline int StreamingRecognitionResult::alternatives_size() const {
  return alternatives_.size();
}
inline void StreamingRecognitionResult::clear_alternatives() {
  alternatives_.Clear();
}
inline const ::google::cloud::speech::v1beta1::SpeechRecognitionAlternative& StreamingRecognitionResult::alternatives(int index) const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.StreamingRecognitionResult.alternatives)
  return alternatives_.Get(index);
}
inline ::google::cloud::speech::v1beta1::SpeechRecognitionAlternative* StreamingRecognitionResult::mutable_alternatives(int index) {
  // @@protoc_insertion_point(field_mutable:google.cloud.speech.v1beta1.StreamingRecognitionResult.alternatives)
  return alternatives_.Mutable(index);
}
inline ::google::cloud::speech::v1beta1::SpeechRecognitionAlternative* StreamingRecognitionResult::add_alternatives() {
  // @@protoc_insertion_point(field_add:google.cloud.speech.v1beta1.StreamingRecognitionResult.alternatives)
  return alternatives_.Add();
}
inline ::google::protobuf::RepeatedPtrField< ::google::cloud::speech::v1beta1::SpeechRecognitionAlternative >*
StreamingRecognitionResult::mutable_alternatives() {
  // @@protoc_insertion_point(field_mutable_list:google.cloud.speech.v1beta1.StreamingRecognitionResult.alternatives)
  return &alternatives_;
}
inline const ::google::protobuf::RepeatedPtrField< ::google::cloud::speech::v1beta1::SpeechRecognitionAlternative >&
StreamingRecognitionResult::alternatives() const {
  // @@protoc_insertion_point(field_list:google.cloud.speech.v1beta1.StreamingRecognitionResult.alternatives)
  return alternatives_;
}

// optional bool is_final = 2;
inline void StreamingRecognitionResult::clear_is_final() {
  is_final_ = false;
}
inline bool StreamingRecognitionResult::is_final() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.StreamingRecognitionResult.is_final)
  return is_final_;
}
inline void StreamingRecognitionResult::set_is_final(bool value) {
  
  is_final_ = value;
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.StreamingRecognitionResult.is_final)
}

// optional float stability = 3;
inline void StreamingRecognitionResult::clear_stability() {
  stability_ = 0;
}
inline float StreamingRecognitionResult::stability() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.StreamingRecognitionResult.stability)
  return stability_;
}
inline void StreamingRecognitionResult::set_stability(float value) {
  
  stability_ = value;
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.StreamingRecognitionResult.stability)
}

inline const StreamingRecognitionResult* StreamingRecognitionResult::internal_default_instance() {
  return &StreamingRecognitionResult_default_instance_.get();
}
// -------------------------------------------------------------------

// SpeechRecognitionResult

// repeated .google.cloud.speech.v1beta1.SpeechRecognitionAlternative alternatives = 1;
inline int SpeechRecognitionResult::alternatives_size() const {
  return alternatives_.size();
}
inline void SpeechRecognitionResult::clear_alternatives() {
  alternatives_.Clear();
}
inline const ::google::cloud::speech::v1beta1::SpeechRecognitionAlternative& SpeechRecognitionResult::alternatives(int index) const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.SpeechRecognitionResult.alternatives)
  return alternatives_.Get(index);
}
inline ::google::cloud::speech::v1beta1::SpeechRecognitionAlternative* SpeechRecognitionResult::mutable_alternatives(int index) {
  // @@protoc_insertion_point(field_mutable:google.cloud.speech.v1beta1.SpeechRecognitionResult.alternatives)
  return alternatives_.Mutable(index);
}
inline ::google::cloud::speech::v1beta1::SpeechRecognitionAlternative* SpeechRecognitionResult::add_alternatives() {
  // @@protoc_insertion_point(field_add:google.cloud.speech.v1beta1.SpeechRecognitionResult.alternatives)
  return alternatives_.Add();
}
inline ::google::protobuf::RepeatedPtrField< ::google::cloud::speech::v1beta1::SpeechRecognitionAlternative >*
SpeechRecognitionResult::mutable_alternatives() {
  // @@protoc_insertion_point(field_mutable_list:google.cloud.speech.v1beta1.SpeechRecognitionResult.alternatives)
  return &alternatives_;
}
inline const ::google::protobuf::RepeatedPtrField< ::google::cloud::speech::v1beta1::SpeechRecognitionAlternative >&
SpeechRecognitionResult::alternatives() const {
  // @@protoc_insertion_point(field_list:google.cloud.speech.v1beta1.SpeechRecognitionResult.alternatives)
  return alternatives_;
}

inline const SpeechRecognitionResult* SpeechRecognitionResult::internal_default_instance() {
  return &SpeechRecognitionResult_default_instance_.get();
}
// -------------------------------------------------------------------

// SpeechRecognitionAlternative

// optional string transcript = 1;
inline void SpeechRecognitionAlternative::clear_transcript() {
  transcript_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline const ::std::string& SpeechRecognitionAlternative::transcript() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.SpeechRecognitionAlternative.transcript)
  return transcript_.GetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void SpeechRecognitionAlternative::set_transcript(const ::std::string& value) {
  
  transcript_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.SpeechRecognitionAlternative.transcript)
}
inline void SpeechRecognitionAlternative::set_transcript(const char* value) {
  
  transcript_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:google.cloud.speech.v1beta1.SpeechRecognitionAlternative.transcript)
}
inline void SpeechRecognitionAlternative::set_transcript(const char* value, size_t size) {
  
  transcript_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:google.cloud.speech.v1beta1.SpeechRecognitionAlternative.transcript)
}
inline ::std::string* SpeechRecognitionAlternative::mutable_transcript() {
  
  // @@protoc_insertion_point(field_mutable:google.cloud.speech.v1beta1.SpeechRecognitionAlternative.transcript)
  return transcript_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* SpeechRecognitionAlternative::release_transcript() {
  // @@protoc_insertion_point(field_release:google.cloud.speech.v1beta1.SpeechRecognitionAlternative.transcript)
  
  return transcript_.ReleaseNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void SpeechRecognitionAlternative::set_allocated_transcript(::std::string* transcript) {
  if (transcript != NULL) {
    
  } else {
    
  }
  transcript_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), transcript);
  // @@protoc_insertion_point(field_set_allocated:google.cloud.speech.v1beta1.SpeechRecognitionAlternative.transcript)
}

// optional float confidence = 2;
inline void SpeechRecognitionAlternative::clear_confidence() {
  confidence_ = 0;
}
inline float SpeechRecognitionAlternative::confidence() const {
  // @@protoc_insertion_point(field_get:google.cloud.speech.v1beta1.SpeechRecognitionAlternative.confidence)
  return confidence_;
}
inline void SpeechRecognitionAlternative::set_confidence(float value) {
  
  confidence_ = value;
  // @@protoc_insertion_point(field_set:google.cloud.speech.v1beta1.SpeechRecognitionAlternative.confidence)
}

inline const SpeechRecognitionAlternative* SpeechRecognitionAlternative::internal_default_instance() {
  return &SpeechRecognitionAlternative_default_instance_.get();
}
#endif  // !PROTOBUF_INLINE_NOT_IN_HEADERS
// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

}  // namespace v1beta1
}  // namespace speech
}  // namespace cloud
}  // namespace google

#ifndef SWIG
namespace google {
namespace protobuf {

template <> struct is_proto_enum< ::google::cloud::speech::v1beta1::RecognitionConfig_AudioEncoding> : ::google::protobuf::internal::true_type {};
template <>
inline const EnumDescriptor* GetEnumDescriptor< ::google::cloud::speech::v1beta1::RecognitionConfig_AudioEncoding>() {
  return ::google::cloud::speech::v1beta1::RecognitionConfig_AudioEncoding_descriptor();
}
template <> struct is_proto_enum< ::google::cloud::speech::v1beta1::StreamingRecognizeResponse_EndpointerType> : ::google::protobuf::internal::true_type {};
template <>
inline const EnumDescriptor* GetEnumDescriptor< ::google::cloud::speech::v1beta1::StreamingRecognizeResponse_EndpointerType>() {
  return ::google::cloud::speech::v1beta1::StreamingRecognizeResponse_EndpointerType_descriptor();
}

}  // namespace protobuf
}  // namespace google
#endif  // SWIG

// @@protoc_insertion_point(global_scope)

#endif  // PROTOBUF_google_2fcloud_2fspeech_2fv1beta1_2fcloud_5fspeech_2eproto__INCLUDED
